vid count  100
total images: 1500; total batches: 375
hypernet  602767200
encoder  0
decoder  0
binarizer  0
Loaded
[TRAIN] Epoch[1](1/375); Loss: 0.055140; Backpropagation: 0.3195 sec; Batch: 2.1973 sec
0.1169 0.0818 0.0664 0.0593 0.0548 0.0517 0.0494 0.0478 0.0465 0.0455 0.0447 0.0441 0.0437 0.0434 0.0432 0.0430 

[TRAIN] Epoch[1](2/375); Loss: 0.033782; Backpropagation: 0.2899 sec; Batch: 2.0815 sec
0.0921 0.0542 0.0412 0.0356 0.0323 0.0300 0.0284 0.0274 0.0265 0.0258 0.0252 0.0248 0.0246 0.0243 0.0241 0.0240 

[TRAIN] Epoch[1](3/375); Loss: 0.029125; Backpropagation: 0.2892 sec; Batch: 2.1077 sec
0.0787 0.0490 0.0381 0.0307 0.0272 0.0251 0.0237 0.0229 0.0223 0.0219 0.0215 0.0212 0.0210 0.0209 0.0209 0.0208 

[TRAIN] Epoch[1](4/375); Loss: 0.045979; Backpropagation: 0.2886 sec; Batch: 2.0879 sec
0.1320 0.0718 0.0576 0.0472 0.0430 0.0404 0.0384 0.0368 0.0355 0.0345 0.0339 0.0334 0.0331 0.0328 0.0327 0.0325 

[TRAIN] Epoch[1](5/375); Loss: 0.046438; Backpropagation: 0.2885 sec; Batch: 2.0901 sec
0.1048 0.0727 0.0582 0.0503 0.0463 0.0436 0.0414 0.0394 0.0378 0.0368 0.0362 0.0357 0.0353 0.0350 0.0348 0.0347 

[TRAIN] Epoch[1](6/375); Loss: 0.052908; Backpropagation: 0.2886 sec; Batch: 2.0876 sec
0.1126 0.0771 0.0646 0.0566 0.0527 0.0497 0.0478 0.0461 0.0447 0.0436 0.0428 0.0423 0.0418 0.0416 0.0414 0.0412 

[TRAIN] Epoch[1](7/375); Loss: 0.049796; Backpropagation: 0.2884 sec; Batch: 2.0872 sec
0.1064 0.0745 0.0602 0.0528 0.0491 0.0465 0.0445 0.0430 0.0419 0.0410 0.0402 0.0398 0.0395 0.0393 0.0391 0.0389 

[TRAIN] Epoch[1](8/375); Loss: 0.059173; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.1198 0.0856 0.0738 0.0643 0.0596 0.0562 0.0535 0.0517 0.0502 0.0491 0.0483 0.0477 0.0472 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](9/375); Loss: 0.033428; Backpropagation: 0.2885 sec; Batch: 2.0796 sec
0.0866 0.0490 0.0442 0.0377 0.0329 0.0302 0.0284 0.0272 0.0263 0.0257 0.0251 0.0248 0.0245 0.0243 0.0241 0.0240 

[TRAIN] Epoch[1](10/375); Loss: 0.053095; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.1163 0.0717 0.0618 0.0562 0.0523 0.0498 0.0476 0.0464 0.0453 0.0445 0.0438 0.0433 0.0430 0.0427 0.0425 0.0424 

[TRAIN] Epoch[1](11/375); Loss: 0.059762; Backpropagation: 0.2880 sec; Batch: 2.0753 sec
0.1140 0.0836 0.0706 0.0645 0.0607 0.0577 0.0553 0.0534 0.0520 0.0509 0.0500 0.0494 0.0489 0.0486 0.0483 0.0482 

[TRAIN] Epoch[1](12/375); Loss: 0.037930; Backpropagation: 0.2883 sec; Batch: 2.0789 sec
0.0801 0.0525 0.0441 0.0395 0.0370 0.0354 0.0341 0.0333 0.0326 0.0320 0.0316 0.0313 0.0311 0.0309 0.0308 0.0307 

[TRAIN] Epoch[1](13/375); Loss: 0.049708; Backpropagation: 0.2883 sec; Batch: 2.0773 sec
0.1160 0.0763 0.0587 0.0516 0.0478 0.0457 0.0439 0.0423 0.0412 0.0403 0.0396 0.0391 0.0386 0.0383 0.0380 0.0378 

[TRAIN] Epoch[1](14/375); Loss: 0.040729; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.0972 0.0635 0.0487 0.0428 0.0393 0.0369 0.0353 0.0342 0.0333 0.0326 0.0321 0.0316 0.0313 0.0311 0.0309 0.0308 

[TRAIN] Epoch[1](15/375); Loss: 0.041154; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1026 0.0567 0.0450 0.0411 0.0389 0.0374 0.0360 0.0350 0.0343 0.0339 0.0335 0.0331 0.0330 0.0328 0.0327 0.0326 

[TRAIN] Epoch[1](16/375); Loss: 0.037200; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.0992 0.0609 0.0457 0.0379 0.0346 0.0327 0.0312 0.0301 0.0292 0.0286 0.0281 0.0278 0.0275 0.0273 0.0272 0.0271 

[TRAIN] Epoch[1](17/375); Loss: 0.062172; Backpropagation: 0.2883 sec; Batch: 2.0816 sec
0.1172 0.0895 0.0749 0.0675 0.0635 0.0604 0.0578 0.0556 0.0539 0.0527 0.0517 0.0509 0.0503 0.0499 0.0496 0.0493 

[TRAIN] Epoch[1](18/375); Loss: 0.057697; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1069 0.0825 0.0687 0.0620 0.0579 0.0555 0.0533 0.0517 0.0504 0.0493 0.0486 0.0479 0.0475 0.0472 0.0469 0.0467 

[TRAIN] Epoch[1](19/375); Loss: 0.056284; Backpropagation: 0.2882 sec; Batch: 2.0813 sec
0.1160 0.0813 0.0683 0.0621 0.0577 0.0542 0.0513 0.0491 0.0476 0.0464 0.0455 0.0448 0.0444 0.0441 0.0438 0.0436 

[TRAIN] Epoch[1](20/375); Loss: 0.058043; Backpropagation: 0.2884 sec; Batch: 2.0763 sec
0.1211 0.0816 0.0670 0.0602 0.0565 0.0542 0.0524 0.0510 0.0498 0.0491 0.0485 0.0480 0.0477 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](21/375); Loss: 0.042643; Backpropagation: 0.2883 sec; Batch: 2.0805 sec
0.1005 0.0649 0.0505 0.0439 0.0405 0.0388 0.0373 0.0362 0.0353 0.0345 0.0340 0.0336 0.0334 0.0331 0.0330 0.0328 

[TRAIN] Epoch[1](22/375); Loss: 0.036401; Backpropagation: 0.2881 sec; Batch: 2.0741 sec
0.0812 0.0540 0.0442 0.0388 0.0359 0.0339 0.0323 0.0311 0.0302 0.0295 0.0291 0.0288 0.0285 0.0284 0.0283 0.0282 

[TRAIN] Epoch[1](23/375); Loss: 0.040729; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.0850 0.0617 0.0503 0.0443 0.0413 0.0386 0.0366 0.0350 0.0340 0.0332 0.0327 0.0323 0.0320 0.0317 0.0316 0.0315 

[TRAIN] Epoch[1](24/375); Loss: 0.053672; Backpropagation: 0.2886 sec; Batch: 2.0773 sec
0.0981 0.0728 0.0646 0.0588 0.0551 0.0519 0.0496 0.0481 0.0469 0.0459 0.0453 0.0448 0.0445 0.0443 0.0441 0.0441 

[TRAIN] Epoch[1](25/375); Loss: 0.037971; Backpropagation: 0.2883 sec; Batch: 2.0751 sec
0.0866 0.0554 0.0458 0.0407 0.0376 0.0352 0.0334 0.0320 0.0310 0.0305 0.0302 0.0300 0.0298 0.0297 0.0297 0.0297 

[TRAIN] Epoch[1](26/375); Loss: 0.051786; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0968 0.0695 0.0600 0.0556 0.0529 0.0502 0.0481 0.0465 0.0454 0.0446 0.0440 0.0435 0.0432 0.0430 0.0428 0.0426 

[TRAIN] Epoch[1](27/375); Loss: 0.030811; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0729 0.0475 0.0386 0.0327 0.0299 0.0280 0.0267 0.0258 0.0251 0.0245 0.0241 0.0238 0.0235 0.0234 0.0233 0.0232 

[TRAIN] Epoch[1](28/375); Loss: 0.052891; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0933 0.0726 0.0620 0.0571 0.0541 0.0516 0.0496 0.0478 0.0466 0.0458 0.0451 0.0447 0.0443 0.0441 0.0439 0.0437 

[TRAIN] Epoch[1](29/375); Loss: 0.050697; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1034 0.0708 0.0607 0.0548 0.0511 0.0483 0.0461 0.0445 0.0433 0.0424 0.0417 0.0413 0.0410 0.0407 0.0406 0.0405 

[TRAIN] Epoch[1](30/375); Loss: 0.027584; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.0630 0.0433 0.0339 0.0295 0.0268 0.0252 0.0240 0.0230 0.0224 0.0220 0.0217 0.0215 0.0214 0.0213 0.0212 0.0211 

[TRAIN] Epoch[1](31/375); Loss: 0.031908; Backpropagation: 0.2883 sec; Batch: 2.0856 sec
0.0745 0.0466 0.0382 0.0335 0.0308 0.0290 0.0277 0.0269 0.0263 0.0259 0.0255 0.0254 0.0252 0.0251 0.0250 0.0249 

[TRAIN] Epoch[1](32/375); Loss: 0.051703; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.0899 0.0695 0.0603 0.0555 0.0528 0.0505 0.0488 0.0473 0.0460 0.0451 0.0445 0.0440 0.0436 0.0433 0.0431 0.0430 

[TRAIN] Epoch[1](33/375); Loss: 0.022934; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0573 0.0347 0.0271 0.0231 0.0212 0.0203 0.0196 0.0191 0.0187 0.0184 0.0182 0.0180 0.0179 0.0178 0.0178 0.0177 

[TRAIN] Epoch[1](34/375); Loss: 0.059155; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1152 0.0822 0.0700 0.0639 0.0600 0.0567 0.0542 0.0523 0.0511 0.0502 0.0494 0.0489 0.0485 0.0482 0.0479 0.0476 

[TRAIN] Epoch[1](35/375); Loss: 0.040899; Backpropagation: 0.2887 sec; Batch: 2.0752 sec
0.0859 0.0601 0.0493 0.0438 0.0405 0.0384 0.0368 0.0355 0.0346 0.0339 0.0333 0.0329 0.0326 0.0323 0.0322 0.0321 

[TRAIN] Epoch[1](36/375); Loss: 0.041481; Backpropagation: 0.2886 sec; Batch: 2.0763 sec
0.0711 0.0540 0.0479 0.0441 0.0417 0.0399 0.0387 0.0378 0.0371 0.0366 0.0363 0.0360 0.0358 0.0357 0.0355 0.0355 

[TRAIN] Epoch[1](37/375); Loss: 0.050716; Backpropagation: 0.2941 sec; Batch: 2.0818 sec
0.1017 0.0747 0.0631 0.0551 0.0509 0.0483 0.0460 0.0443 0.0430 0.0421 0.0414 0.0408 0.0405 0.0401 0.0398 0.0397 

[TRAIN] Epoch[1](38/375); Loss: 0.044485; Backpropagation: 0.2917 sec; Batch: 2.0797 sec
0.1014 0.0649 0.0552 0.0469 0.0434 0.0411 0.0393 0.0379 0.0369 0.0361 0.0356 0.0351 0.0348 0.0346 0.0344 0.0342 

[TRAIN] Epoch[1](39/375); Loss: 0.045238; Backpropagation: 0.2899 sec; Batch: 2.0804 sec
0.0959 0.0664 0.0546 0.0483 0.0453 0.0428 0.0409 0.0392 0.0381 0.0374 0.0367 0.0362 0.0359 0.0356 0.0354 0.0352 

[TRAIN] Epoch[1](40/375); Loss: 0.042045; Backpropagation: 0.2898 sec; Batch: 2.0768 sec
0.0911 0.0625 0.0534 0.0470 0.0429 0.0399 0.0377 0.0359 0.0348 0.0339 0.0332 0.0327 0.0323 0.0320 0.0317 0.0315 

[TRAIN] Epoch[1](41/375); Loss: 0.040654; Backpropagation: 0.2900 sec; Batch: 2.0766 sec
0.0789 0.0587 0.0498 0.0442 0.0410 0.0388 0.0371 0.0357 0.0348 0.0341 0.0336 0.0332 0.0329 0.0327 0.0325 0.0324 

[TRAIN] Epoch[1](42/375); Loss: 0.049193; Backpropagation: 0.2882 sec; Batch: 2.0754 sec
0.0867 0.0703 0.0586 0.0528 0.0499 0.0476 0.0457 0.0442 0.0432 0.0423 0.0418 0.0413 0.0409 0.0407 0.0405 0.0403 

[TRAIN] Epoch[1](43/375); Loss: 0.052288; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1016 0.0769 0.0642 0.0570 0.0530 0.0503 0.0476 0.0459 0.0446 0.0436 0.0430 0.0425 0.0420 0.0417 0.0415 0.0413 

[TRAIN] Epoch[1](44/375); Loss: 0.031624; Backpropagation: 0.2881 sec; Batch: 2.0745 sec
0.0877 0.0548 0.0393 0.0330 0.0297 0.0276 0.0261 0.0249 0.0241 0.0236 0.0231 0.0228 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[1](45/375); Loss: 0.052993; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.1092 0.0745 0.0614 0.0561 0.0524 0.0498 0.0480 0.0467 0.0455 0.0447 0.0442 0.0437 0.0433 0.0430 0.0428 0.0427 

[TRAIN] Epoch[1](46/375); Loss: 0.050117; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0995 0.0711 0.0593 0.0537 0.0506 0.0480 0.0461 0.0446 0.0433 0.0423 0.0415 0.0410 0.0405 0.0403 0.0401 0.0399 

[TRAIN] Epoch[1](47/375); Loss: 0.041952; Backpropagation: 0.2880 sec; Batch: 2.0753 sec
0.0988 0.0678 0.0531 0.0445 0.0406 0.0382 0.0365 0.0350 0.0338 0.0330 0.0324 0.0320 0.0317 0.0314 0.0313 0.0311 

[TRAIN] Epoch[1](48/375); Loss: 0.046347; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1080 0.0710 0.0571 0.0493 0.0455 0.0429 0.0407 0.0391 0.0380 0.0370 0.0363 0.0359 0.0356 0.0353 0.0351 0.0350 

[TRAIN] Epoch[1](49/375); Loss: 0.025349; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.0566 0.0408 0.0310 0.0260 0.0239 0.0227 0.0218 0.0212 0.0208 0.0205 0.0203 0.0201 0.0200 0.0200 0.0199 0.0199 

[TRAIN] Epoch[1](50/375); Loss: 0.046445; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.0941 0.0655 0.0539 0.0496 0.0467 0.0442 0.0423 0.0409 0.0400 0.0391 0.0386 0.0382 0.0378 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](51/375); Loss: 0.036090; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0823 0.0552 0.0441 0.0384 0.0351 0.0328 0.0315 0.0305 0.0298 0.0292 0.0287 0.0283 0.0281 0.0279 0.0278 0.0277 

[TRAIN] Epoch[1](52/375); Loss: 0.047637; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0851 0.0700 0.0568 0.0513 0.0482 0.0459 0.0441 0.0427 0.0417 0.0409 0.0402 0.0396 0.0392 0.0390 0.0388 0.0387 

[TRAIN] Epoch[1](53/375); Loss: 0.056836; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.1185 0.0857 0.0687 0.0612 0.0564 0.0527 0.0507 0.0490 0.0478 0.0469 0.0462 0.0457 0.0453 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](54/375); Loss: 0.045027; Backpropagation: 0.2883 sec; Batch: 2.0801 sec
0.1007 0.0671 0.0549 0.0491 0.0447 0.0420 0.0399 0.0384 0.0373 0.0364 0.0358 0.0353 0.0350 0.0347 0.0346 0.0345 

[TRAIN] Epoch[1](55/375); Loss: 0.036467; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.0834 0.0607 0.0468 0.0396 0.0360 0.0336 0.0318 0.0303 0.0292 0.0285 0.0279 0.0276 0.0273 0.0271 0.0269 0.0268 

[TRAIN] Epoch[1](56/375); Loss: 0.039345; Backpropagation: 0.2880 sec; Batch: 2.0733 sec
0.0691 0.0565 0.0471 0.0422 0.0397 0.0379 0.0364 0.0354 0.0345 0.0340 0.0334 0.0331 0.0328 0.0326 0.0324 0.0323 

[TRAIN] Epoch[1](57/375); Loss: 0.036395; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0777 0.0544 0.0442 0.0391 0.0357 0.0336 0.0322 0.0311 0.0304 0.0299 0.0295 0.0292 0.0290 0.0289 0.0288 0.0287 

[TRAIN] Epoch[1](58/375); Loss: 0.036862; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0909 0.0599 0.0482 0.0398 0.0358 0.0333 0.0314 0.0301 0.0291 0.0284 0.0279 0.0275 0.0271 0.0269 0.0268 0.0267 

[TRAIN] Epoch[1](59/375); Loss: 0.049133; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0910 0.0697 0.0589 0.0531 0.0493 0.0469 0.0450 0.0436 0.0427 0.0419 0.0414 0.0410 0.0407 0.0405 0.0403 0.0402 

[TRAIN] Epoch[1](60/375); Loss: 0.063030; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1120 0.0927 0.0775 0.0701 0.0645 0.0606 0.0581 0.0562 0.0548 0.0536 0.0526 0.0519 0.0514 0.0510 0.0508 0.0506 

[TRAIN] Epoch[1](61/375); Loss: 0.037199; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0903 0.0554 0.0443 0.0390 0.0358 0.0338 0.0325 0.0313 0.0304 0.0298 0.0294 0.0290 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](62/375); Loss: 0.042893; Backpropagation: 0.2888 sec; Batch: 2.0729 sec
0.0978 0.0637 0.0507 0.0451 0.0417 0.0394 0.0380 0.0368 0.0358 0.0350 0.0345 0.0341 0.0338 0.0335 0.0333 0.0332 

[TRAIN] Epoch[1](63/375); Loss: 0.046084; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0863 0.0687 0.0564 0.0503 0.0462 0.0440 0.0422 0.0409 0.0397 0.0388 0.0382 0.0377 0.0373 0.0371 0.0369 0.0367 

[TRAIN] Epoch[1](64/375); Loss: 0.049703; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1257 0.0891 0.0689 0.0583 0.0501 0.0448 0.0414 0.0389 0.0373 0.0361 0.0352 0.0346 0.0342 0.0338 0.0335 0.0333 

[TRAIN] Epoch[1](65/375); Loss: 0.051364; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0874 0.0732 0.0614 0.0560 0.0523 0.0499 0.0480 0.0466 0.0454 0.0445 0.0438 0.0433 0.0429 0.0426 0.0424 0.0421 

[TRAIN] Epoch[1](66/375); Loss: 0.044635; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0817 0.0649 0.0551 0.0486 0.0448 0.0424 0.0408 0.0396 0.0387 0.0379 0.0374 0.0369 0.0367 0.0364 0.0362 0.0361 

[TRAIN] Epoch[1](67/375); Loss: 0.054236; Backpropagation: 0.2880 sec; Batch: 2.0733 sec
0.1148 0.0926 0.0752 0.0632 0.0549 0.0499 0.0465 0.0444 0.0431 0.0420 0.0413 0.0407 0.0402 0.0399 0.0397 0.0395 

[TRAIN] Epoch[1](68/375); Loss: 0.053038; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.1100 0.0870 0.0702 0.0594 0.0535 0.0496 0.0466 0.0448 0.0432 0.0422 0.0415 0.0408 0.0404 0.0400 0.0398 0.0396 

[TRAIN] Epoch[1](69/375); Loss: 0.049138; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.0930 0.0716 0.0605 0.0533 0.0493 0.0467 0.0447 0.0433 0.0422 0.0415 0.0409 0.0404 0.0400 0.0398 0.0396 0.0394 

[TRAIN] Epoch[1](70/375); Loss: 0.038582; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0827 0.0586 0.0491 0.0426 0.0389 0.0361 0.0344 0.0329 0.0319 0.0313 0.0307 0.0302 0.0298 0.0295 0.0293 0.0292 

[TRAIN] Epoch[1](71/375); Loss: 0.038197; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0913 0.0598 0.0455 0.0403 0.0373 0.0348 0.0331 0.0318 0.0310 0.0304 0.0299 0.0296 0.0294 0.0291 0.0290 0.0288 

[TRAIN] Epoch[1](72/375); Loss: 0.049060; Backpropagation: 0.2882 sec; Batch: 2.0729 sec
0.0910 0.0745 0.0616 0.0552 0.0507 0.0475 0.0451 0.0432 0.0418 0.0409 0.0401 0.0394 0.0389 0.0386 0.0383 0.0381 

[TRAIN] Epoch[1](73/375); Loss: 0.053376; Backpropagation: 0.2886 sec; Batch: 2.0728 sec
0.0982 0.0751 0.0652 0.0591 0.0551 0.0524 0.0501 0.0482 0.0466 0.0454 0.0445 0.0437 0.0432 0.0427 0.0424 0.0421 

[TRAIN] Epoch[1](74/375); Loss: 0.058591; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.1092 0.0873 0.0745 0.0666 0.0608 0.0567 0.0536 0.0514 0.0499 0.0487 0.0477 0.0471 0.0466 0.0461 0.0458 0.0456 

[TRAIN] Epoch[1](75/375); Loss: 0.037842; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0826 0.0590 0.0497 0.0419 0.0381 0.0354 0.0335 0.0319 0.0308 0.0300 0.0294 0.0291 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](76/375); Loss: 0.036580; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0804 0.0604 0.0475 0.0405 0.0365 0.0338 0.0322 0.0310 0.0298 0.0289 0.0283 0.0278 0.0274 0.0271 0.0269 0.0268 

[TRAIN] Epoch[1](77/375); Loss: 0.057850; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1009 0.0801 0.0690 0.0630 0.0589 0.0561 0.0540 0.0524 0.0511 0.0502 0.0495 0.0488 0.0484 0.0480 0.0478 0.0476 

[TRAIN] Epoch[1](78/375); Loss: 0.048781; Backpropagation: 0.2883 sec; Batch: 2.0725 sec
0.0817 0.0671 0.0567 0.0519 0.0491 0.0473 0.0458 0.0446 0.0436 0.0429 0.0424 0.0420 0.0416 0.0414 0.0413 0.0412 

[TRAIN] Epoch[1](79/375); Loss: 0.049564; Backpropagation: 0.2880 sec; Batch: 2.0722 sec
0.0870 0.0688 0.0607 0.0543 0.0503 0.0478 0.0461 0.0447 0.0435 0.0427 0.0420 0.0416 0.0412 0.0409 0.0407 0.0406 

[TRAIN] Epoch[1](80/375); Loss: 0.048293; Backpropagation: 0.2886 sec; Batch: 2.0812 sec
0.0819 0.0709 0.0599 0.0523 0.0486 0.0460 0.0445 0.0432 0.0422 0.0415 0.0410 0.0406 0.0403 0.0401 0.0400 0.0399 

[TRAIN] Epoch[1](81/375); Loss: 0.042553; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0762 0.0610 0.0521 0.0472 0.0442 0.0415 0.0396 0.0380 0.0369 0.0361 0.0355 0.0350 0.0347 0.0344 0.0342 0.0341 

[TRAIN] Epoch[1](82/375); Loss: 0.033666; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.0713 0.0502 0.0415 0.0367 0.0338 0.0316 0.0300 0.0289 0.0282 0.0276 0.0271 0.0267 0.0265 0.0263 0.0262 0.0261 

[TRAIN] Epoch[1](83/375); Loss: 0.039248; Backpropagation: 0.2879 sec; Batch: 2.0715 sec
0.0927 0.0579 0.0453 0.0408 0.0380 0.0360 0.0348 0.0335 0.0326 0.0319 0.0314 0.0310 0.0307 0.0306 0.0304 0.0303 

[TRAIN] Epoch[1](84/375); Loss: 0.050344; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.0959 0.0705 0.0610 0.0549 0.0514 0.0486 0.0466 0.0449 0.0437 0.0426 0.0418 0.0414 0.0409 0.0406 0.0404 0.0403 

[TRAIN] Epoch[1](85/375); Loss: 0.046254; Backpropagation: 0.2882 sec; Batch: 2.0728 sec
0.0967 0.0729 0.0603 0.0523 0.0467 0.0433 0.0408 0.0392 0.0381 0.0371 0.0363 0.0358 0.0355 0.0352 0.0350 0.0348 

[TRAIN] Epoch[1](86/375); Loss: 0.056336; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1038 0.0819 0.0674 0.0612 0.0573 0.0544 0.0523 0.0504 0.0490 0.0479 0.0471 0.0464 0.0460 0.0457 0.0454 0.0452 

[TRAIN] Epoch[1](87/375); Loss: 0.032633; Backpropagation: 0.2880 sec; Batch: 2.0731 sec
0.0684 0.0520 0.0408 0.0357 0.0327 0.0306 0.0291 0.0279 0.0270 0.0263 0.0259 0.0255 0.0253 0.0251 0.0250 0.0249 

[TRAIN] Epoch[1](88/375); Loss: 0.051839; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0949 0.0716 0.0620 0.0555 0.0519 0.0494 0.0478 0.0464 0.0454 0.0446 0.0441 0.0436 0.0433 0.0431 0.0429 0.0428 

[TRAIN] Epoch[1](89/375); Loss: 0.037531; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0921 0.0696 0.0519 0.0417 0.0373 0.0339 0.0317 0.0298 0.0285 0.0277 0.0269 0.0264 0.0260 0.0258 0.0256 0.0255 

[TRAIN] Epoch[1](90/375); Loss: 0.045266; Backpropagation: 0.2884 sec; Batch: 2.0722 sec
0.0825 0.0721 0.0571 0.0487 0.0450 0.0424 0.0408 0.0395 0.0386 0.0379 0.0374 0.0370 0.0367 0.0364 0.0362 0.0361 

[TRAIN] Epoch[1](91/375); Loss: 0.063172; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1109 0.0912 0.0755 0.0682 0.0639 0.0608 0.0587 0.0570 0.0556 0.0544 0.0535 0.0530 0.0525 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](92/375); Loss: 0.050411; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.1056 0.0829 0.0662 0.0563 0.0500 0.0467 0.0446 0.0428 0.0415 0.0404 0.0395 0.0388 0.0383 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](93/375); Loss: 0.049606; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.0991 0.0795 0.0625 0.0537 0.0499 0.0467 0.0445 0.0431 0.0417 0.0405 0.0397 0.0392 0.0388 0.0384 0.0382 0.0380 

[TRAIN] Epoch[1](94/375); Loss: 0.063601; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1104 0.0930 0.0785 0.0708 0.0662 0.0628 0.0599 0.0573 0.0555 0.0540 0.0528 0.0521 0.0516 0.0511 0.0509 0.0507 

[TRAIN] Epoch[1](95/375); Loss: 0.059943; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1093 0.0962 0.0770 0.0658 0.0610 0.0574 0.0548 0.0526 0.0509 0.0496 0.0486 0.0480 0.0474 0.0471 0.0468 0.0466 

[TRAIN] Epoch[1](96/375); Loss: 0.053319; Backpropagation: 0.2883 sec; Batch: 2.0719 sec
0.0973 0.0799 0.0648 0.0579 0.0541 0.0512 0.0489 0.0474 0.0462 0.0452 0.0444 0.0439 0.0434 0.0430 0.0428 0.0426 

[TRAIN] Epoch[1](97/375); Loss: 0.061046; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1043 0.0871 0.0743 0.0666 0.0625 0.0595 0.0570 0.0551 0.0536 0.0525 0.0516 0.0511 0.0508 0.0505 0.0503 0.0501 

[TRAIN] Epoch[1](98/375); Loss: 0.046092; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.0953 0.0778 0.0600 0.0495 0.0457 0.0427 0.0405 0.0388 0.0379 0.0370 0.0363 0.0357 0.0353 0.0352 0.0350 0.0349 

[TRAIN] Epoch[1](99/375); Loss: 0.065811; Backpropagation: 0.2892 sec; Batch: 2.0738 sec
0.1130 0.0975 0.0807 0.0723 0.0675 0.0639 0.0614 0.0594 0.0578 0.0564 0.0553 0.0545 0.0539 0.0534 0.0531 0.0529 

[TRAIN] Epoch[1](100/375); Loss: 0.050262; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.0978 0.0835 0.0626 0.0553 0.0511 0.0481 0.0458 0.0437 0.0420 0.0408 0.0401 0.0394 0.0389 0.0386 0.0383 0.0381 

[TRAIN] Epoch[1](101/375); Loss: 0.045920; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0947 0.0762 0.0589 0.0497 0.0453 0.0425 0.0404 0.0388 0.0377 0.0370 0.0364 0.0360 0.0356 0.0354 0.0352 0.0350 

[TRAIN] Epoch[1](102/375); Loss: 0.051144; Backpropagation: 0.2884 sec; Batch: 2.0719 sec
0.1110 0.0876 0.0665 0.0559 0.0511 0.0476 0.0450 0.0429 0.0415 0.0403 0.0394 0.0388 0.0382 0.0378 0.0375 0.0373 

[TRAIN] Epoch[1](103/375); Loss: 0.043396; Backpropagation: 0.2885 sec; Batch: 2.0779 sec
0.1098 0.0871 0.0571 0.0472 0.0419 0.0383 0.0357 0.0340 0.0327 0.0316 0.0308 0.0303 0.0299 0.0296 0.0293 0.0291 

[TRAIN] Epoch[1](104/375); Loss: 0.052532; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1053 0.0811 0.0636 0.0557 0.0525 0.0500 0.0478 0.0461 0.0447 0.0436 0.0428 0.0422 0.0417 0.0414 0.0411 0.0409 

[TRAIN] Epoch[1](105/375); Loss: 0.033238; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0935 0.0745 0.0487 0.0344 0.0302 0.0279 0.0255 0.0240 0.0231 0.0223 0.0219 0.0215 0.0213 0.0211 0.0210 0.0209 

[TRAIN] Epoch[1](106/375); Loss: 0.053464; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1112 0.0903 0.0674 0.0580 0.0528 0.0499 0.0474 0.0457 0.0441 0.0430 0.0421 0.0414 0.0410 0.0406 0.0403 0.0401 

[TRAIN] Epoch[1](107/375); Loss: 0.039578; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0935 0.0722 0.0518 0.0427 0.0387 0.0358 0.0337 0.0322 0.0311 0.0302 0.0295 0.0290 0.0286 0.0283 0.0281 0.0280 

[TRAIN] Epoch[1](108/375); Loss: 0.050508; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1021 0.0846 0.0657 0.0562 0.0510 0.0477 0.0454 0.0433 0.0417 0.0406 0.0396 0.0389 0.0383 0.0379 0.0376 0.0374 

[TRAIN] Epoch[1](109/375); Loss: 0.046076; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0884 0.0757 0.0594 0.0513 0.0467 0.0435 0.0414 0.0398 0.0386 0.0376 0.0368 0.0362 0.0358 0.0355 0.0353 0.0352 

[TRAIN] Epoch[1](110/375); Loss: 0.040757; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0989 0.0755 0.0546 0.0446 0.0405 0.0371 0.0347 0.0328 0.0314 0.0304 0.0296 0.0291 0.0286 0.0283 0.0281 0.0279 

[TRAIN] Epoch[1](111/375); Loss: 0.035043; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0720 0.0570 0.0426 0.0365 0.0337 0.0319 0.0307 0.0299 0.0292 0.0287 0.0284 0.0282 0.0281 0.0280 0.0279 0.0279 

[TRAIN] Epoch[1](112/375); Loss: 0.059819; Backpropagation: 0.2881 sec; Batch: 2.0738 sec
0.1094 0.0929 0.0756 0.0667 0.0621 0.0583 0.0552 0.0528 0.0508 0.0496 0.0486 0.0479 0.0474 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](113/375); Loss: 0.037460; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.0867 0.0706 0.0515 0.0404 0.0366 0.0341 0.0319 0.0303 0.0291 0.0281 0.0275 0.0270 0.0267 0.0265 0.0263 0.0262 

[TRAIN] Epoch[1](114/375); Loss: 0.056506; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0989 0.0860 0.0680 0.0612 0.0576 0.0544 0.0523 0.0508 0.0492 0.0481 0.0473 0.0467 0.0463 0.0460 0.0458 0.0456 

[TRAIN] Epoch[1](115/375); Loss: 0.061409; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1162 0.1006 0.0811 0.0696 0.0629 0.0587 0.0556 0.0532 0.0512 0.0497 0.0487 0.0480 0.0474 0.0469 0.0466 0.0463 

[TRAIN] Epoch[1](116/375); Loss: 0.033839; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0877 0.0654 0.0443 0.0362 0.0315 0.0290 0.0276 0.0264 0.0255 0.0248 0.0243 0.0240 0.0237 0.0236 0.0236 0.0236 

[TRAIN] Epoch[1](117/375); Loss: 0.041883; Backpropagation: 0.2884 sec; Batch: 2.0807 sec
0.0892 0.0725 0.0545 0.0472 0.0419 0.0388 0.0368 0.0352 0.0338 0.0329 0.0321 0.0316 0.0312 0.0310 0.0308 0.0307 

[TRAIN] Epoch[1](118/375); Loss: 0.045813; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0984 0.0762 0.0598 0.0505 0.0457 0.0429 0.0406 0.0387 0.0374 0.0364 0.0355 0.0349 0.0345 0.0341 0.0339 0.0336 

[TRAIN] Epoch[1](119/375); Loss: 0.059290; Backpropagation: 0.2885 sec; Batch: 2.0783 sec
0.1192 0.0947 0.0725 0.0641 0.0595 0.0561 0.0534 0.0512 0.0497 0.0487 0.0479 0.0472 0.0466 0.0462 0.0459 0.0457 

[TRAIN] Epoch[1](120/375); Loss: 0.045987; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1008 0.0785 0.0616 0.0514 0.0464 0.0429 0.0405 0.0386 0.0371 0.0359 0.0350 0.0343 0.0337 0.0333 0.0331 0.0328 

[TRAIN] Epoch[1](121/375); Loss: 0.045516; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0971 0.0785 0.0620 0.0517 0.0461 0.0426 0.0401 0.0381 0.0366 0.0355 0.0344 0.0338 0.0334 0.0331 0.0327 0.0325 

[TRAIN] Epoch[1](122/375); Loss: 0.052862; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.1018 0.0823 0.0642 0.0575 0.0537 0.0507 0.0482 0.0463 0.0449 0.0439 0.0432 0.0426 0.0421 0.0418 0.0415 0.0413 

[TRAIN] Epoch[1](123/375); Loss: 0.040332; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0831 0.0686 0.0524 0.0456 0.0407 0.0368 0.0350 0.0338 0.0328 0.0322 0.0317 0.0312 0.0308 0.0304 0.0302 0.0301 

[TRAIN] Epoch[1](124/375); Loss: 0.056428; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1013 0.0817 0.0678 0.0616 0.0571 0.0538 0.0518 0.0502 0.0491 0.0483 0.0476 0.0471 0.0468 0.0464 0.0462 0.0461 

[TRAIN] Epoch[1](125/375); Loss: 0.053729; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.1190 0.0934 0.0693 0.0580 0.0518 0.0487 0.0463 0.0446 0.0432 0.0424 0.0416 0.0411 0.0406 0.0402 0.0399 0.0397 

[TRAIN] Epoch[1](126/375); Loss: 0.042145; Backpropagation: 0.2879 sec; Batch: 2.0729 sec
0.0835 0.0659 0.0531 0.0468 0.0429 0.0401 0.0380 0.0364 0.0356 0.0347 0.0339 0.0333 0.0329 0.0326 0.0324 0.0322 

[TRAIN] Epoch[1](127/375); Loss: 0.053057; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1126 0.0845 0.0654 0.0570 0.0525 0.0492 0.0472 0.0457 0.0443 0.0432 0.0423 0.0418 0.0413 0.0410 0.0406 0.0404 

[TRAIN] Epoch[1](128/375); Loss: 0.046467; Backpropagation: 0.2882 sec; Batch: 2.0737 sec
0.1006 0.0763 0.0554 0.0489 0.0448 0.0423 0.0405 0.0394 0.0383 0.0376 0.0372 0.0368 0.0366 0.0364 0.0362 0.0362 

[TRAIN] Epoch[1](129/375); Loss: 0.042304; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1002 0.0655 0.0519 0.0458 0.0417 0.0385 0.0366 0.0352 0.0342 0.0335 0.0330 0.0326 0.0323 0.0321 0.0320 0.0319 

[TRAIN] Epoch[1](130/375); Loss: 0.054353; Backpropagation: 0.2883 sec; Batch: 2.0775 sec
0.1081 0.0865 0.0697 0.0607 0.0551 0.0519 0.0493 0.0473 0.0455 0.0442 0.0432 0.0425 0.0419 0.0415 0.0413 0.0411 

[TRAIN] Epoch[1](131/375); Loss: 0.051218; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.1023 0.0779 0.0640 0.0571 0.0517 0.0486 0.0464 0.0446 0.0432 0.0421 0.0413 0.0407 0.0403 0.0400 0.0397 0.0395 

[TRAIN] Epoch[1](132/375); Loss: 0.072914; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.1224 0.1015 0.0881 0.0804 0.0752 0.0713 0.0684 0.0663 0.0646 0.0632 0.0623 0.0615 0.0609 0.0604 0.0602 0.0600 

[TRAIN] Epoch[1](133/375); Loss: 0.060773; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1276 0.0954 0.0783 0.0698 0.0632 0.0578 0.0541 0.0515 0.0497 0.0484 0.0474 0.0467 0.0461 0.0457 0.0454 0.0452 

[TRAIN] Epoch[1](134/375); Loss: 0.047810; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1091 0.0781 0.0613 0.0512 0.0459 0.0430 0.0412 0.0398 0.0388 0.0379 0.0373 0.0368 0.0365 0.0362 0.0360 0.0358 

[TRAIN] Epoch[1](135/375); Loss: 0.042422; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.0897 0.0663 0.0546 0.0467 0.0425 0.0398 0.0379 0.0364 0.0351 0.0341 0.0335 0.0330 0.0326 0.0324 0.0321 0.0319 

[TRAIN] Epoch[1](136/375); Loss: 0.051656; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.1059 0.0802 0.0654 0.0572 0.0518 0.0484 0.0461 0.0445 0.0432 0.0422 0.0414 0.0407 0.0403 0.0399 0.0397 0.0395 

[TRAIN] Epoch[1](137/375); Loss: 0.042684; Backpropagation: 0.2883 sec; Batch: 2.0726 sec
0.0834 0.0643 0.0511 0.0458 0.0425 0.0403 0.0388 0.0374 0.0364 0.0356 0.0352 0.0348 0.0346 0.0344 0.0342 0.0341 

[TRAIN] Epoch[1](138/375); Loss: 0.052255; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.0977 0.0777 0.0642 0.0569 0.0526 0.0500 0.0479 0.0464 0.0451 0.0440 0.0433 0.0427 0.0423 0.0420 0.0418 0.0416 

[TRAIN] Epoch[1](139/375); Loss: 0.043194; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.0707 0.0563 0.0506 0.0462 0.0435 0.0418 0.0407 0.0397 0.0389 0.0384 0.0379 0.0376 0.0374 0.0372 0.0371 0.0370 

[TRAIN] Epoch[1](140/375); Loss: 0.049118; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1021 0.0809 0.0640 0.0552 0.0499 0.0465 0.0439 0.0418 0.0403 0.0390 0.0381 0.0375 0.0370 0.0367 0.0365 0.0363 

[TRAIN] Epoch[1](141/375); Loss: 0.043520; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0943 0.0713 0.0587 0.0501 0.0451 0.0414 0.0386 0.0367 0.0351 0.0339 0.0330 0.0324 0.0319 0.0315 0.0312 0.0310 

[TRAIN] Epoch[1](142/375); Loss: 0.044696; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0833 0.0700 0.0569 0.0489 0.0451 0.0423 0.0404 0.0392 0.0380 0.0371 0.0365 0.0360 0.0356 0.0354 0.0353 0.0352 

[TRAIN] Epoch[1](143/375); Loss: 0.057309; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1057 0.0821 0.0701 0.0631 0.0588 0.0549 0.0524 0.0505 0.0494 0.0485 0.0479 0.0474 0.0470 0.0466 0.0464 0.0461 

[TRAIN] Epoch[1](144/375); Loss: 0.049779; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.1073 0.0812 0.0629 0.0520 0.0514 0.0493 0.0457 0.0424 0.0402 0.0391 0.0385 0.0379 0.0375 0.0372 0.0370 0.0367 

[TRAIN] Epoch[1](145/375); Loss: 0.050645; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0969 0.0719 0.0615 0.0561 0.0516 0.0485 0.0463 0.0447 0.0436 0.0427 0.0420 0.0415 0.0411 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](146/375); Loss: 0.036509; Backpropagation: 0.2888 sec; Batch: 2.0793 sec
0.0847 0.0609 0.0476 0.0398 0.0358 0.0334 0.0314 0.0301 0.0290 0.0283 0.0278 0.0274 0.0272 0.0270 0.0269 0.0268 

[TRAIN] Epoch[1](147/375); Loss: 0.046741; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1239 0.0815 0.0573 0.0464 0.0429 0.0407 0.0389 0.0377 0.0368 0.0359 0.0352 0.0347 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[1](148/375); Loss: 0.054736; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0951 0.0746 0.0635 0.0586 0.0556 0.0531 0.0512 0.0499 0.0487 0.0478 0.0471 0.0466 0.0464 0.0460 0.0458 0.0457 

[TRAIN] Epoch[1](149/375); Loss: 0.053848; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0971 0.0782 0.0651 0.0589 0.0553 0.0523 0.0499 0.0481 0.0468 0.0458 0.0451 0.0445 0.0441 0.0437 0.0435 0.0433 

[TRAIN] Epoch[1](150/375); Loss: 0.035699; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0820 0.0578 0.0435 0.0377 0.0348 0.0327 0.0311 0.0300 0.0290 0.0284 0.0280 0.0276 0.0274 0.0272 0.0270 0.0269 

[TRAIN] Epoch[1](151/375); Loss: 0.032389; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0617 0.0436 0.0369 0.0332 0.0316 0.0304 0.0296 0.0290 0.0285 0.0282 0.0279 0.0277 0.0276 0.0275 0.0275 0.0274 

[TRAIN] Epoch[1](152/375); Loss: 0.039963; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0816 0.0582 0.0497 0.0440 0.0410 0.0388 0.0367 0.0351 0.0339 0.0330 0.0322 0.0317 0.0312 0.0310 0.0307 0.0305 

[TRAIN] Epoch[1](153/375); Loss: 0.061423; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1174 0.0887 0.0739 0.0662 0.0617 0.0587 0.0565 0.0547 0.0532 0.0521 0.0513 0.0505 0.0500 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](154/375); Loss: 0.041649; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0931 0.0645 0.0511 0.0453 0.0416 0.0387 0.0367 0.0352 0.0341 0.0334 0.0328 0.0325 0.0322 0.0320 0.0318 0.0316 

[TRAIN] Epoch[1](155/375); Loss: 0.054269; Backpropagation: 0.2882 sec; Batch: 2.0733 sec
0.1007 0.0778 0.0644 0.0580 0.0547 0.0519 0.0501 0.0485 0.0472 0.0463 0.0456 0.0452 0.0448 0.0445 0.0444 0.0442 

[TRAIN] Epoch[1](156/375); Loss: 0.041303; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0830 0.0626 0.0517 0.0450 0.0416 0.0390 0.0372 0.0358 0.0348 0.0340 0.0335 0.0331 0.0327 0.0325 0.0323 0.0322 

[TRAIN] Epoch[1](157/375); Loss: 0.043959; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0924 0.0669 0.0561 0.0484 0.0440 0.0409 0.0388 0.0373 0.0364 0.0357 0.0351 0.0348 0.0345 0.0342 0.0340 0.0339 

[TRAIN] Epoch[1](158/375); Loss: 0.049438; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1095 0.0745 0.0608 0.0535 0.0495 0.0464 0.0442 0.0426 0.0412 0.0402 0.0394 0.0386 0.0381 0.0378 0.0375 0.0373 

[TRAIN] Epoch[1](159/375); Loss: 0.033107; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.0679 0.0505 0.0421 0.0370 0.0338 0.0314 0.0297 0.0283 0.0275 0.0268 0.0263 0.0260 0.0258 0.0256 0.0255 0.0254 

[TRAIN] Epoch[1](160/375); Loss: 0.048213; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.0974 0.0722 0.0591 0.0525 0.0485 0.0457 0.0437 0.0421 0.0408 0.0400 0.0393 0.0387 0.0383 0.0379 0.0376 0.0375 

[TRAIN] Epoch[1](161/375); Loss: 0.035960; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0721 0.0559 0.0456 0.0396 0.0363 0.0339 0.0321 0.0308 0.0300 0.0293 0.0289 0.0285 0.0283 0.0281 0.0280 0.0279 

[TRAIN] Epoch[1](162/375); Loss: 0.049349; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1036 0.0702 0.0592 0.0525 0.0489 0.0464 0.0446 0.0431 0.0420 0.0411 0.0405 0.0400 0.0397 0.0395 0.0393 0.0391 

[TRAIN] Epoch[1](163/375); Loss: 0.046318; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0964 0.0725 0.0602 0.0518 0.0472 0.0441 0.0416 0.0399 0.0384 0.0374 0.0365 0.0358 0.0352 0.0349 0.0346 0.0345 

[TRAIN] Epoch[1](164/375); Loss: 0.030920; Backpropagation: 0.2884 sec; Batch: 2.0791 sec
0.0774 0.0520 0.0392 0.0328 0.0301 0.0279 0.0263 0.0252 0.0243 0.0237 0.0232 0.0229 0.0227 0.0225 0.0223 0.0222 

[TRAIN] Epoch[1](165/375); Loss: 0.051680; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1064 0.0801 0.0652 0.0569 0.0521 0.0488 0.0465 0.0446 0.0431 0.0421 0.0412 0.0407 0.0403 0.0399 0.0396 0.0394 

[TRAIN] Epoch[1](166/375); Loss: 0.050250; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1094 0.0834 0.0653 0.0555 0.0498 0.0464 0.0441 0.0421 0.0407 0.0396 0.0389 0.0384 0.0380 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](167/375); Loss: 0.044948; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.1014 0.0670 0.0551 0.0481 0.0443 0.0417 0.0398 0.0383 0.0371 0.0363 0.0358 0.0353 0.0350 0.0348 0.0346 0.0344 

[TRAIN] Epoch[1](168/375); Loss: 0.035383; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0785 0.0572 0.0439 0.0374 0.0340 0.0318 0.0305 0.0297 0.0290 0.0285 0.0281 0.0278 0.0276 0.0274 0.0273 0.0272 

[TRAIN] Epoch[1](169/375); Loss: 0.034781; Backpropagation: 0.2889 sec; Batch: 2.0735 sec
0.0693 0.0535 0.0442 0.0387 0.0351 0.0330 0.0312 0.0300 0.0291 0.0285 0.0280 0.0276 0.0273 0.0271 0.0270 0.0269 

[TRAIN] Epoch[1](170/375); Loss: 0.045390; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0893 0.0690 0.0579 0.0508 0.0466 0.0435 0.0412 0.0395 0.0383 0.0373 0.0365 0.0359 0.0355 0.0352 0.0350 0.0348 

[TRAIN] Epoch[1](171/375); Loss: 0.031835; Backpropagation: 0.2889 sec; Batch: 2.0760 sec
0.0784 0.0491 0.0398 0.0347 0.0307 0.0286 0.0273 0.0263 0.0256 0.0250 0.0246 0.0242 0.0240 0.0239 0.0238 0.0237 

[TRAIN] Epoch[1](172/375); Loss: 0.045971; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0909 0.0700 0.0563 0.0495 0.0456 0.0430 0.0412 0.0398 0.0390 0.0383 0.0377 0.0373 0.0370 0.0368 0.0366 0.0365 

[TRAIN] Epoch[1](173/375); Loss: 0.041438; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0925 0.0662 0.0521 0.0457 0.0417 0.0389 0.0367 0.0351 0.0339 0.0330 0.0322 0.0317 0.0313 0.0310 0.0307 0.0305 

[TRAIN] Epoch[1](174/375); Loss: 0.052952; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1009 0.0769 0.0644 0.0581 0.0547 0.0515 0.0489 0.0469 0.0453 0.0443 0.0436 0.0430 0.0426 0.0423 0.0420 0.0418 

[TRAIN] Epoch[1](175/375); Loss: 0.045643; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0958 0.0696 0.0575 0.0504 0.0462 0.0434 0.0409 0.0393 0.0380 0.0371 0.0364 0.0358 0.0354 0.0350 0.0347 0.0345 

[TRAIN] Epoch[1](176/375); Loss: 0.046510; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0865 0.0661 0.0558 0.0499 0.0468 0.0446 0.0427 0.0414 0.0405 0.0397 0.0392 0.0388 0.0384 0.0381 0.0379 0.0378 

[TRAIN] Epoch[1](177/375); Loss: 0.037190; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.0771 0.0538 0.0439 0.0394 0.0368 0.0351 0.0336 0.0324 0.0316 0.0310 0.0305 0.0302 0.0301 0.0299 0.0298 0.0298 

[TRAIN] Epoch[1](178/375); Loss: 0.047336; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0886 0.0681 0.0572 0.0509 0.0475 0.0453 0.0435 0.0421 0.0411 0.0402 0.0396 0.0391 0.0388 0.0386 0.0384 0.0383 

[TRAIN] Epoch[1](179/375); Loss: 0.056511; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1207 0.0880 0.0738 0.0636 0.0572 0.0531 0.0501 0.0480 0.0466 0.0453 0.0443 0.0436 0.0431 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](180/375); Loss: 0.040419; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0905 0.0628 0.0486 0.0428 0.0394 0.0372 0.0355 0.0343 0.0335 0.0329 0.0323 0.0319 0.0315 0.0313 0.0311 0.0310 

[TRAIN] Epoch[1](181/375); Loss: 0.052259; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.0989 0.0740 0.0628 0.0558 0.0522 0.0494 0.0479 0.0465 0.0455 0.0447 0.0440 0.0435 0.0431 0.0428 0.0427 0.0425 

[TRAIN] Epoch[1](182/375); Loss: 0.047279; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.0924 0.0703 0.0588 0.0521 0.0482 0.0455 0.0432 0.0416 0.0403 0.0393 0.0384 0.0378 0.0375 0.0372 0.0369 0.0368 

[TRAIN] Epoch[1](183/375); Loss: 0.056265; Backpropagation: 0.2883 sec; Batch: 2.0759 sec
0.1038 0.0830 0.0682 0.0615 0.0577 0.0545 0.0521 0.0503 0.0487 0.0476 0.0467 0.0460 0.0455 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](184/375); Loss: 0.047082; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1021 0.0727 0.0612 0.0518 0.0471 0.0440 0.0418 0.0401 0.0389 0.0379 0.0370 0.0364 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[1](185/375); Loss: 0.059118; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1118 0.0834 0.0706 0.0643 0.0600 0.0568 0.0544 0.0527 0.0513 0.0502 0.0493 0.0489 0.0485 0.0482 0.0479 0.0477 

[TRAIN] Epoch[1](186/375); Loss: 0.031405; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.0660 0.0485 0.0381 0.0344 0.0315 0.0297 0.0282 0.0271 0.0263 0.0257 0.0252 0.0248 0.0245 0.0243 0.0242 0.0241 

[TRAIN] Epoch[1](187/375); Loss: 0.033566; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0813 0.0544 0.0434 0.0364 0.0330 0.0304 0.0288 0.0276 0.0268 0.0261 0.0256 0.0251 0.0248 0.0246 0.0245 0.0244 

[TRAIN] Epoch[1](188/375); Loss: 0.055682; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1147 0.0853 0.0714 0.0638 0.0572 0.0530 0.0503 0.0480 0.0463 0.0448 0.0439 0.0432 0.0427 0.0423 0.0421 0.0419 

[TRAIN] Epoch[1](189/375); Loss: 0.045343; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.1051 0.0724 0.0562 0.0488 0.0447 0.0420 0.0397 0.0381 0.0369 0.0360 0.0353 0.0347 0.0342 0.0339 0.0337 0.0335 

[TRAIN] Epoch[1](190/375); Loss: 0.037979; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0870 0.0615 0.0479 0.0416 0.0372 0.0344 0.0328 0.0316 0.0309 0.0301 0.0296 0.0291 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](191/375); Loss: 0.050896; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0925 0.0704 0.0602 0.0554 0.0520 0.0496 0.0477 0.0462 0.0448 0.0439 0.0431 0.0424 0.0420 0.0416 0.0414 0.0413 

[TRAIN] Epoch[1](192/375); Loss: 0.051531; Backpropagation: 0.2879 sec; Batch: 2.0745 sec
0.0927 0.0712 0.0605 0.0551 0.0518 0.0495 0.0478 0.0465 0.0455 0.0447 0.0441 0.0437 0.0433 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](193/375); Loss: 0.047055; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0982 0.0740 0.0599 0.0531 0.0477 0.0443 0.0423 0.0403 0.0389 0.0379 0.0371 0.0365 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[1](194/375); Loss: 0.049031; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.0941 0.0733 0.0606 0.0543 0.0507 0.0477 0.0453 0.0433 0.0419 0.0409 0.0401 0.0393 0.0388 0.0384 0.0381 0.0379 

[TRAIN] Epoch[1](195/375); Loss: 0.061732; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1202 0.0918 0.0768 0.0690 0.0637 0.0601 0.0571 0.0546 0.0526 0.0511 0.0500 0.0492 0.0485 0.0481 0.0477 0.0473 

[TRAIN] Epoch[1](196/375); Loss: 0.033308; Backpropagation: 0.2883 sec; Batch: 2.0804 sec
0.0767 0.0491 0.0414 0.0370 0.0338 0.0312 0.0293 0.0281 0.0273 0.0265 0.0261 0.0257 0.0254 0.0252 0.0251 0.0250 

[TRAIN] Epoch[1](197/375); Loss: 0.050695; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.1119 0.0802 0.0632 0.0551 0.0506 0.0473 0.0449 0.0431 0.0418 0.0406 0.0399 0.0393 0.0388 0.0384 0.0381 0.0379 

[TRAIN] Epoch[1](198/375); Loss: 0.042204; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0742 0.0591 0.0516 0.0462 0.0429 0.0406 0.0391 0.0379 0.0370 0.0363 0.0358 0.0354 0.0351 0.0349 0.0347 0.0346 

[TRAIN] Epoch[1](199/375); Loss: 0.044091; Backpropagation: 0.2884 sec; Batch: 2.0747 sec
0.1102 0.0744 0.0589 0.0479 0.0432 0.0402 0.0378 0.0359 0.0344 0.0333 0.0325 0.0319 0.0315 0.0312 0.0311 0.0309 

[TRAIN] Epoch[1](200/375); Loss: 0.043357; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.1004 0.0659 0.0498 0.0445 0.0414 0.0392 0.0379 0.0368 0.0360 0.0354 0.0349 0.0346 0.0344 0.0342 0.0342 0.0341 

[TRAIN] Epoch[1](201/375); Loss: 0.050488; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.0983 0.0750 0.0624 0.0558 0.0514 0.0487 0.0463 0.0446 0.0432 0.0421 0.0413 0.0406 0.0400 0.0397 0.0393 0.0391 

[TRAIN] Epoch[1](202/375); Loss: 0.041908; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1068 0.0713 0.0521 0.0448 0.0400 0.0369 0.0351 0.0337 0.0327 0.0320 0.0315 0.0311 0.0308 0.0307 0.0306 0.0305 

[TRAIN] Epoch[1](203/375); Loss: 0.047155; Backpropagation: 0.2888 sec; Batch: 2.0764 sec
0.0862 0.0663 0.0569 0.0514 0.0479 0.0456 0.0438 0.0424 0.0412 0.0403 0.0397 0.0392 0.0388 0.0385 0.0382 0.0381 

[TRAIN] Epoch[1](204/375); Loss: 0.055513; Backpropagation: 0.2881 sec; Batch: 2.0754 sec
0.1254 0.0917 0.0709 0.0603 0.0557 0.0521 0.0491 0.0468 0.0450 0.0435 0.0426 0.0418 0.0413 0.0409 0.0407 0.0404 

[TRAIN] Epoch[1](205/375); Loss: 0.054473; Backpropagation: 0.2886 sec; Batch: 2.0767 sec
0.1189 0.0862 0.0693 0.0611 0.0554 0.0516 0.0485 0.0461 0.0443 0.0432 0.0424 0.0417 0.0412 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](206/375); Loss: 0.055254; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1094 0.0861 0.0687 0.0598 0.0556 0.0521 0.0499 0.0479 0.0464 0.0455 0.0448 0.0442 0.0438 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](207/375); Loss: 0.062753; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.1252 0.0962 0.0778 0.0686 0.0634 0.0596 0.0565 0.0544 0.0529 0.0518 0.0509 0.0502 0.0496 0.0492 0.0489 0.0487 

[TRAIN] Epoch[1](208/375); Loss: 0.050947; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.1012 0.0769 0.0594 0.0543 0.0501 0.0476 0.0458 0.0444 0.0435 0.0428 0.0422 0.0418 0.0416 0.0413 0.0412 0.0410 

[TRAIN] Epoch[1](209/375); Loss: 0.057132; Backpropagation: 0.2886 sec; Batch: 2.0756 sec
0.1268 0.0861 0.0698 0.0632 0.0579 0.0540 0.0509 0.0486 0.0470 0.0460 0.0452 0.0446 0.0440 0.0436 0.0433 0.0431 

[TRAIN] Epoch[1](210/375); Loss: 0.044719; Backpropagation: 0.2884 sec; Batch: 2.0797 sec
0.1075 0.0752 0.0541 0.0472 0.0432 0.0403 0.0385 0.0370 0.0358 0.0350 0.0345 0.0340 0.0336 0.0334 0.0332 0.0331 

[TRAIN] Epoch[1](211/375); Loss: 0.060467; Backpropagation: 0.2882 sec; Batch: 2.0759 sec
0.1319 0.1006 0.0779 0.0674 0.0605 0.0559 0.0529 0.0506 0.0490 0.0478 0.0469 0.0462 0.0456 0.0451 0.0447 0.0445 

[TRAIN] Epoch[1](212/375); Loss: 0.045574; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1001 0.0700 0.0570 0.0501 0.0452 0.0426 0.0405 0.0389 0.0375 0.0367 0.0361 0.0355 0.0351 0.0348 0.0346 0.0344 

[TRAIN] Epoch[1](213/375); Loss: 0.035513; Backpropagation: 0.2879 sec; Batch: 2.0750 sec
0.0834 0.0568 0.0443 0.0382 0.0347 0.0327 0.0310 0.0296 0.0287 0.0281 0.0275 0.0271 0.0268 0.0266 0.0264 0.0263 

[TRAIN] Epoch[1](214/375); Loss: 0.034057; Backpropagation: 0.2884 sec; Batch: 2.0804 sec
0.0997 0.0685 0.0458 0.0356 0.0308 0.0285 0.0268 0.0255 0.0245 0.0238 0.0232 0.0229 0.0226 0.0224 0.0222 0.0221 

[TRAIN] Epoch[1](215/375); Loss: 0.057666; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1109 0.0821 0.0697 0.0630 0.0584 0.0554 0.0528 0.0510 0.0497 0.0488 0.0479 0.0474 0.0469 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](216/375); Loss: 0.055925; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1150 0.0839 0.0690 0.0597 0.0555 0.0523 0.0502 0.0487 0.0473 0.0463 0.0455 0.0450 0.0445 0.0442 0.0440 0.0438 

[TRAIN] Epoch[1](217/375); Loss: 0.058728; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.1086 0.0846 0.0726 0.0640 0.0590 0.0561 0.0538 0.0520 0.0508 0.0499 0.0491 0.0486 0.0481 0.0477 0.0474 0.0472 

[TRAIN] Epoch[1](218/375); Loss: 0.043192; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.0977 0.0692 0.0532 0.0461 0.0421 0.0396 0.0376 0.0362 0.0352 0.0345 0.0340 0.0336 0.0333 0.0331 0.0329 0.0328 

[TRAIN] Epoch[1](219/375); Loss: 0.063278; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.1353 0.1010 0.0744 0.0658 0.0609 0.0574 0.0555 0.0541 0.0528 0.0520 0.0513 0.0509 0.0505 0.0503 0.0501 0.0500 

[TRAIN] Epoch[1](220/375); Loss: 0.046528; Backpropagation: 0.2881 sec; Batch: 2.0755 sec
0.0994 0.0851 0.0676 0.0582 0.0508 0.0450 0.0402 0.0368 0.0347 0.0336 0.0329 0.0325 0.0321 0.0319 0.0318 0.0317 

[TRAIN] Epoch[1](221/375); Loss: 0.036250; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.1053 0.0644 0.0477 0.0397 0.0345 0.0314 0.0294 0.0281 0.0269 0.0260 0.0253 0.0249 0.0244 0.0241 0.0239 0.0238 

[TRAIN] Epoch[1](222/375); Loss: 0.050286; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1322 0.1082 0.0795 0.0624 0.0493 0.0420 0.0384 0.0363 0.0348 0.0337 0.0327 0.0320 0.0313 0.0309 0.0305 0.0303 

[TRAIN] Epoch[1](223/375); Loss: 0.060933; Backpropagation: 0.2881 sec; Batch: 2.0754 sec
0.1336 0.1066 0.0831 0.0709 0.0625 0.0574 0.0534 0.0501 0.0480 0.0467 0.0456 0.0446 0.0438 0.0433 0.0429 0.0425 

[TRAIN] Epoch[1](224/375); Loss: 0.054843; Backpropagation: 0.2882 sec; Batch: 2.0818 sec
0.1042 0.0826 0.0679 0.0601 0.0554 0.0524 0.0499 0.0482 0.0469 0.0459 0.0451 0.0445 0.0440 0.0437 0.0434 0.0433 

[TRAIN] Epoch[1](225/375); Loss: 0.058565; Backpropagation: 0.2884 sec; Batch: 2.0773 sec
0.1164 0.0950 0.0766 0.0661 0.0592 0.0549 0.0522 0.0501 0.0486 0.0474 0.0465 0.0457 0.0451 0.0447 0.0444 0.0443 

[TRAIN] Epoch[1](226/375); Loss: 0.044906; Backpropagation: 0.2881 sec; Batch: 2.0753 sec
0.1279 0.0743 0.0537 0.0469 0.0422 0.0393 0.0372 0.0357 0.0347 0.0338 0.0331 0.0326 0.0321 0.0319 0.0316 0.0315 

[TRAIN] Epoch[1](227/375); Loss: 0.054552; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.1261 0.1087 0.0786 0.0639 0.0510 0.0447 0.0421 0.0414 0.0407 0.0402 0.0398 0.0394 0.0392 0.0390 0.0390 0.0389 

[TRAIN] Epoch[1](228/375); Loss: 0.067839; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1355 0.1125 0.0862 0.0745 0.0670 0.0637 0.0605 0.0583 0.0566 0.0550 0.0540 0.0531 0.0526 0.0522 0.0519 0.0517 

[TRAIN] Epoch[1](229/375); Loss: 0.056721; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.1061 0.0863 0.0710 0.0628 0.0569 0.0537 0.0517 0.0499 0.0485 0.0475 0.0466 0.0461 0.0456 0.0452 0.0450 0.0448 

[TRAIN] Epoch[1](230/375); Loss: 0.040742; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1099 0.0859 0.0603 0.0491 0.0399 0.0345 0.0309 0.0296 0.0282 0.0274 0.0269 0.0263 0.0260 0.0258 0.0256 0.0254 

[TRAIN] Epoch[1](231/375); Loss: 0.043244; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1105 0.0789 0.0591 0.0495 0.0425 0.0385 0.0360 0.0341 0.0328 0.0319 0.0310 0.0303 0.0297 0.0293 0.0290 0.0288 

[TRAIN] Epoch[1](232/375); Loss: 0.058614; Backpropagation: 0.2886 sec; Batch: 2.0750 sec
0.1173 0.0935 0.0758 0.0661 0.0596 0.0553 0.0524 0.0500 0.0484 0.0473 0.0464 0.0458 0.0453 0.0450 0.0449 0.0447 

[TRAIN] Epoch[1](233/375); Loss: 0.062727; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1380 0.1065 0.0823 0.0693 0.0614 0.0571 0.0544 0.0524 0.0508 0.0495 0.0484 0.0477 0.0470 0.0466 0.0463 0.0460 

[TRAIN] Epoch[1](234/375); Loss: 0.044592; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1288 0.0964 0.0674 0.0502 0.0397 0.0343 0.0327 0.0314 0.0305 0.0298 0.0294 0.0290 0.0287 0.0285 0.0283 0.0282 

[TRAIN] Epoch[1](235/375); Loss: 0.048488; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1111 0.0840 0.0650 0.0538 0.0478 0.0440 0.0416 0.0398 0.0385 0.0374 0.0366 0.0360 0.0355 0.0352 0.0349 0.0347 

[TRAIN] Epoch[1](236/375); Loss: 0.042915; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.1063 0.0834 0.0610 0.0511 0.0429 0.0383 0.0351 0.0331 0.0316 0.0306 0.0298 0.0293 0.0289 0.0286 0.0283 0.0282 

[TRAIN] Epoch[1](237/375); Loss: 0.029810; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0811 0.0531 0.0375 0.0320 0.0280 0.0261 0.0245 0.0236 0.0228 0.0221 0.0216 0.0213 0.0210 0.0208 0.0207 0.0206 

[TRAIN] Epoch[1](238/375); Loss: 0.044323; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0948 0.0762 0.0596 0.0505 0.0454 0.0415 0.0388 0.0370 0.0356 0.0345 0.0336 0.0330 0.0325 0.0322 0.0320 0.0319 

[TRAIN] Epoch[1](239/375); Loss: 0.048301; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.1100 0.0871 0.0654 0.0555 0.0480 0.0440 0.0409 0.0389 0.0376 0.0367 0.0358 0.0352 0.0348 0.0345 0.0343 0.0342 

[TRAIN] Epoch[1](240/375); Loss: 0.048429; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1068 0.0872 0.0690 0.0579 0.0493 0.0442 0.0408 0.0386 0.0374 0.0365 0.0358 0.0351 0.0346 0.0342 0.0338 0.0336 

[TRAIN] Epoch[1](241/375); Loss: 0.052204; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1273 0.0955 0.0724 0.0586 0.0509 0.0465 0.0434 0.0411 0.0396 0.0386 0.0379 0.0374 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[1](242/375); Loss: 0.072534; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.1276 0.1085 0.0921 0.0833 0.0771 0.0725 0.0685 0.0653 0.0627 0.0609 0.0592 0.0580 0.0571 0.0564 0.0559 0.0555 

[TRAIN] Epoch[1](243/375); Loss: 0.048357; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0877 0.0738 0.0592 0.0530 0.0490 0.0463 0.0442 0.0429 0.0418 0.0409 0.0402 0.0396 0.0392 0.0389 0.0386 0.0384 

[TRAIN] Epoch[1](244/375); Loss: 0.055971; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.1190 0.0906 0.0675 0.0598 0.0552 0.0528 0.0498 0.0479 0.0464 0.0452 0.0445 0.0440 0.0435 0.0433 0.0431 0.0429 

[TRAIN] Epoch[1](245/375); Loss: 0.050875; Backpropagation: 0.2885 sec; Batch: 2.0812 sec
0.1245 0.0919 0.0694 0.0571 0.0495 0.0457 0.0430 0.0411 0.0396 0.0382 0.0371 0.0363 0.0357 0.0354 0.0350 0.0347 

[TRAIN] Epoch[1](246/375); Loss: 0.061691; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.1417 0.1043 0.0787 0.0654 0.0595 0.0555 0.0526 0.0506 0.0495 0.0484 0.0477 0.0473 0.0469 0.0465 0.0463 0.0462 

[TRAIN] Epoch[1](247/375); Loss: 0.038639; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0916 0.0668 0.0519 0.0440 0.0384 0.0351 0.0330 0.0313 0.0301 0.0292 0.0286 0.0281 0.0278 0.0276 0.0274 0.0273 

[TRAIN] Epoch[1](248/375); Loss: 0.046239; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1034 0.0770 0.0594 0.0514 0.0458 0.0425 0.0405 0.0389 0.0375 0.0363 0.0355 0.0349 0.0345 0.0343 0.0341 0.0339 

[TRAIN] Epoch[1](249/375); Loss: 0.049810; Backpropagation: 0.2887 sec; Batch: 2.0755 sec
0.0983 0.0789 0.0621 0.0565 0.0513 0.0474 0.0448 0.0429 0.0417 0.0407 0.0399 0.0392 0.0387 0.0384 0.0382 0.0380 

[TRAIN] Epoch[1](250/375); Loss: 0.067219; Backpropagation: 0.2881 sec; Batch: 2.0751 sec
0.1215 0.0993 0.0822 0.0732 0.0679 0.0644 0.0619 0.0597 0.0582 0.0570 0.0562 0.0555 0.0550 0.0547 0.0544 0.0543 

[TRAIN] Epoch[1](251/375); Loss: 0.046014; Backpropagation: 0.2890 sec; Batch: 2.0751 sec
0.1084 0.0790 0.0584 0.0498 0.0440 0.0412 0.0394 0.0378 0.0368 0.0359 0.0352 0.0346 0.0343 0.0340 0.0338 0.0337 

[TRAIN] Epoch[1](252/375); Loss: 0.041987; Backpropagation: 0.2883 sec; Batch: 2.0757 sec
0.0810 0.0609 0.0496 0.0449 0.0417 0.0396 0.0382 0.0371 0.0362 0.0356 0.0351 0.0348 0.0345 0.0343 0.0342 0.0341 

[TRAIN] Epoch[1](253/375); Loss: 0.044783; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.0955 0.0717 0.0560 0.0479 0.0442 0.0415 0.0395 0.0382 0.0373 0.0364 0.0356 0.0351 0.0347 0.0344 0.0343 0.0342 

[TRAIN] Epoch[1](254/375); Loss: 0.052178; Backpropagation: 0.2887 sec; Batch: 2.0750 sec
0.0991 0.0757 0.0627 0.0570 0.0526 0.0500 0.0480 0.0463 0.0449 0.0440 0.0433 0.0428 0.0424 0.0422 0.0420 0.0419 

[TRAIN] Epoch[1](255/375); Loss: 0.057213; Backpropagation: 0.2884 sec; Batch: 2.0759 sec
0.1022 0.0779 0.0672 0.0622 0.0585 0.0557 0.0535 0.0518 0.0505 0.0495 0.0487 0.0482 0.0478 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](256/375); Loss: 0.038497; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0743 0.0555 0.0462 0.0415 0.0383 0.0364 0.0352 0.0340 0.0332 0.0326 0.0321 0.0317 0.0314 0.0313 0.0312 0.0310 

[TRAIN] Epoch[1](257/375); Loss: 0.067714; Backpropagation: 0.2887 sec; Batch: 2.0759 sec
0.1162 0.0915 0.0783 0.0719 0.0685 0.0661 0.0640 0.0621 0.0606 0.0595 0.0586 0.0580 0.0575 0.0571 0.0569 0.0566 

[TRAIN] Epoch[1](258/375); Loss: 0.048601; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0940 0.0714 0.0633 0.0557 0.0503 0.0470 0.0446 0.0426 0.0410 0.0399 0.0391 0.0385 0.0380 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](259/375); Loss: 0.051721; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.0958 0.0789 0.0619 0.0553 0.0521 0.0492 0.0473 0.0457 0.0445 0.0437 0.0431 0.0426 0.0422 0.0419 0.0417 0.0416 

[TRAIN] Epoch[1](260/375); Loss: 0.062764; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1203 0.0937 0.0762 0.0678 0.0633 0.0599 0.0571 0.0550 0.0537 0.0527 0.0519 0.0512 0.0507 0.0504 0.0502 0.0500 

[TRAIN] Epoch[1](261/375); Loss: 0.039670; Backpropagation: 0.2882 sec; Batch: 2.0749 sec
0.0788 0.0599 0.0489 0.0436 0.0402 0.0378 0.0361 0.0348 0.0336 0.0328 0.0322 0.0317 0.0314 0.0311 0.0310 0.0308 

[TRAIN] Epoch[1](262/375); Loss: 0.068241; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1165 0.0922 0.0819 0.0747 0.0699 0.0665 0.0639 0.0619 0.0605 0.0594 0.0585 0.0579 0.0574 0.0571 0.0568 0.0567 

[TRAIN] Epoch[1](263/375); Loss: 0.043529; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.0997 0.0644 0.0536 0.0475 0.0426 0.0403 0.0385 0.0371 0.0360 0.0352 0.0345 0.0340 0.0336 0.0334 0.0332 0.0330 

[TRAIN] Epoch[1](264/375); Loss: 0.037596; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.0873 0.0591 0.0470 0.0406 0.0373 0.0347 0.0330 0.0316 0.0306 0.0298 0.0292 0.0288 0.0284 0.0282 0.0280 0.0279 

[TRAIN] Epoch[1](265/375); Loss: 0.044288; Backpropagation: 0.2885 sec; Batch: 2.0846 sec
0.1000 0.0662 0.0544 0.0482 0.0440 0.0413 0.0393 0.0376 0.0366 0.0358 0.0351 0.0346 0.0342 0.0340 0.0337 0.0335 

[TRAIN] Epoch[1](266/375); Loss: 0.042416; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0881 0.0579 0.0486 0.0454 0.0418 0.0400 0.0385 0.0373 0.0364 0.0357 0.0354 0.0350 0.0348 0.0347 0.0346 0.0345 

[TRAIN] Epoch[1](267/375); Loss: 0.046280; Backpropagation: 0.2882 sec; Batch: 2.0807 sec
0.0855 0.0663 0.0573 0.0510 0.0473 0.0446 0.0428 0.0414 0.0402 0.0392 0.0384 0.0379 0.0375 0.0374 0.0371 0.0369 

[TRAIN] Epoch[1](268/375); Loss: 0.038291; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.0896 0.0595 0.0458 0.0393 0.0365 0.0344 0.0329 0.0320 0.0314 0.0309 0.0305 0.0303 0.0300 0.0298 0.0297 0.0297 

[TRAIN] Epoch[1](269/375); Loss: 0.039986; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.0668 0.0556 0.0493 0.0444 0.0412 0.0391 0.0376 0.0365 0.0354 0.0347 0.0341 0.0335 0.0332 0.0330 0.0328 0.0326 

[TRAIN] Epoch[1](270/375); Loss: 0.032602; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0755 0.0515 0.0395 0.0349 0.0321 0.0301 0.0286 0.0273 0.0265 0.0259 0.0255 0.0252 0.0250 0.0248 0.0247 0.0245 

[TRAIN] Epoch[1](271/375); Loss: 0.050966; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0987 0.0727 0.0610 0.0551 0.0515 0.0489 0.0469 0.0453 0.0440 0.0431 0.0424 0.0419 0.0415 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](272/375); Loss: 0.024703; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0641 0.0449 0.0327 0.0266 0.0233 0.0216 0.0204 0.0195 0.0188 0.0184 0.0180 0.0177 0.0175 0.0174 0.0173 0.0172 

[TRAIN] Epoch[1](273/375); Loss: 0.047353; Backpropagation: 0.2885 sec; Batch: 2.0763 sec
0.0987 0.0696 0.0554 0.0502 0.0472 0.0449 0.0430 0.0415 0.0403 0.0394 0.0388 0.0383 0.0379 0.0377 0.0374 0.0373 

[TRAIN] Epoch[1](274/375); Loss: 0.062792; Backpropagation: 0.2880 sec; Batch: 2.0751 sec
0.1331 0.0981 0.0795 0.0683 0.0620 0.0586 0.0559 0.0538 0.0522 0.0509 0.0500 0.0493 0.0488 0.0483 0.0480 0.0477 

[TRAIN] Epoch[1](275/375); Loss: 0.023707; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.0598 0.0399 0.0303 0.0257 0.0228 0.0211 0.0199 0.0191 0.0185 0.0180 0.0177 0.0175 0.0174 0.0172 0.0172 0.0171 

[TRAIN] Epoch[1](276/375); Loss: 0.048523; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.0946 0.0684 0.0577 0.0523 0.0483 0.0460 0.0444 0.0430 0.0420 0.0411 0.0406 0.0401 0.0398 0.0395 0.0393 0.0392 

[TRAIN] Epoch[1](277/375); Loss: 0.057446; Backpropagation: 0.2887 sec; Batch: 2.0755 sec
0.1143 0.0877 0.0704 0.0623 0.0578 0.0543 0.0519 0.0499 0.0487 0.0476 0.0468 0.0463 0.0458 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](278/375); Loss: 0.054155; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1045 0.0859 0.0679 0.0597 0.0545 0.0513 0.0486 0.0468 0.0456 0.0447 0.0439 0.0433 0.0428 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](279/375); Loss: 0.045590; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.0836 0.0675 0.0567 0.0503 0.0464 0.0441 0.0422 0.0406 0.0393 0.0384 0.0377 0.0372 0.0368 0.0364 0.0362 0.0359 

[TRAIN] Epoch[1](280/375); Loss: 0.045120; Backpropagation: 0.2886 sec; Batch: 2.0772 sec
0.0907 0.0679 0.0546 0.0486 0.0450 0.0427 0.0407 0.0393 0.0383 0.0376 0.0369 0.0365 0.0361 0.0359 0.0356 0.0355 

[TRAIN] Epoch[1](281/375); Loss: 0.041381; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0842 0.0673 0.0543 0.0470 0.0421 0.0388 0.0364 0.0350 0.0339 0.0331 0.0325 0.0320 0.0317 0.0314 0.0313 0.0311 

[TRAIN] Epoch[1](282/375); Loss: 0.053434; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1029 0.0769 0.0640 0.0577 0.0539 0.0510 0.0489 0.0473 0.0461 0.0452 0.0445 0.0439 0.0436 0.0432 0.0430 0.0429 

[TRAIN] Epoch[1](283/375); Loss: 0.034462; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.0835 0.0551 0.0429 0.0382 0.0345 0.0319 0.0298 0.0285 0.0275 0.0268 0.0263 0.0258 0.0255 0.0253 0.0250 0.0249 

[TRAIN] Epoch[1](284/375); Loss: 0.050643; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0931 0.0741 0.0633 0.0566 0.0524 0.0492 0.0468 0.0451 0.0438 0.0427 0.0418 0.0411 0.0406 0.0402 0.0398 0.0396 

[TRAIN] Epoch[1](285/375); Loss: 0.053295; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1154 0.0801 0.0649 0.0587 0.0542 0.0510 0.0484 0.0463 0.0446 0.0433 0.0423 0.0416 0.0410 0.0406 0.0403 0.0400 

[TRAIN] Epoch[1](286/375); Loss: 0.059938; Backpropagation: 0.2883 sec; Batch: 2.0789 sec
0.1070 0.0840 0.0718 0.0656 0.0616 0.0584 0.0561 0.0542 0.0527 0.0516 0.0505 0.0498 0.0493 0.0490 0.0488 0.0486 

[TRAIN] Epoch[1](287/375); Loss: 0.049639; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.1025 0.0743 0.0619 0.0542 0.0498 0.0469 0.0445 0.0427 0.0413 0.0404 0.0398 0.0394 0.0393 0.0391 0.0391 0.0392 

[TRAIN] Epoch[1](288/375); Loss: 0.049978; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0926 0.0677 0.0588 0.0538 0.0505 0.0480 0.0461 0.0447 0.0435 0.0428 0.0423 0.0420 0.0417 0.0416 0.0416 0.0417 

[TRAIN] Epoch[1](289/375); Loss: 0.042416; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0734 0.0602 0.0516 0.0463 0.0428 0.0405 0.0391 0.0379 0.0371 0.0365 0.0360 0.0357 0.0355 0.0354 0.0353 0.0353 

[TRAIN] Epoch[1](290/375); Loss: 0.053864; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1105 0.0801 0.0666 0.0599 0.0548 0.0510 0.0485 0.0467 0.0453 0.0442 0.0434 0.0428 0.0422 0.0421 0.0419 0.0418 

[TRAIN] Epoch[1](291/375); Loss: 0.052266; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0974 0.0755 0.0632 0.0568 0.0529 0.0500 0.0480 0.0464 0.0452 0.0443 0.0437 0.0431 0.0427 0.0425 0.0423 0.0422 

[TRAIN] Epoch[1](292/375); Loss: 0.033438; Backpropagation: 0.2881 sec; Batch: 2.0753 sec
0.0771 0.0512 0.0398 0.0349 0.0325 0.0310 0.0297 0.0286 0.0278 0.0271 0.0266 0.0262 0.0259 0.0257 0.0255 0.0254 

[TRAIN] Epoch[1](293/375); Loss: 0.061579; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1061 0.0862 0.0748 0.0675 0.0632 0.0602 0.0577 0.0558 0.0544 0.0532 0.0523 0.0517 0.0511 0.0507 0.0504 0.0501 

[TRAIN] Epoch[1](294/375); Loss: 0.044163; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1013 0.0701 0.0568 0.0498 0.0445 0.0412 0.0385 0.0367 0.0355 0.0345 0.0339 0.0334 0.0330 0.0327 0.0325 0.0324 

[TRAIN] Epoch[1](295/375); Loss: 0.032356; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0685 0.0498 0.0397 0.0346 0.0317 0.0298 0.0285 0.0275 0.0269 0.0265 0.0262 0.0259 0.0257 0.0255 0.0254 0.0254 

[TRAIN] Epoch[1](296/375); Loss: 0.043723; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0949 0.0651 0.0523 0.0465 0.0430 0.0405 0.0388 0.0377 0.0368 0.0360 0.0354 0.0350 0.0347 0.0345 0.0343 0.0342 

[TRAIN] Epoch[1](297/375); Loss: 0.048743; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1138 0.0774 0.0611 0.0525 0.0486 0.0452 0.0426 0.0408 0.0394 0.0385 0.0378 0.0371 0.0367 0.0363 0.0361 0.0358 

[TRAIN] Epoch[1](298/375); Loss: 0.066983; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1225 0.1007 0.0858 0.0744 0.0680 0.0639 0.0611 0.0591 0.0573 0.0561 0.0550 0.0544 0.0539 0.0534 0.0532 0.0529 

[TRAIN] Epoch[1](299/375); Loss: 0.053110; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1137 0.0919 0.0779 0.0666 0.0589 0.0529 0.0479 0.0434 0.0402 0.0386 0.0375 0.0367 0.0363 0.0359 0.0357 0.0356 

[TRAIN] Epoch[1](300/375); Loss: 0.045463; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.0812 0.0646 0.0537 0.0484 0.0453 0.0432 0.0418 0.0406 0.0399 0.0394 0.0389 0.0385 0.0382 0.0380 0.0379 0.0377 

[TRAIN] Epoch[1](301/375); Loss: 0.046005; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0976 0.0711 0.0589 0.0518 0.0466 0.0433 0.0409 0.0391 0.0378 0.0369 0.0363 0.0357 0.0354 0.0351 0.0349 0.0347 

[TRAIN] Epoch[1](302/375); Loss: 0.051391; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1010 0.0745 0.0618 0.0554 0.0516 0.0487 0.0468 0.0452 0.0441 0.0434 0.0427 0.0421 0.0417 0.0413 0.0411 0.0409 

[TRAIN] Epoch[1](303/375); Loss: 0.051381; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1002 0.0787 0.0665 0.0585 0.0531 0.0494 0.0466 0.0447 0.0430 0.0420 0.0411 0.0405 0.0399 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](304/375); Loss: 0.045883; Backpropagation: 0.2883 sec; Batch: 2.0880 sec
0.0842 0.0611 0.0524 0.0479 0.0459 0.0442 0.0428 0.0417 0.0408 0.0401 0.0395 0.0392 0.0389 0.0386 0.0384 0.0383 

[TRAIN] Epoch[1](305/375); Loss: 0.047821; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0910 0.0685 0.0567 0.0515 0.0482 0.0458 0.0439 0.0425 0.0415 0.0407 0.0401 0.0395 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[1](306/375); Loss: 0.046096; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0808 0.0633 0.0541 0.0483 0.0455 0.0436 0.0425 0.0417 0.0410 0.0404 0.0399 0.0396 0.0394 0.0392 0.0391 0.0390 

[TRAIN] Epoch[1](307/375); Loss: 0.042780; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0804 0.0654 0.0544 0.0486 0.0440 0.0407 0.0382 0.0368 0.0359 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 0.0338 

[TRAIN] Epoch[1](308/375); Loss: 0.064507; Backpropagation: 0.2881 sec; Batch: 2.0738 sec
0.1168 0.0974 0.0821 0.0726 0.0663 0.0617 0.0585 0.0568 0.0553 0.0541 0.0531 0.0524 0.0518 0.0513 0.0510 0.0508 

[TRAIN] Epoch[1](309/375); Loss: 0.049076; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0982 0.0756 0.0624 0.0548 0.0499 0.0465 0.0441 0.0425 0.0413 0.0402 0.0394 0.0389 0.0384 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](310/375); Loss: 0.053969; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0934 0.0740 0.0644 0.0600 0.0557 0.0526 0.0504 0.0487 0.0476 0.0465 0.0459 0.0454 0.0450 0.0447 0.0446 0.0445 

[TRAIN] Epoch[1](311/375); Loss: 0.032587; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0864 0.0569 0.0420 0.0352 0.0313 0.0288 0.0271 0.0261 0.0251 0.0243 0.0237 0.0233 0.0230 0.0228 0.0227 0.0226 

[TRAIN] Epoch[1](312/375); Loss: 0.053848; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1026 0.0796 0.0653 0.0583 0.0541 0.0514 0.0496 0.0478 0.0464 0.0455 0.0446 0.0440 0.0436 0.0432 0.0429 0.0427 

[TRAIN] Epoch[1](313/375); Loss: 0.043856; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.0816 0.0628 0.0520 0.0483 0.0450 0.0422 0.0405 0.0391 0.0381 0.0373 0.0367 0.0362 0.0358 0.0356 0.0354 0.0352 

[TRAIN] Epoch[1](314/375); Loss: 0.038585; Backpropagation: 0.2887 sec; Batch: 2.0735 sec
0.0716 0.0577 0.0484 0.0430 0.0392 0.0367 0.0350 0.0337 0.0329 0.0323 0.0318 0.0313 0.0311 0.0309 0.0308 0.0308 

[TRAIN] Epoch[1](315/375); Loss: 0.049619; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.1008 0.0769 0.0615 0.0549 0.0504 0.0473 0.0447 0.0429 0.0416 0.0405 0.0398 0.0393 0.0388 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](316/375); Loss: 0.047182; Backpropagation: 0.2895 sec; Batch: 2.0750 sec
0.0987 0.0757 0.0609 0.0538 0.0490 0.0450 0.0425 0.0402 0.0388 0.0376 0.0367 0.0360 0.0355 0.0351 0.0348 0.0346 

[TRAIN] Epoch[1](317/375); Loss: 0.051481; Backpropagation: 0.2900 sec; Batch: 2.1155 sec
0.1112 0.0794 0.0634 0.0564 0.0513 0.0479 0.0457 0.0440 0.0429 0.0420 0.0412 0.0405 0.0400 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](318/375); Loss: 0.053031; Backpropagation: 0.2886 sec; Batch: 2.0786 sec
0.1009 0.0765 0.0632 0.0578 0.0539 0.0511 0.0490 0.0474 0.0462 0.0451 0.0442 0.0434 0.0430 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](319/375); Loss: 0.064786; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1237 0.0963 0.0784 0.0692 0.0644 0.0614 0.0592 0.0574 0.0559 0.0547 0.0537 0.0532 0.0527 0.0524 0.0521 0.0519 

[TRAIN] Epoch[1](320/375); Loss: 0.050386; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.1186 0.0819 0.0626 0.0529 0.0478 0.0451 0.0435 0.0422 0.0410 0.0402 0.0395 0.0389 0.0384 0.0381 0.0378 0.0377 

[TRAIN] Epoch[1](321/375); Loss: 0.056966; Backpropagation: 0.2881 sec; Batch: 2.0762 sec
0.1241 0.0854 0.0682 0.0606 0.0560 0.0531 0.0509 0.0492 0.0476 0.0468 0.0460 0.0455 0.0449 0.0446 0.0443 0.0441 

[TRAIN] Epoch[1](322/375); Loss: 0.051033; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1248 0.0828 0.0658 0.0555 0.0491 0.0459 0.0438 0.0419 0.0408 0.0396 0.0388 0.0382 0.0378 0.0374 0.0372 0.0370 

[TRAIN] Epoch[1](323/375); Loss: 0.045407; Backpropagation: 0.2881 sec; Batch: 2.0796 sec
0.1115 0.0703 0.0598 0.0492 0.0445 0.0413 0.0395 0.0375 0.0363 0.0352 0.0345 0.0340 0.0336 0.0333 0.0331 0.0330 

[TRAIN] Epoch[1](324/375); Loss: 0.043110; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.0917 0.0699 0.0538 0.0470 0.0427 0.0401 0.0381 0.0368 0.0355 0.0346 0.0340 0.0335 0.0332 0.0330 0.0329 0.0328 

[TRAIN] Epoch[1](325/375); Loss: 0.044334; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1010 0.0655 0.0518 0.0452 0.0431 0.0409 0.0393 0.0381 0.0371 0.0364 0.0359 0.0354 0.0351 0.0350 0.0348 0.0347 

[TRAIN] Epoch[1](326/375); Loss: 0.048538; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.1149 0.0786 0.0649 0.0528 0.0483 0.0449 0.0420 0.0401 0.0386 0.0375 0.0367 0.0361 0.0357 0.0353 0.0351 0.0350 

[TRAIN] Epoch[1](327/375); Loss: 0.052302; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1335 0.0781 0.0694 0.0583 0.0525 0.0481 0.0451 0.0427 0.0413 0.0401 0.0391 0.0385 0.0380 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](328/375); Loss: 0.053085; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.1341 0.0870 0.0658 0.0561 0.0517 0.0481 0.0456 0.0436 0.0421 0.0410 0.0401 0.0396 0.0391 0.0388 0.0385 0.0383 

[TRAIN] Epoch[1](329/375); Loss: 0.052199; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.1382 0.0882 0.0651 0.0558 0.0503 0.0468 0.0441 0.0421 0.0407 0.0396 0.0387 0.0379 0.0374 0.0370 0.0367 0.0365 

[TRAIN] Epoch[1](330/375); Loss: 0.069105; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1391 0.1046 0.0896 0.0761 0.0699 0.0652 0.0614 0.0591 0.0575 0.0564 0.0556 0.0550 0.0545 0.0541 0.0538 0.0536 

[TRAIN] Epoch[1](331/375); Loss: 0.047588; Backpropagation: 0.2887 sec; Batch: 2.0742 sec
0.1175 0.0760 0.0694 0.0571 0.0507 0.0444 0.0408 0.0382 0.0360 0.0347 0.0339 0.0332 0.0328 0.0325 0.0322 0.0320 

[TRAIN] Epoch[1](332/375); Loss: 0.059557; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.1358 0.0992 0.0814 0.0663 0.0591 0.0537 0.0505 0.0484 0.0471 0.0461 0.0453 0.0447 0.0443 0.0439 0.0437 0.0435 

[TRAIN] Epoch[1](333/375); Loss: 0.061895; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1454 0.0918 0.0743 0.0641 0.0595 0.0563 0.0544 0.0527 0.0514 0.0504 0.0495 0.0489 0.0484 0.0480 0.0477 0.0474 

[TRAIN] Epoch[1](334/375); Loss: 0.053992; Backpropagation: 0.2882 sec; Batch: 2.0862 sec
0.1298 0.0880 0.0746 0.0590 0.0516 0.0481 0.0459 0.0442 0.0428 0.0417 0.0409 0.0402 0.0398 0.0394 0.0391 0.0389 

[TRAIN] Epoch[1](335/375); Loss: 0.056362; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.1219 0.0886 0.0722 0.0637 0.0579 0.0535 0.0504 0.0480 0.0461 0.0448 0.0437 0.0431 0.0425 0.0421 0.0418 0.0416 

[TRAIN] Epoch[1](336/375); Loss: 0.055940; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1322 0.1025 0.0840 0.0657 0.0559 0.0506 0.0469 0.0444 0.0424 0.0410 0.0400 0.0390 0.0383 0.0378 0.0374 0.0370 

[TRAIN] Epoch[1](337/375); Loss: 0.056122; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1245 0.0875 0.0717 0.0641 0.0572 0.0530 0.0501 0.0480 0.0461 0.0445 0.0435 0.0425 0.0419 0.0415 0.0411 0.0409 

[TRAIN] Epoch[1](338/375); Loss: 0.056634; Backpropagation: 0.2879 sec; Batch: 2.0730 sec
0.1246 0.0942 0.0755 0.0649 0.0569 0.0522 0.0491 0.0471 0.0456 0.0444 0.0434 0.0426 0.0419 0.0415 0.0412 0.0410 

[TRAIN] Epoch[1](339/375); Loss: 0.053723; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1256 0.0867 0.0688 0.0604 0.0536 0.0487 0.0465 0.0447 0.0432 0.0420 0.0411 0.0405 0.0400 0.0395 0.0392 0.0390 

[TRAIN] Epoch[1](340/375); Loss: 0.058233; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1301 0.0981 0.0766 0.0656 0.0585 0.0540 0.0510 0.0486 0.0468 0.0455 0.0444 0.0435 0.0429 0.0424 0.0420 0.0417 

[TRAIN] Epoch[1](341/375); Loss: 0.043761; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1046 0.0759 0.0638 0.0505 0.0439 0.0394 0.0366 0.0350 0.0337 0.0327 0.0319 0.0313 0.0308 0.0304 0.0300 0.0298 

[TRAIN] Epoch[1](342/375); Loss: 0.045698; Backpropagation: 0.2879 sec; Batch: 2.0752 sec
0.1019 0.0839 0.0635 0.0519 0.0468 0.0427 0.0395 0.0374 0.0358 0.0344 0.0334 0.0327 0.0322 0.0319 0.0317 0.0316 

[TRAIN] Epoch[1](343/375); Loss: 0.035504; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0905 0.0631 0.0466 0.0427 0.0359 0.0320 0.0296 0.0282 0.0269 0.0259 0.0253 0.0248 0.0245 0.0242 0.0240 0.0239 

[TRAIN] Epoch[1](344/375); Loss: 0.069353; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.1452 0.1111 0.0939 0.0785 0.0703 0.0661 0.0626 0.0596 0.0569 0.0551 0.0537 0.0526 0.0518 0.0512 0.0508 0.0505 

[TRAIN] Epoch[1](345/375); Loss: 0.060877; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1198 0.0883 0.0755 0.0659 0.0615 0.0574 0.0550 0.0534 0.0520 0.0508 0.0501 0.0494 0.0490 0.0488 0.0486 0.0485 

[TRAIN] Epoch[1](346/375); Loss: 0.050519; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.1133 0.0791 0.0679 0.0560 0.0502 0.0469 0.0444 0.0425 0.0411 0.0399 0.0390 0.0383 0.0379 0.0376 0.0373 0.0371 

[TRAIN] Epoch[1](347/375); Loss: 0.051131; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1172 0.0966 0.0696 0.0550 0.0481 0.0447 0.0428 0.0411 0.0399 0.0390 0.0383 0.0378 0.0374 0.0370 0.0369 0.0367 

[TRAIN] Epoch[1](348/375); Loss: 0.046448; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1020 0.0789 0.0660 0.0534 0.0456 0.0417 0.0393 0.0379 0.0367 0.0359 0.0352 0.0347 0.0343 0.0340 0.0339 0.0338 

[TRAIN] Epoch[1](349/375); Loss: 0.055227; Backpropagation: 0.2886 sec; Batch: 2.0841 sec
0.1378 0.1113 0.0817 0.0574 0.0528 0.0479 0.0452 0.0429 0.0412 0.0398 0.0389 0.0382 0.0377 0.0373 0.0369 0.0367 

[TRAIN] Epoch[1](350/375); Loss: 0.058780; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1341 0.1019 0.0782 0.0651 0.0570 0.0534 0.0506 0.0483 0.0468 0.0457 0.0446 0.0439 0.0433 0.0429 0.0425 0.0422 

[TRAIN] Epoch[1](351/375); Loss: 0.047660; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.0951 0.0700 0.0595 0.0512 0.0470 0.0448 0.0434 0.0419 0.0408 0.0398 0.0392 0.0386 0.0382 0.0379 0.0376 0.0375 

[TRAIN] Epoch[1](352/375); Loss: 0.046116; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.1038 0.0850 0.0674 0.0537 0.0461 0.0420 0.0392 0.0373 0.0357 0.0345 0.0335 0.0328 0.0322 0.0318 0.0315 0.0313 

[TRAIN] Epoch[1](353/375); Loss: 0.065639; Backpropagation: 0.2882 sec; Batch: 2.0803 sec
0.1270 0.1074 0.0914 0.0748 0.0662 0.0613 0.0583 0.0556 0.0537 0.0525 0.0516 0.0510 0.0504 0.0500 0.0497 0.0495 

[TRAIN] Epoch[1](354/375); Loss: 0.062216; Backpropagation: 0.2886 sec; Batch: 2.0761 sec
0.1266 0.0950 0.0858 0.0755 0.0673 0.0615 0.0573 0.0537 0.0509 0.0491 0.0476 0.0463 0.0455 0.0449 0.0444 0.0442 

[TRAIN] Epoch[1](355/375); Loss: 0.068409; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.1408 0.1066 0.0931 0.0788 0.0711 0.0657 0.0620 0.0596 0.0573 0.0552 0.0535 0.0519 0.0508 0.0500 0.0493 0.0489 

[TRAIN] Epoch[1](356/375); Loss: 0.066884; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1481 0.1074 0.0859 0.0740 0.0682 0.0639 0.0602 0.0569 0.0545 0.0527 0.0514 0.0505 0.0497 0.0493 0.0490 0.0487 

[TRAIN] Epoch[1](357/375); Loss: 0.034774; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.0787 0.0541 0.0445 0.0374 0.0334 0.0314 0.0300 0.0290 0.0283 0.0277 0.0274 0.0271 0.0270 0.0268 0.0268 0.0268 

[TRAIN] Epoch[1](358/375); Loss: 0.050416; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.1027 0.0914 0.0728 0.0575 0.0500 0.0460 0.0435 0.0417 0.0402 0.0390 0.0382 0.0374 0.0370 0.0367 0.0364 0.0362 

[TRAIN] Epoch[1](359/375); Loss: 0.053482; Backpropagation: 0.2881 sec; Batch: 2.0747 sec
0.1067 0.0843 0.0731 0.0609 0.0540 0.0501 0.0477 0.0458 0.0443 0.0430 0.0421 0.0414 0.0409 0.0406 0.0403 0.0402 

[TRAIN] Epoch[1](360/375); Loss: 0.032418; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0777 0.0519 0.0452 0.0355 0.0318 0.0293 0.0277 0.0265 0.0256 0.0249 0.0244 0.0240 0.0237 0.0235 0.0234 0.0234 

[TRAIN] Epoch[1](361/375); Loss: 0.062016; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1300 0.0973 0.0784 0.0671 0.0613 0.0576 0.0550 0.0532 0.0516 0.0503 0.0495 0.0489 0.0485 0.0480 0.0478 0.0476 

[TRAIN] Epoch[1](362/375); Loss: 0.042274; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0994 0.0795 0.0601 0.0466 0.0404 0.0371 0.0349 0.0333 0.0322 0.0313 0.0309 0.0305 0.0303 0.0301 0.0300 0.0299 

[TRAIN] Epoch[1](363/375); Loss: 0.060448; Backpropagation: 0.2887 sec; Batch: 2.0857 sec
0.1189 0.0923 0.0804 0.0675 0.0614 0.0572 0.0544 0.0522 0.0504 0.0492 0.0484 0.0478 0.0473 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](364/375); Loss: 0.055902; Backpropagation: 0.2881 sec; Batch: 2.0758 sec
0.1246 0.0892 0.0747 0.0619 0.0550 0.0516 0.0490 0.0470 0.0454 0.0442 0.0435 0.0426 0.0421 0.0416 0.0412 0.0409 

[TRAIN] Epoch[1](365/375); Loss: 0.049411; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1148 0.0797 0.0668 0.0564 0.0490 0.0451 0.0429 0.0410 0.0394 0.0384 0.0374 0.0368 0.0363 0.0358 0.0356 0.0353 

[TRAIN] Epoch[1](366/375); Loss: 0.047515; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1067 0.0729 0.0613 0.0501 0.0460 0.0431 0.0415 0.0401 0.0390 0.0383 0.0377 0.0372 0.0368 0.0367 0.0365 0.0364 

[TRAIN] Epoch[1](367/375); Loss: 0.047837; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1065 0.0836 0.0648 0.0533 0.0479 0.0440 0.0415 0.0394 0.0380 0.0367 0.0359 0.0354 0.0350 0.0347 0.0345 0.0343 

[TRAIN] Epoch[1](368/375); Loss: 0.076766; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.1410 0.1061 0.0934 0.0830 0.0779 0.0741 0.0714 0.0690 0.0672 0.0659 0.0648 0.0639 0.0632 0.0627 0.0624 0.0623 

[TRAIN] Epoch[1](369/375); Loss: 0.056504; Backpropagation: 0.2882 sec; Batch: 2.0844 sec
0.1265 0.0861 0.0760 0.0627 0.0572 0.0533 0.0504 0.0481 0.0461 0.0447 0.0437 0.0429 0.0421 0.0417 0.0413 0.0411 

[TRAIN] Epoch[1](370/375); Loss: 0.032225; Backpropagation: 0.2887 sec; Batch: 2.0764 sec
0.0808 0.0522 0.0407 0.0341 0.0309 0.0289 0.0276 0.0264 0.0255 0.0249 0.0244 0.0241 0.0239 0.0238 0.0237 0.0237 

[TRAIN] Epoch[1](371/375); Loss: 0.048367; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1079 0.0748 0.0661 0.0535 0.0483 0.0445 0.0425 0.0406 0.0393 0.0383 0.0375 0.0368 0.0363 0.0360 0.0358 0.0356 

[TRAIN] Epoch[1](372/375); Loss: 0.034469; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0884 0.0605 0.0477 0.0379 0.0334 0.0304 0.0287 0.0274 0.0263 0.0255 0.0250 0.0246 0.0242 0.0239 0.0237 0.0237 

[TRAIN] Epoch[1](373/375); Loss: 0.044984; Backpropagation: 0.2884 sec; Batch: 2.0874 sec
0.1071 0.0748 0.0576 0.0479 0.0431 0.0404 0.0387 0.0374 0.0362 0.0354 0.0346 0.0340 0.0335 0.0332 0.0330 0.0329 

[TRAIN] Epoch[1](374/375); Loss: 0.052105; Backpropagation: 0.2880 sec; Batch: 2.0755 sec
0.1220 0.0821 0.0672 0.0558 0.0508 0.0475 0.0454 0.0436 0.0421 0.0412 0.0404 0.0398 0.0394 0.0391 0.0388 0.0386 

[TRAIN] Epoch[1](375/375); Loss: 0.029223; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.0868 0.0543 0.0425 0.0317 0.0270 0.0241 0.0231 0.0217 0.0207 0.0201 0.0197 0.0194 0.0192 0.0191 0.0190 0.0190 

/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
train.py:248: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  len(train_loader), loss.data[0], bp_t1 - bp_t0, batch_t1 -
train.py:251: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  '\n').format(* [l.data[0] for l in losses]))
[TRAIN] Epoch[2](1/375); Loss: 0.064030; Backpropagation: 0.3022 sec; Batch: 2.1484 sec
0.1363 0.0925 0.0794 0.0681 0.0633 0.0600 0.0575 0.0557 0.0542 0.0530 0.0521 0.0513 0.0507 0.0503 0.0500 0.0498 

[TRAIN] Epoch[2](2/375); Loss: 0.066192; Backpropagation: 0.2908 sec; Batch: 2.1002 sec
0.1413 0.1034 0.0853 0.0730 0.0666 0.0623 0.0591 0.0565 0.0546 0.0531 0.0520 0.0513 0.0507 0.0503 0.0499 0.0497 

[TRAIN] Epoch[2](3/375); Loss: 0.052994; Backpropagation: 0.2910 sec; Batch: 2.0847 sec
0.1155 0.0813 0.0700 0.0586 0.0525 0.0492 0.0473 0.0454 0.0438 0.0427 0.0417 0.0409 0.0403 0.0399 0.0396 0.0393 

[TRAIN] Epoch[2](4/375); Loss: 0.048149; Backpropagation: 0.2881 sec; Batch: 2.0747 sec
0.1181 0.0791 0.0626 0.0526 0.0478 0.0443 0.0414 0.0393 0.0379 0.0368 0.0360 0.0355 0.0351 0.0349 0.0346 0.0345 

[TRAIN] Epoch[2](5/375); Loss: 0.049648; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.0999 0.0763 0.0649 0.0535 0.0484 0.0462 0.0444 0.0430 0.0419 0.0408 0.0400 0.0395 0.0391 0.0389 0.0388 0.0387 

[TRAIN] Epoch[2](6/375); Loss: 0.058865; Backpropagation: 0.2880 sec; Batch: 2.0748 sec
0.1079 0.0889 0.0732 0.0639 0.0591 0.0565 0.0541 0.0522 0.0508 0.0497 0.0487 0.0481 0.0476 0.0473 0.0470 0.0468 

[TRAIN] Epoch[2](7/375); Loss: 0.054331; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1439 0.0979 0.0707 0.0630 0.0542 0.0483 0.0451 0.0423 0.0406 0.0394 0.0384 0.0377 0.0372 0.0370 0.0368 0.0367 

[TRAIN] Epoch[2](8/375); Loss: 0.051941; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1237 0.0890 0.0721 0.0582 0.0498 0.0463 0.0434 0.0418 0.0403 0.0393 0.0387 0.0382 0.0379 0.0376 0.0375 0.0374 

[TRAIN] Epoch[2](9/375); Loss: 0.043376; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1008 0.0696 0.0562 0.0475 0.0430 0.0403 0.0379 0.0362 0.0350 0.0340 0.0332 0.0327 0.0323 0.0320 0.0318 0.0316 

[TRAIN] Epoch[2](10/375); Loss: 0.051834; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.1171 0.0808 0.0659 0.0567 0.0520 0.0484 0.0457 0.0438 0.0424 0.0414 0.0405 0.0398 0.0392 0.0388 0.0385 0.0383 

[TRAIN] Epoch[2](11/375); Loss: 0.051914; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1185 0.0846 0.0689 0.0584 0.0521 0.0480 0.0453 0.0432 0.0416 0.0404 0.0394 0.0389 0.0383 0.0380 0.0377 0.0374 

[TRAIN] Epoch[2](12/375); Loss: 0.051171; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1104 0.0774 0.0628 0.0556 0.0510 0.0485 0.0461 0.0442 0.0428 0.0417 0.0409 0.0402 0.0398 0.0394 0.0391 0.0389 

[TRAIN] Epoch[2](13/375); Loss: 0.057641; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1198 0.0854 0.0756 0.0629 0.0576 0.0542 0.0516 0.0498 0.0482 0.0471 0.0463 0.0456 0.0451 0.0447 0.0444 0.0441 

[TRAIN] Epoch[2](14/375); Loss: 0.049780; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1056 0.0727 0.0634 0.0552 0.0502 0.0470 0.0447 0.0430 0.0416 0.0406 0.0398 0.0392 0.0387 0.0385 0.0382 0.0380 

[TRAIN] Epoch[2](15/375); Loss: 0.055666; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1106 0.0785 0.0703 0.0602 0.0560 0.0530 0.0509 0.0492 0.0479 0.0467 0.0458 0.0451 0.0446 0.0442 0.0439 0.0436 

[TRAIN] Epoch[2](16/375); Loss: 0.037440; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.0868 0.0549 0.0480 0.0397 0.0367 0.0343 0.0328 0.0316 0.0307 0.0301 0.0296 0.0292 0.0289 0.0287 0.0286 0.0285 

[TRAIN] Epoch[2](17/375); Loss: 0.041496; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1064 0.0661 0.0535 0.0450 0.0401 0.0371 0.0353 0.0338 0.0326 0.0318 0.0313 0.0308 0.0304 0.0301 0.0299 0.0298 

[TRAIN] Epoch[2](18/375); Loss: 0.065151; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1224 0.0937 0.0809 0.0715 0.0660 0.0625 0.0598 0.0578 0.0562 0.0549 0.0541 0.0533 0.0528 0.0524 0.0522 0.0520 

[TRAIN] Epoch[2](19/375); Loss: 0.047435; Backpropagation: 0.2883 sec; Batch: 2.0803 sec
0.1154 0.0784 0.0632 0.0511 0.0465 0.0429 0.0404 0.0386 0.0374 0.0365 0.0358 0.0353 0.0348 0.0345 0.0342 0.0339 

[TRAIN] Epoch[2](20/375); Loss: 0.044148; Backpropagation: 0.2882 sec; Batch: 2.0756 sec
0.1018 0.0699 0.0569 0.0489 0.0437 0.0404 0.0381 0.0366 0.0356 0.0348 0.0340 0.0336 0.0333 0.0331 0.0328 0.0327 

[TRAIN] Epoch[2](21/375); Loss: 0.045065; Backpropagation: 0.2882 sec; Batch: 2.0860 sec
0.1043 0.0734 0.0555 0.0477 0.0442 0.0414 0.0393 0.0378 0.0365 0.0357 0.0351 0.0345 0.0341 0.0339 0.0337 0.0336 

[TRAIN] Epoch[2](22/375); Loss: 0.056558; Backpropagation: 0.2884 sec; Batch: 2.0837 sec
0.1295 0.0872 0.0706 0.0615 0.0568 0.0529 0.0501 0.0480 0.0464 0.0452 0.0441 0.0433 0.0429 0.0424 0.0421 0.0418 

[TRAIN] Epoch[2](23/375); Loss: 0.057068; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.1270 0.0895 0.0694 0.0601 0.0557 0.0526 0.0503 0.0486 0.0473 0.0463 0.0454 0.0448 0.0444 0.0441 0.0439 0.0437 

[TRAIN] Epoch[2](24/375); Loss: 0.052716; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.1034 0.0692 0.0619 0.0561 0.0529 0.0507 0.0489 0.0474 0.0462 0.0452 0.0444 0.0439 0.0436 0.0433 0.0432 0.0431 

[TRAIN] Epoch[2](25/375); Loss: 0.022285; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.0734 0.0371 0.0290 0.0239 0.0215 0.0192 0.0176 0.0167 0.0159 0.0153 0.0150 0.0147 0.0145 0.0144 0.0143 0.0142 

[TRAIN] Epoch[2](26/375); Loss: 0.039641; Backpropagation: 0.2885 sec; Batch: 2.0756 sec
0.0880 0.0600 0.0486 0.0422 0.0392 0.0369 0.0351 0.0339 0.0330 0.0322 0.0316 0.0312 0.0308 0.0306 0.0305 0.0304 

[TRAIN] Epoch[2](27/375); Loss: 0.051897; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.0981 0.0744 0.0618 0.0561 0.0526 0.0496 0.0475 0.0460 0.0450 0.0440 0.0433 0.0429 0.0425 0.0423 0.0422 0.0421 

[TRAIN] Epoch[2](28/375); Loss: 0.039290; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0952 0.0639 0.0485 0.0412 0.0377 0.0356 0.0339 0.0328 0.0318 0.0311 0.0304 0.0299 0.0296 0.0292 0.0290 0.0289 

[TRAIN] Epoch[2](29/375); Loss: 0.054491; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1018 0.0787 0.0645 0.0583 0.0546 0.0521 0.0501 0.0487 0.0476 0.0466 0.0459 0.0452 0.0448 0.0445 0.0443 0.0441 

[TRAIN] Epoch[2](30/375); Loss: 0.057466; Backpropagation: 0.2883 sec; Batch: 2.0758 sec
0.1166 0.0858 0.0702 0.0613 0.0578 0.0543 0.0520 0.0501 0.0488 0.0478 0.0470 0.0463 0.0458 0.0455 0.0452 0.0450 

[TRAIN] Epoch[2](31/375); Loss: 0.053545; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1056 0.0788 0.0633 0.0567 0.0530 0.0505 0.0487 0.0472 0.0460 0.0452 0.0445 0.0441 0.0437 0.0433 0.0431 0.0430 

[TRAIN] Epoch[2](32/375); Loss: 0.050685; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.1282 0.0849 0.0653 0.0546 0.0487 0.0450 0.0427 0.0408 0.0396 0.0387 0.0380 0.0375 0.0371 0.0368 0.0366 0.0364 

[TRAIN] Epoch[2](33/375); Loss: 0.044041; Backpropagation: 0.2880 sec; Batch: 2.0754 sec
0.0976 0.0649 0.0533 0.0471 0.0441 0.0413 0.0393 0.0378 0.0368 0.0359 0.0352 0.0348 0.0344 0.0342 0.0340 0.0340 

[TRAIN] Epoch[2](34/375); Loss: 0.064850; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1342 0.0984 0.0818 0.0715 0.0655 0.0616 0.0589 0.0566 0.0547 0.0531 0.0519 0.0510 0.0502 0.0498 0.0494 0.0491 

[TRAIN] Epoch[2](35/375); Loss: 0.047119; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1004 0.0665 0.0580 0.0510 0.0472 0.0445 0.0426 0.0409 0.0398 0.0391 0.0385 0.0378 0.0373 0.0370 0.0367 0.0365 

[TRAIN] Epoch[2](36/375); Loss: 0.027643; Backpropagation: 0.2888 sec; Batch: 2.0759 sec
0.0908 0.0487 0.0351 0.0279 0.0249 0.0230 0.0217 0.0207 0.0199 0.0193 0.0189 0.0186 0.0184 0.0182 0.0181 0.0180 

[TRAIN] Epoch[2](37/375); Loss: 0.061901; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1199 0.0876 0.0731 0.0672 0.0628 0.0594 0.0570 0.0550 0.0535 0.0524 0.0516 0.0509 0.0505 0.0501 0.0499 0.0496 

[TRAIN] Epoch[2](38/375); Loss: 0.040739; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.0970 0.0631 0.0495 0.0435 0.0397 0.0373 0.0356 0.0341 0.0331 0.0323 0.0318 0.0313 0.0311 0.0308 0.0307 0.0306 

[TRAIN] Epoch[2](39/375); Loss: 0.067099; Backpropagation: 0.2884 sec; Batch: 2.0757 sec
0.1218 0.0956 0.0814 0.0724 0.0684 0.0651 0.0624 0.0601 0.0584 0.0572 0.0564 0.0557 0.0552 0.0548 0.0545 0.0544 

[TRAIN] Epoch[2](40/375); Loss: 0.050400; Backpropagation: 0.2886 sec; Batch: 2.0756 sec
0.1164 0.0794 0.0637 0.0533 0.0486 0.0457 0.0434 0.0420 0.0410 0.0402 0.0396 0.0391 0.0388 0.0386 0.0384 0.0383 

[TRAIN] Epoch[2](41/375); Loss: 0.046689; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1045 0.0778 0.0605 0.0522 0.0471 0.0437 0.0412 0.0391 0.0377 0.0366 0.0358 0.0351 0.0345 0.0341 0.0338 0.0336 

[TRAIN] Epoch[2](42/375); Loss: 0.040298; Backpropagation: 0.2883 sec; Batch: 2.0893 sec
0.1021 0.0666 0.0508 0.0438 0.0395 0.0363 0.0341 0.0327 0.0316 0.0307 0.0302 0.0297 0.0294 0.0292 0.0291 0.0290 

[TRAIN] Epoch[2](43/375); Loss: 0.033689; Backpropagation: 0.2882 sec; Batch: 2.0768 sec
0.0920 0.0569 0.0437 0.0374 0.0331 0.0302 0.0282 0.0268 0.0258 0.0248 0.0242 0.0237 0.0234 0.0231 0.0229 0.0228 

[TRAIN] Epoch[2](44/375); Loss: 0.032358; Backpropagation: 0.2883 sec; Batch: 2.0790 sec
0.0887 0.0566 0.0426 0.0361 0.0316 0.0288 0.0269 0.0255 0.0244 0.0236 0.0230 0.0225 0.0222 0.0219 0.0217 0.0216 

[TRAIN] Epoch[2](45/375); Loss: 0.056646; Backpropagation: 0.2884 sec; Batch: 2.0751 sec
0.1184 0.0847 0.0698 0.0614 0.0570 0.0536 0.0510 0.0493 0.0480 0.0468 0.0458 0.0451 0.0445 0.0440 0.0437 0.0434 

[TRAIN] Epoch[2](46/375); Loss: 0.060053; Backpropagation: 0.2884 sec; Batch: 2.0869 sec
0.1316 0.0917 0.0728 0.0648 0.0596 0.0558 0.0536 0.0516 0.0501 0.0489 0.0481 0.0474 0.0468 0.0464 0.0460 0.0458 

[TRAIN] Epoch[2](47/375); Loss: 0.045020; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0934 0.0646 0.0527 0.0480 0.0448 0.0425 0.0408 0.0396 0.0385 0.0377 0.0371 0.0367 0.0363 0.0360 0.0358 0.0357 

[TRAIN] Epoch[2](48/375); Loss: 0.060044; Backpropagation: 0.2884 sec; Batch: 2.0804 sec
0.1187 0.0907 0.0757 0.0669 0.0615 0.0575 0.0547 0.0525 0.0508 0.0495 0.0484 0.0477 0.0472 0.0467 0.0463 0.0460 

[TRAIN] Epoch[2](49/375); Loss: 0.057791; Backpropagation: 0.2879 sec; Batch: 2.0749 sec
0.1249 0.0935 0.0749 0.0617 0.0562 0.0529 0.0506 0.0487 0.0474 0.0464 0.0456 0.0451 0.0446 0.0443 0.0441 0.0439 

[TRAIN] Epoch[2](50/375); Loss: 0.054586; Backpropagation: 0.2887 sec; Batch: 2.0761 sec
0.1184 0.0838 0.0689 0.0601 0.0549 0.0513 0.0487 0.0468 0.0453 0.0440 0.0431 0.0425 0.0420 0.0415 0.0412 0.0410 

[TRAIN] Epoch[2](51/375); Loss: 0.052839; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.1226 0.0866 0.0679 0.0591 0.0528 0.0483 0.0456 0.0437 0.0422 0.0413 0.0403 0.0396 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[2](52/375); Loss: 0.044785; Backpropagation: 0.2887 sec; Batch: 2.0759 sec
0.1203 0.0824 0.0586 0.0505 0.0439 0.0396 0.0368 0.0350 0.0336 0.0324 0.0317 0.0311 0.0307 0.0302 0.0300 0.0297 

[TRAIN] Epoch[2](53/375); Loss: 0.054520; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.1144 0.0864 0.0695 0.0588 0.0539 0.0505 0.0483 0.0466 0.0454 0.0444 0.0436 0.0430 0.0424 0.0420 0.0418 0.0415 

[TRAIN] Epoch[2](54/375); Loss: 0.058083; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1221 0.0917 0.0705 0.0627 0.0573 0.0537 0.0513 0.0499 0.0485 0.0476 0.0468 0.0462 0.0457 0.0453 0.0451 0.0449 

[TRAIN] Epoch[2](55/375); Loss: 0.045401; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.0921 0.0695 0.0584 0.0506 0.0453 0.0423 0.0406 0.0391 0.0381 0.0372 0.0365 0.0360 0.0356 0.0352 0.0350 0.0348 

[TRAIN] Epoch[2](56/375); Loss: 0.049021; Backpropagation: 0.2879 sec; Batch: 2.0745 sec
0.1037 0.0745 0.0615 0.0538 0.0496 0.0463 0.0440 0.0422 0.0409 0.0399 0.0391 0.0385 0.0381 0.0377 0.0375 0.0372 

[TRAIN] Epoch[2](57/375); Loss: 0.040079; Backpropagation: 0.2883 sec; Batch: 2.0839 sec
0.0975 0.0677 0.0545 0.0467 0.0409 0.0368 0.0344 0.0325 0.0312 0.0302 0.0294 0.0287 0.0282 0.0278 0.0275 0.0274 

[TRAIN] Epoch[2](58/375); Loss: 0.053251; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1110 0.0806 0.0644 0.0570 0.0524 0.0496 0.0475 0.0460 0.0448 0.0440 0.0433 0.0429 0.0425 0.0422 0.0420 0.0418 

[TRAIN] Epoch[2](59/375); Loss: 0.049441; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1123 0.0792 0.0633 0.0543 0.0497 0.0460 0.0434 0.0416 0.0402 0.0392 0.0381 0.0374 0.0370 0.0367 0.0365 0.0362 

[TRAIN] Epoch[2](60/375); Loss: 0.044374; Backpropagation: 0.2884 sec; Batch: 2.0752 sec
0.0980 0.0730 0.0563 0.0483 0.0443 0.0412 0.0391 0.0376 0.0363 0.0354 0.0346 0.0340 0.0335 0.0331 0.0328 0.0326 

[TRAIN] Epoch[2](61/375); Loss: 0.053237; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.1100 0.0800 0.0661 0.0585 0.0536 0.0503 0.0480 0.0461 0.0448 0.0438 0.0429 0.0422 0.0418 0.0414 0.0412 0.0410 

[TRAIN] Epoch[2](62/375); Loss: 0.040594; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1169 0.0840 0.0579 0.0442 0.0375 0.0338 0.0316 0.0300 0.0288 0.0278 0.0271 0.0266 0.0262 0.0259 0.0257 0.0256 

[TRAIN] Epoch[2](63/375); Loss: 0.030954; Backpropagation: 0.2883 sec; Batch: 2.0754 sec
0.0710 0.0496 0.0402 0.0340 0.0311 0.0283 0.0268 0.0257 0.0250 0.0245 0.0239 0.0235 0.0232 0.0230 0.0228 0.0227 

[TRAIN] Epoch[2](64/375); Loss: 0.049913; Backpropagation: 0.2888 sec; Batch: 2.0759 sec
0.1158 0.0795 0.0637 0.0552 0.0493 0.0456 0.0434 0.0416 0.0403 0.0394 0.0385 0.0379 0.0375 0.0371 0.0369 0.0368 

[TRAIN] Epoch[2](65/375); Loss: 0.029335; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0786 0.0515 0.0369 0.0310 0.0273 0.0256 0.0242 0.0232 0.0225 0.0220 0.0216 0.0213 0.0211 0.0209 0.0209 0.0208 

[TRAIN] Epoch[2](66/375); Loss: 0.037127; Backpropagation: 0.2879 sec; Batch: 2.0751 sec
0.0858 0.0602 0.0457 0.0394 0.0354 0.0333 0.0319 0.0308 0.0301 0.0296 0.0291 0.0288 0.0286 0.0285 0.0284 0.0283 

[TRAIN] Epoch[2](67/375); Loss: 0.028690; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.0929 0.0522 0.0348 0.0281 0.0251 0.0233 0.0221 0.0213 0.0208 0.0204 0.0201 0.0198 0.0197 0.0196 0.0195 0.0194 

[TRAIN] Epoch[2](68/375); Loss: 0.057771; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1242 0.0743 0.0658 0.0608 0.0573 0.0544 0.0525 0.0510 0.0499 0.0491 0.0484 0.0479 0.0474 0.0472 0.0470 0.0469 

[TRAIN] Epoch[2](69/375); Loss: 0.038856; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.0794 0.0592 0.0486 0.0426 0.0383 0.0360 0.0346 0.0334 0.0326 0.0319 0.0314 0.0311 0.0308 0.0307 0.0306 0.0305 

[TRAIN] Epoch[2](70/375); Loss: 0.036498; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0885 0.0602 0.0458 0.0381 0.0351 0.0326 0.0310 0.0299 0.0290 0.0284 0.0280 0.0277 0.0276 0.0274 0.0273 0.0272 

[TRAIN] Epoch[2](71/375); Loss: 0.061175; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.1341 0.0924 0.0745 0.0651 0.0604 0.0573 0.0548 0.0529 0.0512 0.0498 0.0489 0.0483 0.0478 0.0474 0.0471 0.0469 

[TRAIN] Epoch[2](72/375); Loss: 0.048695; Backpropagation: 0.2883 sec; Batch: 2.0806 sec
0.1111 0.0768 0.0611 0.0530 0.0485 0.0452 0.0430 0.0412 0.0398 0.0386 0.0379 0.0373 0.0368 0.0365 0.0363 0.0361 

[TRAIN] Epoch[2](73/375); Loss: 0.041634; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0774 0.0609 0.0515 0.0462 0.0426 0.0402 0.0385 0.0371 0.0359 0.0350 0.0343 0.0338 0.0334 0.0332 0.0330 0.0329 

[TRAIN] Epoch[2](74/375); Loss: 0.048130; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.1051 0.0723 0.0585 0.0511 0.0474 0.0447 0.0426 0.0412 0.0403 0.0394 0.0387 0.0382 0.0379 0.0377 0.0375 0.0375 

[TRAIN] Epoch[2](75/375); Loss: 0.055795; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1186 0.0816 0.0669 0.0592 0.0552 0.0524 0.0503 0.0484 0.0471 0.0461 0.0454 0.0449 0.0445 0.0442 0.0440 0.0439 

[TRAIN] Epoch[2](76/375); Loss: 0.052019; Backpropagation: 0.2882 sec; Batch: 2.0758 sec
0.1156 0.0802 0.0667 0.0569 0.0525 0.0490 0.0463 0.0443 0.0426 0.0415 0.0406 0.0399 0.0394 0.0391 0.0389 0.0388 

[TRAIN] Epoch[2](77/375); Loss: 0.048864; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1021 0.0734 0.0612 0.0538 0.0494 0.0463 0.0441 0.0424 0.0410 0.0399 0.0391 0.0385 0.0380 0.0377 0.0376 0.0374 

[TRAIN] Epoch[2](78/375); Loss: 0.066386; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1126 0.0909 0.0777 0.0716 0.0670 0.0643 0.0621 0.0605 0.0592 0.0581 0.0575 0.0569 0.0564 0.0560 0.0558 0.0556 

[TRAIN] Epoch[2](79/375); Loss: 0.057418; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1165 0.0837 0.0708 0.0629 0.0581 0.0548 0.0521 0.0503 0.0489 0.0478 0.0468 0.0461 0.0455 0.0451 0.0448 0.0445 

[TRAIN] Epoch[2](80/375); Loss: 0.064267; Backpropagation: 0.2883 sec; Batch: 2.0754 sec
0.1168 0.0918 0.0786 0.0721 0.0660 0.0624 0.0595 0.0574 0.0556 0.0544 0.0535 0.0528 0.0524 0.0519 0.0517 0.0515 

[TRAIN] Epoch[2](81/375); Loss: 0.038812; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0836 0.0570 0.0468 0.0402 0.0379 0.0360 0.0346 0.0336 0.0328 0.0321 0.0317 0.0313 0.0311 0.0309 0.0307 0.0307 

[TRAIN] Epoch[2](82/375); Loss: 0.036637; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.0816 0.0527 0.0450 0.0388 0.0360 0.0339 0.0326 0.0315 0.0308 0.0301 0.0296 0.0292 0.0289 0.0287 0.0285 0.0284 

[TRAIN] Epoch[2](83/375); Loss: 0.044858; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0936 0.0720 0.0559 0.0486 0.0438 0.0415 0.0397 0.0385 0.0374 0.0365 0.0358 0.0354 0.0351 0.0348 0.0346 0.0345 

[TRAIN] Epoch[2](84/375); Loss: 0.040909; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0978 0.0636 0.0493 0.0437 0.0399 0.0376 0.0358 0.0344 0.0333 0.0326 0.0319 0.0315 0.0312 0.0309 0.0307 0.0305 

[TRAIN] Epoch[2](85/375); Loss: 0.054272; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.1056 0.0815 0.0667 0.0595 0.0544 0.0517 0.0495 0.0477 0.0463 0.0453 0.0445 0.0439 0.0434 0.0430 0.0426 0.0423 

[TRAIN] Epoch[2](86/375); Loss: 0.041714; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0853 0.0580 0.0489 0.0433 0.0406 0.0387 0.0375 0.0365 0.0359 0.0354 0.0351 0.0348 0.0346 0.0344 0.0343 0.0342 

[TRAIN] Epoch[2](87/375); Loss: 0.051978; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1036 0.0813 0.0644 0.0566 0.0522 0.0490 0.0470 0.0453 0.0440 0.0429 0.0420 0.0415 0.0410 0.0406 0.0403 0.0400 

[TRAIN] Epoch[2](88/375); Loss: 0.042070; Backpropagation: 0.2883 sec; Batch: 2.0792 sec
0.0791 0.0564 0.0495 0.0451 0.0423 0.0404 0.0391 0.0380 0.0372 0.0365 0.0358 0.0353 0.0349 0.0347 0.0345 0.0344 

[TRAIN] Epoch[2](89/375); Loss: 0.048047; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.1077 0.0724 0.0599 0.0537 0.0484 0.0446 0.0426 0.0408 0.0395 0.0384 0.0378 0.0371 0.0367 0.0365 0.0363 0.0362 

[TRAIN] Epoch[2](90/375); Loss: 0.054753; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.1203 0.0871 0.0700 0.0616 0.0553 0.0512 0.0483 0.0462 0.0445 0.0433 0.0425 0.0419 0.0414 0.0411 0.0408 0.0406 

[TRAIN] Epoch[2](91/375); Loss: 0.050074; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1064 0.0781 0.0642 0.0555 0.0502 0.0468 0.0446 0.0429 0.0414 0.0403 0.0395 0.0390 0.0385 0.0382 0.0379 0.0377 

[TRAIN] Epoch[2](92/375); Loss: 0.056857; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1106 0.0824 0.0692 0.0618 0.0571 0.0537 0.0514 0.0499 0.0489 0.0479 0.0472 0.0466 0.0461 0.0458 0.0456 0.0454 

[TRAIN] Epoch[2](93/375); Loss: 0.045553; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0994 0.0705 0.0581 0.0501 0.0447 0.0417 0.0398 0.0384 0.0374 0.0366 0.0361 0.0358 0.0354 0.0351 0.0349 0.0348 

[TRAIN] Epoch[2](94/375); Loss: 0.053108; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.1048 0.0785 0.0663 0.0585 0.0535 0.0507 0.0484 0.0467 0.0453 0.0442 0.0433 0.0427 0.0423 0.0418 0.0415 0.0412 

[TRAIN] Epoch[2](95/375); Loss: 0.062644; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1138 0.0825 0.0744 0.0680 0.0642 0.0613 0.0588 0.0569 0.0555 0.0543 0.0533 0.0526 0.0521 0.0518 0.0516 0.0513 

[TRAIN] Epoch[2](96/375); Loss: 0.057789; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.1118 0.0831 0.0705 0.0637 0.0588 0.0555 0.0530 0.0511 0.0498 0.0487 0.0477 0.0470 0.0465 0.0461 0.0458 0.0456 

[TRAIN] Epoch[2](97/375); Loss: 0.054958; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.1182 0.0894 0.0744 0.0640 0.0568 0.0515 0.0480 0.0459 0.0442 0.0430 0.0420 0.0412 0.0407 0.0403 0.0400 0.0398 

[TRAIN] Epoch[2](98/375); Loss: 0.037003; Backpropagation: 0.2880 sec; Batch: 2.0741 sec
0.0917 0.0634 0.0469 0.0407 0.0357 0.0328 0.0311 0.0300 0.0291 0.0284 0.0278 0.0274 0.0271 0.0269 0.0267 0.0266 

[TRAIN] Epoch[2](99/375); Loss: 0.049312; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1059 0.0764 0.0665 0.0568 0.0503 0.0461 0.0435 0.0417 0.0403 0.0392 0.0383 0.0377 0.0371 0.0367 0.0364 0.0362 

[TRAIN] Epoch[2](100/375); Loss: 0.052870; Backpropagation: 0.2877 sec; Batch: 2.0740 sec
0.1074 0.0788 0.0674 0.0590 0.0537 0.0499 0.0477 0.0461 0.0446 0.0435 0.0426 0.0419 0.0413 0.0409 0.0407 0.0404 

[TRAIN] Epoch[2](101/375); Loss: 0.049855; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.0932 0.0772 0.0647 0.0570 0.0517 0.0475 0.0450 0.0435 0.0421 0.0411 0.0404 0.0397 0.0392 0.0388 0.0385 0.0382 

[TRAIN] Epoch[2](102/375); Loss: 0.033182; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.0900 0.0546 0.0423 0.0357 0.0316 0.0292 0.0276 0.0265 0.0256 0.0249 0.0245 0.0241 0.0238 0.0236 0.0235 0.0234 

[TRAIN] Epoch[2](103/375); Loss: 0.047224; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0886 0.0673 0.0595 0.0526 0.0481 0.0457 0.0438 0.0422 0.0408 0.0399 0.0390 0.0383 0.0379 0.0376 0.0373 0.0370 

[TRAIN] Epoch[2](104/375); Loss: 0.047070; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0967 0.0773 0.0642 0.0559 0.0498 0.0452 0.0418 0.0397 0.0381 0.0370 0.0360 0.0352 0.0346 0.0342 0.0339 0.0336 

[TRAIN] Epoch[2](105/375); Loss: 0.055424; Backpropagation: 0.2886 sec; Batch: 2.0838 sec
0.1143 0.0804 0.0665 0.0582 0.0538 0.0514 0.0498 0.0484 0.0474 0.0466 0.0459 0.0454 0.0450 0.0447 0.0446 0.0444 

[TRAIN] Epoch[2](106/375); Loss: 0.034005; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0742 0.0532 0.0418 0.0361 0.0328 0.0312 0.0301 0.0293 0.0284 0.0277 0.0272 0.0269 0.0266 0.0264 0.0262 0.0261 

[TRAIN] Epoch[2](107/375); Loss: 0.057203; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1218 0.0862 0.0720 0.0612 0.0556 0.0527 0.0505 0.0490 0.0478 0.0470 0.0462 0.0457 0.0453 0.0449 0.0447 0.0446 

[TRAIN] Epoch[2](108/375); Loss: 0.041043; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0942 0.0660 0.0542 0.0451 0.0403 0.0371 0.0354 0.0342 0.0331 0.0323 0.0317 0.0312 0.0309 0.0306 0.0303 0.0302 

[TRAIN] Epoch[2](109/375); Loss: 0.036026; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0804 0.0643 0.0509 0.0410 0.0352 0.0320 0.0303 0.0290 0.0280 0.0274 0.0269 0.0265 0.0262 0.0261 0.0260 0.0260 

[TRAIN] Epoch[2](110/375); Loss: 0.050783; Backpropagation: 0.2883 sec; Batch: 2.0757 sec
0.1002 0.0790 0.0672 0.0581 0.0521 0.0481 0.0458 0.0440 0.0426 0.0415 0.0404 0.0396 0.0390 0.0386 0.0383 0.0381 

[TRAIN] Epoch[2](111/375); Loss: 0.044194; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1011 0.0756 0.0596 0.0492 0.0438 0.0404 0.0380 0.0366 0.0353 0.0343 0.0334 0.0327 0.0322 0.0318 0.0316 0.0313 

[TRAIN] Epoch[2](112/375); Loss: 0.050596; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0994 0.0789 0.0651 0.0564 0.0504 0.0474 0.0451 0.0438 0.0425 0.0416 0.0408 0.0403 0.0398 0.0395 0.0392 0.0391 

[TRAIN] Epoch[2](113/375); Loss: 0.038610; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0770 0.0603 0.0502 0.0423 0.0378 0.0356 0.0340 0.0330 0.0323 0.0317 0.0312 0.0309 0.0306 0.0304 0.0303 0.0302 

[TRAIN] Epoch[2](114/375); Loss: 0.032922; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0803 0.0517 0.0425 0.0355 0.0319 0.0298 0.0281 0.0271 0.0263 0.0257 0.0253 0.0249 0.0247 0.0245 0.0243 0.0242 

[TRAIN] Epoch[2](115/375); Loss: 0.058614; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.1128 0.0877 0.0749 0.0659 0.0605 0.0566 0.0536 0.0514 0.0498 0.0485 0.0475 0.0467 0.0461 0.0456 0.0453 0.0450 

[TRAIN] Epoch[2](116/375); Loss: 0.040536; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.0994 0.0624 0.0487 0.0427 0.0387 0.0366 0.0349 0.0337 0.0327 0.0321 0.0317 0.0314 0.0311 0.0309 0.0309 0.0308 

[TRAIN] Epoch[2](117/375); Loss: 0.060136; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1387 0.0928 0.0766 0.0650 0.0586 0.0553 0.0524 0.0504 0.0491 0.0480 0.0472 0.0465 0.0459 0.0455 0.0452 0.0450 

[TRAIN] Epoch[2](118/375); Loss: 0.041984; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1103 0.0762 0.0562 0.0441 0.0390 0.0364 0.0343 0.0330 0.0320 0.0312 0.0306 0.0302 0.0299 0.0296 0.0295 0.0294 

[TRAIN] Epoch[2](119/375); Loss: 0.035791; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.0686 0.0542 0.0442 0.0385 0.0359 0.0340 0.0326 0.0314 0.0306 0.0299 0.0294 0.0290 0.0288 0.0286 0.0285 0.0284 

[TRAIN] Epoch[2](120/375); Loss: 0.055690; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1259 0.0894 0.0711 0.0602 0.0549 0.0514 0.0489 0.0471 0.0456 0.0444 0.0434 0.0426 0.0420 0.0416 0.0414 0.0412 

[TRAIN] Epoch[2](121/375); Loss: 0.028622; Backpropagation: 0.2887 sec; Batch: 2.0752 sec
0.0676 0.0379 0.0327 0.0306 0.0282 0.0264 0.0254 0.0246 0.0240 0.0235 0.0232 0.0229 0.0228 0.0228 0.0227 0.0227 

[TRAIN] Epoch[2](122/375); Loss: 0.071664; Backpropagation: 0.2881 sec; Batch: 2.0795 sec
0.1270 0.1033 0.0891 0.0792 0.0732 0.0690 0.0661 0.0641 0.0623 0.0610 0.0601 0.0594 0.0588 0.0583 0.0579 0.0577 

[TRAIN] Epoch[2](123/375); Loss: 0.071149; Backpropagation: 0.2886 sec; Batch: 2.0750 sec
0.1427 0.1131 0.0957 0.0821 0.0734 0.0671 0.0628 0.0600 0.0581 0.0568 0.0557 0.0551 0.0546 0.0541 0.0538 0.0535 

[TRAIN] Epoch[2](124/375); Loss: 0.049748; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1097 0.0763 0.0631 0.0539 0.0493 0.0461 0.0439 0.0423 0.0412 0.0402 0.0395 0.0388 0.0384 0.0380 0.0377 0.0376 

[TRAIN] Epoch[2](125/375); Loss: 0.058091; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1125 0.0850 0.0715 0.0633 0.0585 0.0556 0.0532 0.0513 0.0499 0.0488 0.0479 0.0472 0.0467 0.0463 0.0461 0.0459 

[TRAIN] Epoch[2](126/375); Loss: 0.052257; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1064 0.0775 0.0648 0.0575 0.0528 0.0496 0.0472 0.0455 0.0442 0.0431 0.0424 0.0418 0.0413 0.0409 0.0407 0.0405 

[TRAIN] Epoch[2](127/375); Loss: 0.034752; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1045 0.0650 0.0432 0.0353 0.0315 0.0292 0.0274 0.0263 0.0256 0.0251 0.0245 0.0241 0.0238 0.0237 0.0235 0.0234 

[TRAIN] Epoch[2](128/375); Loss: 0.043368; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1006 0.0663 0.0537 0.0477 0.0432 0.0402 0.0383 0.0368 0.0355 0.0345 0.0339 0.0332 0.0328 0.0326 0.0324 0.0323 

[TRAIN] Epoch[2](129/375); Loss: 0.049789; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0974 0.0740 0.0616 0.0555 0.0509 0.0477 0.0455 0.0436 0.0422 0.0412 0.0404 0.0399 0.0395 0.0393 0.0391 0.0389 

[TRAIN] Epoch[2](130/375); Loss: 0.044838; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0948 0.0715 0.0569 0.0488 0.0443 0.0417 0.0398 0.0382 0.0370 0.0361 0.0355 0.0351 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[2](131/375); Loss: 0.042449; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1066 0.0667 0.0545 0.0460 0.0409 0.0383 0.0365 0.0350 0.0338 0.0330 0.0323 0.0317 0.0313 0.0310 0.0308 0.0307 

[TRAIN] Epoch[2](132/375); Loss: 0.055330; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1128 0.0814 0.0693 0.0617 0.0566 0.0528 0.0499 0.0481 0.0465 0.0454 0.0445 0.0439 0.0435 0.0432 0.0429 0.0427 

[TRAIN] Epoch[2](133/375); Loss: 0.040093; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0893 0.0695 0.0527 0.0432 0.0386 0.0361 0.0342 0.0331 0.0322 0.0315 0.0310 0.0305 0.0302 0.0300 0.0298 0.0297 

[TRAIN] Epoch[2](134/375); Loss: 0.046836; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.1051 0.0782 0.0616 0.0513 0.0459 0.0429 0.0407 0.0390 0.0377 0.0367 0.0360 0.0355 0.0351 0.0348 0.0345 0.0344 

[TRAIN] Epoch[2](135/375); Loss: 0.056281; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1075 0.0806 0.0695 0.0622 0.0578 0.0547 0.0523 0.0501 0.0484 0.0473 0.0463 0.0456 0.0450 0.0446 0.0443 0.0441 

[TRAIN] Epoch[2](136/375); Loss: 0.075270; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1333 0.1050 0.0903 0.0811 0.0762 0.0724 0.0698 0.0678 0.0662 0.0650 0.0642 0.0635 0.0629 0.0625 0.0622 0.0620 

[TRAIN] Epoch[2](137/375); Loss: 0.043133; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1030 0.0681 0.0547 0.0466 0.0426 0.0396 0.0372 0.0356 0.0344 0.0336 0.0331 0.0327 0.0324 0.0323 0.0321 0.0320 

[TRAIN] Epoch[2](138/375); Loss: 0.050008; Backpropagation: 0.2880 sec; Batch: 2.0748 sec
0.0973 0.0728 0.0615 0.0547 0.0506 0.0476 0.0457 0.0440 0.0427 0.0417 0.0411 0.0406 0.0403 0.0400 0.0398 0.0397 

[TRAIN] Epoch[2](139/375); Loss: 0.051218; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1053 0.0762 0.0631 0.0556 0.0510 0.0484 0.0464 0.0446 0.0432 0.0423 0.0415 0.0410 0.0406 0.0403 0.0401 0.0399 

[TRAIN] Epoch[2](140/375); Loss: 0.054115; Backpropagation: 0.2884 sec; Batch: 2.0786 sec
0.1102 0.0790 0.0675 0.0609 0.0563 0.0524 0.0495 0.0472 0.0456 0.0442 0.0434 0.0427 0.0422 0.0419 0.0415 0.0413 

[TRAIN] Epoch[2](141/375); Loss: 0.053947; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1039 0.0791 0.0653 0.0579 0.0546 0.0516 0.0493 0.0476 0.0465 0.0455 0.0447 0.0441 0.0437 0.0433 0.0430 0.0428 

[TRAIN] Epoch[2](142/375); Loss: 0.046686; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1150 0.0807 0.0603 0.0502 0.0452 0.0421 0.0399 0.0383 0.0370 0.0359 0.0350 0.0344 0.0338 0.0334 0.0330 0.0328 

[TRAIN] Epoch[2](143/375); Loss: 0.031140; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0795 0.0560 0.0416 0.0333 0.0293 0.0274 0.0257 0.0247 0.0240 0.0234 0.0229 0.0225 0.0222 0.0220 0.0219 0.0218 

[TRAIN] Epoch[2](144/375); Loss: 0.038979; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.0888 0.0616 0.0483 0.0421 0.0384 0.0359 0.0343 0.0330 0.0319 0.0311 0.0306 0.0301 0.0298 0.0295 0.0293 0.0291 

[TRAIN] Epoch[2](145/375); Loss: 0.056392; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1096 0.0838 0.0689 0.0614 0.0567 0.0538 0.0515 0.0497 0.0483 0.0472 0.0464 0.0456 0.0452 0.0449 0.0447 0.0445 

[TRAIN] Epoch[2](146/375); Loss: 0.062010; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1251 0.0961 0.0780 0.0677 0.0627 0.0590 0.0559 0.0539 0.0522 0.0508 0.0499 0.0491 0.0485 0.0480 0.0477 0.0474 

[TRAIN] Epoch[2](147/375); Loss: 0.046294; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0953 0.0667 0.0555 0.0492 0.0459 0.0434 0.0419 0.0405 0.0394 0.0387 0.0381 0.0377 0.0374 0.0372 0.0370 0.0368 

[TRAIN] Epoch[2](148/375); Loss: 0.035898; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0860 0.0591 0.0454 0.0390 0.0355 0.0330 0.0312 0.0297 0.0286 0.0279 0.0273 0.0268 0.0265 0.0263 0.0261 0.0259 

[TRAIN] Epoch[2](149/375); Loss: 0.054323; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.1065 0.0763 0.0632 0.0579 0.0541 0.0515 0.0495 0.0481 0.0470 0.0462 0.0456 0.0452 0.0449 0.0446 0.0444 0.0443 

[TRAIN] Epoch[2](150/375); Loss: 0.051614; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1050 0.0741 0.0623 0.0572 0.0530 0.0496 0.0473 0.0454 0.0439 0.0427 0.0420 0.0414 0.0409 0.0406 0.0403 0.0401 

[TRAIN] Epoch[2](151/375); Loss: 0.050133; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0907 0.0653 0.0589 0.0534 0.0506 0.0484 0.0467 0.0453 0.0443 0.0437 0.0431 0.0428 0.0425 0.0423 0.0421 0.0420 

[TRAIN] Epoch[2](152/375); Loss: 0.052252; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1074 0.0750 0.0622 0.0556 0.0519 0.0493 0.0473 0.0460 0.0447 0.0438 0.0431 0.0425 0.0421 0.0419 0.0417 0.0415 

[TRAIN] Epoch[2](153/375); Loss: 0.043758; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.1001 0.0650 0.0517 0.0460 0.0424 0.0402 0.0385 0.0374 0.0365 0.0358 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 

[TRAIN] Epoch[2](154/375); Loss: 0.059711; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1120 0.0830 0.0712 0.0638 0.0603 0.0574 0.0555 0.0536 0.0522 0.0511 0.0502 0.0497 0.0492 0.0489 0.0488 0.0486 

[TRAIN] Epoch[2](155/375); Loss: 0.066692; Backpropagation: 0.2879 sec; Batch: 2.0746 sec
0.1291 0.0950 0.0809 0.0742 0.0695 0.0650 0.0614 0.0589 0.0571 0.0557 0.0546 0.0539 0.0534 0.0531 0.0528 0.0525 

[TRAIN] Epoch[2](156/375); Loss: 0.049554; Backpropagation: 0.2888 sec; Batch: 2.0746 sec
0.1006 0.0739 0.0616 0.0543 0.0506 0.0473 0.0449 0.0432 0.0419 0.0408 0.0400 0.0394 0.0390 0.0387 0.0385 0.0384 

[TRAIN] Epoch[2](157/375); Loss: 0.036223; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0759 0.0537 0.0463 0.0388 0.0358 0.0337 0.0321 0.0312 0.0304 0.0297 0.0293 0.0289 0.0287 0.0285 0.0284 0.0283 

[TRAIN] Epoch[2](158/375); Loss: 0.038489; Backpropagation: 0.2885 sec; Batch: 2.0834 sec
0.0839 0.0557 0.0475 0.0420 0.0387 0.0364 0.0344 0.0332 0.0322 0.0314 0.0308 0.0304 0.0301 0.0298 0.0296 0.0295 

[TRAIN] Epoch[2](159/375); Loss: 0.050131; Backpropagation: 0.2880 sec; Batch: 2.0739 sec
0.0967 0.0724 0.0592 0.0528 0.0494 0.0472 0.0455 0.0444 0.0434 0.0427 0.0422 0.0418 0.0414 0.0412 0.0410 0.0408 

[TRAIN] Epoch[2](160/375); Loss: 0.045468; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0978 0.0668 0.0541 0.0488 0.0448 0.0426 0.0408 0.0394 0.0383 0.0375 0.0368 0.0364 0.0361 0.0359 0.0357 0.0356 

[TRAIN] Epoch[2](161/375); Loss: 0.029157; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0796 0.0468 0.0364 0.0314 0.0278 0.0261 0.0248 0.0237 0.0228 0.0221 0.0216 0.0212 0.0209 0.0207 0.0204 0.0203 

[TRAIN] Epoch[2](162/375); Loss: 0.039791; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0801 0.0576 0.0481 0.0429 0.0401 0.0379 0.0362 0.0349 0.0340 0.0333 0.0327 0.0323 0.0319 0.0317 0.0315 0.0314 

[TRAIN] Epoch[2](163/375); Loss: 0.052915; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.1012 0.0759 0.0638 0.0572 0.0536 0.0510 0.0486 0.0470 0.0457 0.0446 0.0439 0.0435 0.0431 0.0427 0.0425 0.0424 

[TRAIN] Epoch[2](164/375); Loss: 0.046642; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0896 0.0664 0.0573 0.0508 0.0474 0.0450 0.0429 0.0413 0.0401 0.0394 0.0385 0.0381 0.0377 0.0374 0.0372 0.0371 

[TRAIN] Epoch[2](165/375); Loss: 0.035526; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0851 0.0546 0.0437 0.0384 0.0349 0.0325 0.0312 0.0299 0.0289 0.0281 0.0275 0.0272 0.0269 0.0267 0.0265 0.0265 

[TRAIN] Epoch[2](166/375); Loss: 0.047128; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1113 0.0694 0.0560 0.0494 0.0460 0.0435 0.0416 0.0402 0.0392 0.0382 0.0376 0.0370 0.0365 0.0363 0.0361 0.0359 

[TRAIN] Epoch[2](167/375); Loss: 0.047573; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0964 0.0701 0.0564 0.0506 0.0465 0.0441 0.0425 0.0414 0.0405 0.0399 0.0394 0.0391 0.0388 0.0386 0.0385 0.0383 

[TRAIN] Epoch[2](168/375); Loss: 0.043648; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0825 0.0617 0.0532 0.0478 0.0447 0.0422 0.0405 0.0391 0.0380 0.0370 0.0363 0.0357 0.0353 0.0350 0.0348 0.0346 

[TRAIN] Epoch[2](169/375); Loss: 0.045367; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0891 0.0652 0.0548 0.0488 0.0455 0.0430 0.0413 0.0400 0.0389 0.0382 0.0376 0.0372 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[2](170/375); Loss: 0.044302; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0914 0.0642 0.0547 0.0476 0.0436 0.0413 0.0397 0.0383 0.0374 0.0368 0.0363 0.0359 0.0357 0.0355 0.0353 0.0352 

[TRAIN] Epoch[2](171/375); Loss: 0.052780; Backpropagation: 0.2881 sec; Batch: 2.0727 sec
0.1107 0.0786 0.0666 0.0598 0.0549 0.0508 0.0479 0.0456 0.0441 0.0429 0.0419 0.0411 0.0404 0.0400 0.0397 0.0394 

[TRAIN] Epoch[2](172/375); Loss: 0.038398; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.0840 0.0561 0.0467 0.0418 0.0389 0.0365 0.0346 0.0331 0.0321 0.0313 0.0306 0.0302 0.0299 0.0297 0.0295 0.0293 

[TRAIN] Epoch[2](173/375); Loss: 0.043865; Backpropagation: 0.2889 sec; Batch: 2.0757 sec
0.1012 0.0675 0.0527 0.0457 0.0424 0.0398 0.0381 0.0369 0.0360 0.0354 0.0349 0.0346 0.0343 0.0342 0.0341 0.0340 

[TRAIN] Epoch[2](174/375); Loss: 0.027129; Backpropagation: 0.2883 sec; Batch: 2.0751 sec
0.0756 0.0482 0.0352 0.0298 0.0261 0.0241 0.0224 0.0212 0.0203 0.0197 0.0192 0.0189 0.0186 0.0184 0.0183 0.0182 

[TRAIN] Epoch[2](175/375); Loss: 0.044152; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0926 0.0662 0.0549 0.0491 0.0451 0.0423 0.0400 0.0381 0.0367 0.0359 0.0352 0.0347 0.0343 0.0340 0.0338 0.0336 

[TRAIN] Epoch[2](176/375); Loss: 0.055617; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.1004 0.0730 0.0669 0.0601 0.0563 0.0539 0.0519 0.0503 0.0492 0.0482 0.0475 0.0470 0.0466 0.0464 0.0462 0.0460 

[TRAIN] Epoch[2](177/375); Loss: 0.031943; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0909 0.0520 0.0404 0.0343 0.0307 0.0283 0.0265 0.0253 0.0243 0.0236 0.0230 0.0227 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[2](178/375); Loss: 0.045915; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1004 0.0720 0.0587 0.0505 0.0459 0.0434 0.0410 0.0392 0.0378 0.0367 0.0359 0.0353 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[2](179/375); Loss: 0.041590; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.0928 0.0599 0.0483 0.0434 0.0408 0.0384 0.0369 0.0358 0.0350 0.0343 0.0339 0.0336 0.0333 0.0331 0.0330 0.0329 

[TRAIN] Epoch[2](180/375); Loss: 0.035549; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0899 0.0552 0.0439 0.0376 0.0347 0.0324 0.0307 0.0294 0.0285 0.0278 0.0272 0.0268 0.0265 0.0263 0.0261 0.0260 

[TRAIN] Epoch[2](181/375); Loss: 0.052995; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1073 0.0745 0.0646 0.0583 0.0541 0.0507 0.0484 0.0465 0.0450 0.0442 0.0435 0.0430 0.0426 0.0421 0.0418 0.0415 

[TRAIN] Epoch[2](182/375); Loss: 0.059800; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1110 0.0866 0.0694 0.0633 0.0594 0.0569 0.0550 0.0535 0.0523 0.0515 0.0507 0.0501 0.0497 0.0493 0.0491 0.0489 

[TRAIN] Epoch[2](183/375); Loss: 0.049514; Backpropagation: 0.2881 sec; Batch: 2.0742 sec
0.1111 0.0846 0.0654 0.0558 0.0496 0.0450 0.0424 0.0408 0.0396 0.0386 0.0377 0.0371 0.0366 0.0362 0.0360 0.0357 

[TRAIN] Epoch[2](184/375); Loss: 0.054936; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1425 0.1051 0.0827 0.0666 0.0544 0.0472 0.0439 0.0413 0.0397 0.0385 0.0376 0.0369 0.0363 0.0358 0.0355 0.0352 

[TRAIN] Epoch[2](185/375); Loss: 0.068757; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1364 0.1197 0.0994 0.0843 0.0733 0.0656 0.0606 0.0572 0.0547 0.0526 0.0514 0.0503 0.0495 0.0489 0.0484 0.0479 

[TRAIN] Epoch[2](186/375); Loss: 0.058858; Backpropagation: 0.2880 sec; Batch: 2.0738 sec
0.1289 0.1130 0.0883 0.0702 0.0588 0.0516 0.0480 0.0465 0.0450 0.0438 0.0428 0.0420 0.0414 0.0408 0.0404 0.0401 

[TRAIN] Epoch[2](187/375); Loss: 0.059661; Backpropagation: 0.2883 sec; Batch: 2.0793 sec
0.1271 0.1070 0.0920 0.0765 0.0637 0.0557 0.0503 0.0470 0.0454 0.0439 0.0429 0.0420 0.0412 0.0405 0.0398 0.0393 

[TRAIN] Epoch[2](188/375); Loss: 0.099075; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1825 0.1659 0.1457 0.1269 0.1121 0.1000 0.0907 0.0835 0.0789 0.0764 0.0742 0.0723 0.0709 0.0697 0.0683 0.0672 

[TRAIN] Epoch[2](189/375); Loss: 0.058918; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1113 0.0960 0.0835 0.0680 0.0603 0.0569 0.0535 0.0510 0.0489 0.0474 0.0463 0.0453 0.0445 0.0438 0.0432 0.0428 

[TRAIN] Epoch[2](190/375); Loss: 0.050246; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1084 0.0886 0.0715 0.0598 0.0519 0.0471 0.0433 0.0409 0.0394 0.0383 0.0374 0.0367 0.0359 0.0354 0.0348 0.0344 

[TRAIN] Epoch[2](191/375); Loss: 0.092004; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1431 0.1291 0.1138 0.1018 0.0946 0.0900 0.0870 0.0851 0.0831 0.0814 0.0799 0.0786 0.0775 0.0765 0.0757 0.0749 

[TRAIN] Epoch[2](192/375); Loss: 0.045623; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0862 0.0762 0.0691 0.0574 0.0495 0.0445 0.0409 0.0383 0.0366 0.0352 0.0341 0.0334 0.0328 0.0324 0.0319 0.0316 

[TRAIN] Epoch[2](193/375); Loss: 0.061365; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1236 0.1059 0.0879 0.0748 0.0642 0.0581 0.0545 0.0516 0.0497 0.0479 0.0460 0.0449 0.0441 0.0435 0.0428 0.0424 

[TRAIN] Epoch[2](194/375); Loss: 0.093851; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.1680 0.1550 0.1330 0.1108 0.0998 0.0915 0.0853 0.0809 0.0780 0.0758 0.0737 0.0720 0.0707 0.0698 0.0690 0.0683 

[TRAIN] Epoch[2](195/375); Loss: 0.071138; Backpropagation: 0.2881 sec; Batch: 2.0730 sec
0.1359 0.1341 0.1082 0.0939 0.0811 0.0697 0.0630 0.0582 0.0545 0.0521 0.0504 0.0491 0.0482 0.0473 0.0466 0.0459 

[TRAIN] Epoch[2](196/375); Loss: 0.072499; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1278 0.1267 0.1074 0.0842 0.0715 0.0691 0.0651 0.0617 0.0595 0.0578 0.0566 0.0556 0.0550 0.0544 0.0540 0.0537 

[TRAIN] Epoch[2](197/375); Loss: 0.073218; Backpropagation: 0.2941 sec; Batch: 2.0806 sec
0.1615 0.1521 0.1322 0.1073 0.0843 0.0676 0.0586 0.0543 0.0513 0.0480 0.0453 0.0436 0.0424 0.0415 0.0410 0.0404 

[TRAIN] Epoch[2](198/375); Loss: 0.058329; Backpropagation: 0.2901 sec; Batch: 2.0765 sec
0.1260 0.1109 0.0811 0.0646 0.0614 0.0541 0.0495 0.0469 0.0451 0.0437 0.0429 0.0422 0.0416 0.0413 0.0410 0.0408 

[TRAIN] Epoch[2](199/375); Loss: 0.087769; Backpropagation: 0.2896 sec; Batch: 2.0755 sec
0.1731 0.1692 0.1521 0.1316 0.1113 0.0919 0.0762 0.0661 0.0604 0.0592 0.0571 0.0540 0.0523 0.0509 0.0498 0.0492 

[TRAIN] Epoch[2](200/375); Loss: 0.051645; Backpropagation: 0.2893 sec; Batch: 2.0740 sec
0.1154 0.1206 0.1012 0.0776 0.0596 0.0452 0.0379 0.0360 0.0341 0.0315 0.0299 0.0286 0.0277 0.0273 0.0269 0.0267 

[TRAIN] Epoch[2](201/375); Loss: 0.077505; Backpropagation: 0.2881 sec; Batch: 2.0746 sec
0.1664 0.1616 0.1421 0.1067 0.0782 0.0707 0.0652 0.0593 0.0548 0.0520 0.0502 0.0486 0.0473 0.0462 0.0456 0.0451 

[TRAIN] Epoch[2](202/375); Loss: 0.065842; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1253 0.1002 0.0818 0.0699 0.0653 0.0638 0.0619 0.0589 0.0563 0.0546 0.0536 0.0528 0.0524 0.0522 0.0522 0.0524 

[TRAIN] Epoch[2](203/375); Loss: 0.050245; Backpropagation: 0.2888 sec; Batch: 2.0765 sec
0.0935 0.0874 0.0800 0.0649 0.0537 0.0481 0.0454 0.0410 0.0384 0.0372 0.0363 0.0358 0.0355 0.0354 0.0357 0.0356 

[TRAIN] Epoch[2](204/375); Loss: 0.070200; Backpropagation: 0.2882 sec; Batch: 2.0754 sec
0.1362 0.1181 0.0959 0.0788 0.0715 0.0659 0.0624 0.0597 0.0574 0.0559 0.0548 0.0540 0.0535 0.0531 0.0530 0.0530 

[TRAIN] Epoch[2](205/375); Loss: 0.079803; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1575 0.1435 0.1244 0.1007 0.0853 0.0753 0.0691 0.0649 0.0622 0.0601 0.0582 0.0569 0.0560 0.0550 0.0542 0.0535 

[TRAIN] Epoch[2](206/375); Loss: 0.046595; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1065 0.0971 0.0761 0.0550 0.0452 0.0418 0.0386 0.0359 0.0336 0.0325 0.0317 0.0309 0.0305 0.0301 0.0300 0.0300 

[TRAIN] Epoch[2](207/375); Loss: 0.060900; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1236 0.1066 0.0904 0.0697 0.0624 0.0574 0.0527 0.0503 0.0484 0.0468 0.0457 0.0448 0.0442 0.0439 0.0438 0.0437 

[TRAIN] Epoch[2](208/375); Loss: 0.049054; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1070 0.0956 0.0742 0.0556 0.0489 0.0452 0.0408 0.0388 0.0372 0.0363 0.0354 0.0346 0.0342 0.0339 0.0337 0.0335 

[TRAIN] Epoch[2](209/375); Loss: 0.051145; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.1031 0.0765 0.0677 0.0573 0.0514 0.0499 0.0460 0.0442 0.0429 0.0418 0.0409 0.0401 0.0396 0.0392 0.0389 0.0388 

[TRAIN] Epoch[2](210/375); Loss: 0.055824; Backpropagation: 0.2888 sec; Batch: 2.0732 sec
0.1301 0.1093 0.0843 0.0668 0.0576 0.0504 0.0466 0.0442 0.0417 0.0401 0.0389 0.0380 0.0372 0.0364 0.0359 0.0356 

[TRAIN] Epoch[2](211/375); Loss: 0.069384; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.1615 0.1505 0.1164 0.0812 0.0647 0.0599 0.0554 0.0519 0.0501 0.0483 0.0470 0.0460 0.0452 0.0445 0.0441 0.0437 

[TRAIN] Epoch[2](212/375); Loss: 0.055857; Backpropagation: 0.2888 sec; Batch: 2.0737 sec
0.1146 0.0968 0.0766 0.0631 0.0575 0.0516 0.0486 0.0468 0.0452 0.0443 0.0431 0.0423 0.0416 0.0410 0.0405 0.0402 

[TRAIN] Epoch[2](213/375); Loss: 0.057437; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.1294 0.1005 0.0776 0.0619 0.0561 0.0522 0.0496 0.0479 0.0462 0.0448 0.0438 0.0429 0.0422 0.0416 0.0412 0.0410 

[TRAIN] Epoch[2](214/375); Loss: 0.064143; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1316 0.1012 0.0863 0.0702 0.0639 0.0603 0.0573 0.0552 0.0535 0.0518 0.0507 0.0499 0.0492 0.0487 0.0483 0.0481 

[TRAIN] Epoch[2](215/375); Loss: 0.074232; Backpropagation: 0.2880 sec; Batch: 2.1091 sec
0.1636 0.1298 0.1075 0.0857 0.0750 0.0689 0.0646 0.0608 0.0581 0.0566 0.0554 0.0540 0.0529 0.0521 0.0516 0.0513 

[TRAIN] Epoch[2](216/375); Loss: 0.051053; Backpropagation: 0.2886 sec; Batch: 2.1083 sec
0.1174 0.1009 0.0712 0.0570 0.0531 0.0459 0.0428 0.0406 0.0390 0.0378 0.0367 0.0359 0.0352 0.0347 0.0345 0.0342 

[TRAIN] Epoch[2](217/375); Loss: 0.047429; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0992 0.0886 0.0671 0.0519 0.0462 0.0427 0.0411 0.0389 0.0376 0.0366 0.0358 0.0352 0.0348 0.0345 0.0343 0.0342 

[TRAIN] Epoch[2](218/375); Loss: 0.050123; Backpropagation: 0.2885 sec; Batch: 2.0863 sec
0.1125 0.0906 0.0625 0.0543 0.0480 0.0455 0.0432 0.0413 0.0401 0.0391 0.0384 0.0379 0.0375 0.0372 0.0371 0.0369 

[TRAIN] Epoch[2](219/375); Loss: 0.068474; Backpropagation: 0.2881 sec; Batch: 2.0758 sec
0.1455 0.1266 0.0967 0.0783 0.0686 0.0630 0.0592 0.0563 0.0541 0.0525 0.0511 0.0499 0.0492 0.0486 0.0482 0.0478 

[TRAIN] Epoch[2](220/375); Loss: 0.061008; Backpropagation: 0.2883 sec; Batch: 2.0782 sec
0.1425 0.1202 0.0893 0.0692 0.0598 0.0534 0.0501 0.0473 0.0456 0.0444 0.0436 0.0429 0.0424 0.0420 0.0418 0.0417 

[TRAIN] Epoch[2](221/375); Loss: 0.045584; Backpropagation: 0.2886 sec; Batch: 2.1095 sec
0.1088 0.0786 0.0591 0.0495 0.0442 0.0409 0.0388 0.0371 0.0361 0.0352 0.0345 0.0340 0.0336 0.0332 0.0330 0.0329 

[TRAIN] Epoch[2](222/375); Loss: 0.077400; Backpropagation: 0.2879 sec; Batch: 2.0733 sec
0.1600 0.1290 0.1050 0.0908 0.0798 0.0722 0.0673 0.0639 0.0622 0.0607 0.0597 0.0586 0.0579 0.0574 0.0570 0.0568 

[TRAIN] Epoch[2](223/375); Loss: 0.061209; Backpropagation: 0.2883 sec; Batch: 2.0825 sec
0.1071 0.0940 0.0753 0.0656 0.0609 0.0582 0.0562 0.0546 0.0534 0.0523 0.0515 0.0508 0.0503 0.0499 0.0497 0.0495 

[TRAIN] Epoch[2](224/375); Loss: 0.058483; Backpropagation: 0.2884 sec; Batch: 2.0796 sec
0.1241 0.0931 0.0723 0.0626 0.0578 0.0547 0.0519 0.0499 0.0485 0.0474 0.0466 0.0460 0.0456 0.0453 0.0451 0.0449 

[TRAIN] Epoch[2](225/375); Loss: 0.067832; Backpropagation: 0.2880 sec; Batch: 2.0786 sec
0.1275 0.1040 0.0855 0.0754 0.0700 0.0656 0.0621 0.0598 0.0581 0.0563 0.0551 0.0542 0.0535 0.0531 0.0527 0.0525 

[TRAIN] Epoch[2](226/375); Loss: 0.058859; Backpropagation: 0.2882 sec; Batch: 2.0767 sec
0.1498 0.1235 0.0818 0.0597 0.0533 0.0498 0.0475 0.0452 0.0439 0.0428 0.0419 0.0413 0.0408 0.0404 0.0401 0.0400 

[TRAIN] Epoch[2](227/375); Loss: 0.062650; Backpropagation: 0.2885 sec; Batch: 2.0822 sec
0.1438 0.1077 0.0814 0.0675 0.0616 0.0575 0.0543 0.0519 0.0502 0.0488 0.0478 0.0470 0.0463 0.0458 0.0455 0.0453 

[TRAIN] Epoch[2](228/375); Loss: 0.059837; Backpropagation: 0.2886 sec; Batch: 2.1015 sec
0.1027 0.0831 0.0707 0.0653 0.0610 0.0579 0.0558 0.0544 0.0532 0.0522 0.0514 0.0507 0.0502 0.0499 0.0496 0.0494 

[TRAIN] Epoch[2](229/375); Loss: 0.052477; Backpropagation: 0.2883 sec; Batch: 2.0782 sec
0.1108 0.0881 0.0651 0.0571 0.0509 0.0478 0.0460 0.0445 0.0433 0.0424 0.0416 0.0409 0.0406 0.0403 0.0401 0.0400 

[TRAIN] Epoch[2](230/375); Loss: 0.059250; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1187 0.0992 0.0769 0.0635 0.0583 0.0544 0.0517 0.0502 0.0493 0.0483 0.0474 0.0469 0.0463 0.0459 0.0457 0.0454 

[TRAIN] Epoch[2](231/375); Loss: 0.043134; Backpropagation: 0.2883 sec; Batch: 2.0809 sec
0.0891 0.0646 0.0523 0.0461 0.0434 0.0410 0.0388 0.0373 0.0362 0.0356 0.0350 0.0346 0.0343 0.0341 0.0339 0.0339 

[TRAIN] Epoch[2](232/375); Loss: 0.056459; Backpropagation: 0.2883 sec; Batch: 2.0780 sec
0.1185 0.0872 0.0682 0.0621 0.0563 0.0530 0.0507 0.0485 0.0473 0.0464 0.0455 0.0447 0.0442 0.0438 0.0435 0.0433 

[TRAIN] Epoch[2](233/375); Loss: 0.061655; Backpropagation: 0.2883 sec; Batch: 2.0775 sec
0.1072 0.0915 0.0772 0.0679 0.0631 0.0598 0.0575 0.0557 0.0539 0.0526 0.0515 0.0507 0.0501 0.0496 0.0492 0.0488 

[TRAIN] Epoch[2](234/375); Loss: 0.060434; Backpropagation: 0.2885 sec; Batch: 2.0778 sec
0.1249 0.0968 0.0820 0.0726 0.0643 0.0582 0.0541 0.0512 0.0490 0.0475 0.0463 0.0453 0.0445 0.0438 0.0433 0.0429 

[TRAIN] Epoch[2](235/375); Loss: 0.057349; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1299 0.0941 0.0703 0.0591 0.0547 0.0520 0.0501 0.0483 0.0472 0.0463 0.0456 0.0448 0.0443 0.0440 0.0436 0.0434 

[TRAIN] Epoch[2](236/375); Loss: 0.050393; Backpropagation: 0.2883 sec; Batch: 2.0816 sec
0.1168 0.1007 0.0688 0.0541 0.0489 0.0453 0.0422 0.0404 0.0387 0.0376 0.0368 0.0361 0.0355 0.0351 0.0348 0.0345 

[TRAIN] Epoch[2](237/375); Loss: 0.058874; Backpropagation: 0.2886 sec; Batch: 2.0780 sec
0.1131 0.0858 0.0669 0.0611 0.0573 0.0550 0.0535 0.0522 0.0512 0.0504 0.0499 0.0495 0.0492 0.0490 0.0489 0.0487 

[TRAIN] Epoch[2](238/375); Loss: 0.077086; Backpropagation: 0.2881 sec; Batch: 2.0774 sec
0.1466 0.1314 0.1083 0.0852 0.0793 0.0760 0.0701 0.0671 0.0645 0.0621 0.0600 0.0585 0.0573 0.0563 0.0557 0.0551 

[TRAIN] Epoch[2](239/375); Loss: 0.059137; Backpropagation: 0.2885 sec; Batch: 2.0779 sec
0.1500 0.1365 0.1040 0.0758 0.0559 0.0454 0.0418 0.0401 0.0394 0.0384 0.0375 0.0368 0.0365 0.0362 0.0360 0.0359 

[TRAIN] Epoch[2](240/375); Loss: 0.046265; Backpropagation: 0.2883 sec; Batch: 2.0780 sec
0.0918 0.0801 0.0640 0.0532 0.0469 0.0437 0.0409 0.0393 0.0381 0.0369 0.0359 0.0350 0.0343 0.0338 0.0334 0.0332 

[TRAIN] Epoch[2](241/375); Loss: 0.052544; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0959 0.0798 0.0637 0.0596 0.0536 0.0503 0.0481 0.0466 0.0452 0.0441 0.0434 0.0427 0.0423 0.0420 0.0418 0.0416 

[TRAIN] Epoch[2](242/375); Loss: 0.050633; Backpropagation: 0.2885 sec; Batch: 2.0763 sec
0.1047 0.0834 0.0641 0.0565 0.0512 0.0473 0.0449 0.0431 0.0417 0.0406 0.0399 0.0393 0.0388 0.0385 0.0382 0.0379 

[TRAIN] Epoch[2](243/375); Loss: 0.041938; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0948 0.0677 0.0520 0.0465 0.0425 0.0396 0.0374 0.0358 0.0345 0.0334 0.0324 0.0317 0.0312 0.0309 0.0305 0.0303 

[TRAIN] Epoch[2](244/375); Loss: 0.044992; Backpropagation: 0.2884 sec; Batch: 2.1041 sec
0.0937 0.0731 0.0599 0.0514 0.0461 0.0426 0.0400 0.0382 0.0368 0.0358 0.0350 0.0343 0.0337 0.0333 0.0331 0.0329 

[TRAIN] Epoch[2](245/375); Loss: 0.068926; Backpropagation: 0.2887 sec; Batch: 2.0890 sec
0.1147 0.0955 0.0819 0.0750 0.0707 0.0675 0.0651 0.0631 0.0614 0.0603 0.0593 0.0586 0.0580 0.0576 0.0573 0.0571 

[TRAIN] Epoch[2](246/375); Loss: 0.066564; Backpropagation: 0.2884 sec; Batch: 2.0796 sec
0.1449 0.1277 0.1000 0.0807 0.0681 0.0602 0.0562 0.0535 0.0511 0.0493 0.0476 0.0467 0.0456 0.0449 0.0444 0.0441 

[TRAIN] Epoch[2](247/375); Loss: 0.070509; Backpropagation: 0.2882 sec; Batch: 2.0780 sec
0.1462 0.1306 0.1025 0.0812 0.0734 0.0666 0.0616 0.0590 0.0561 0.0535 0.0518 0.0506 0.0496 0.0490 0.0484 0.0480 

[TRAIN] Epoch[2](248/375); Loss: 0.051133; Backpropagation: 0.2882 sec; Batch: 2.0774 sec
0.1008 0.0763 0.0603 0.0532 0.0497 0.0476 0.0464 0.0453 0.0443 0.0434 0.0428 0.0423 0.0419 0.0415 0.0412 0.0410 

[TRAIN] Epoch[2](249/375); Loss: 0.045483; Backpropagation: 0.2882 sec; Batch: 2.1129 sec
0.0971 0.0718 0.0556 0.0491 0.0454 0.0426 0.0406 0.0391 0.0379 0.0369 0.0362 0.0356 0.0353 0.0350 0.0348 0.0347 

[TRAIN] Epoch[2](250/375); Loss: 0.050130; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0976 0.0805 0.0638 0.0541 0.0506 0.0477 0.0454 0.0436 0.0424 0.0412 0.0403 0.0397 0.0392 0.0388 0.0386 0.0385 

[TRAIN] Epoch[2](251/375); Loss: 0.048059; Backpropagation: 0.2886 sec; Batch: 2.0824 sec
0.0946 0.0687 0.0568 0.0513 0.0477 0.0453 0.0436 0.0424 0.0414 0.0407 0.0402 0.0397 0.0394 0.0392 0.0390 0.0388 

[TRAIN] Epoch[2](252/375); Loss: 0.064378; Backpropagation: 0.2885 sec; Batch: 2.0756 sec
0.1412 0.1077 0.0825 0.0697 0.0630 0.0584 0.0554 0.0535 0.0523 0.0512 0.0503 0.0498 0.0493 0.0489 0.0486 0.0484 

[TRAIN] Epoch[2](253/375); Loss: 0.038990; Backpropagation: 0.2881 sec; Batch: 2.0746 sec
0.0918 0.0588 0.0475 0.0407 0.0372 0.0352 0.0339 0.0327 0.0320 0.0314 0.0310 0.0307 0.0304 0.0302 0.0302 0.0301 

[TRAIN] Epoch[2](254/375); Loss: 0.050891; Backpropagation: 0.2880 sec; Batch: 2.0968 sec
0.1095 0.0847 0.0653 0.0553 0.0502 0.0466 0.0445 0.0429 0.0417 0.0408 0.0400 0.0394 0.0388 0.0384 0.0382 0.0380 

[TRAIN] Epoch[2](255/375); Loss: 0.047601; Backpropagation: 0.2879 sec; Batch: 2.0738 sec
0.0896 0.0708 0.0588 0.0520 0.0479 0.0451 0.0432 0.0419 0.0408 0.0399 0.0393 0.0389 0.0386 0.0384 0.0383 0.0382 

[TRAIN] Epoch[2](256/375); Loss: 0.052101; Backpropagation: 0.2882 sec; Batch: 2.0785 sec
0.1060 0.0885 0.0671 0.0598 0.0527 0.0490 0.0466 0.0447 0.0430 0.0417 0.0406 0.0398 0.0391 0.0386 0.0383 0.0380 

[TRAIN] Epoch[2](257/375); Loss: 0.054899; Backpropagation: 0.2887 sec; Batch: 2.0749 sec
0.1085 0.0855 0.0686 0.0599 0.0550 0.0515 0.0493 0.0478 0.0464 0.0454 0.0446 0.0439 0.0434 0.0431 0.0429 0.0426 

[TRAIN] Epoch[2](258/375); Loss: 0.036761; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0659 0.0533 0.0446 0.0401 0.0371 0.0351 0.0338 0.0329 0.0321 0.0315 0.0309 0.0306 0.0302 0.0301 0.0299 0.0299 

[TRAIN] Epoch[2](259/375); Loss: 0.057410; Backpropagation: 0.2889 sec; Batch: 2.0747 sec
0.1248 0.1083 0.0832 0.0687 0.0587 0.0523 0.0482 0.0457 0.0439 0.0426 0.0417 0.0409 0.0404 0.0400 0.0397 0.0395 

[TRAIN] Epoch[2](260/375); Loss: 0.054179; Backpropagation: 0.2881 sec; Batch: 2.0735 sec
0.1093 0.0858 0.0694 0.0602 0.0545 0.0515 0.0489 0.0469 0.0454 0.0442 0.0433 0.0425 0.0419 0.0413 0.0409 0.0406 

[TRAIN] Epoch[2](261/375); Loss: 0.052875; Backpropagation: 0.2880 sec; Batch: 2.0870 sec
0.1109 0.0898 0.0679 0.0590 0.0533 0.0495 0.0464 0.0446 0.0431 0.0420 0.0411 0.0405 0.0400 0.0395 0.0392 0.0390 

[TRAIN] Epoch[2](262/375); Loss: 0.049525; Backpropagation: 0.2884 sec; Batch: 2.0788 sec
0.1173 0.0854 0.0646 0.0543 0.0485 0.0450 0.0426 0.0408 0.0393 0.0381 0.0373 0.0366 0.0361 0.0358 0.0355 0.0353 

[TRAIN] Epoch[2](263/375); Loss: 0.055448; Backpropagation: 0.2884 sec; Batch: 2.0776 sec
0.1112 0.0848 0.0677 0.0588 0.0553 0.0526 0.0505 0.0487 0.0473 0.0461 0.0453 0.0446 0.0441 0.0437 0.0434 0.0432 

[TRAIN] Epoch[2](264/375); Loss: 0.069123; Backpropagation: 0.2884 sec; Batch: 2.1093 sec
0.1411 0.1112 0.0924 0.0803 0.0725 0.0668 0.0626 0.0594 0.0569 0.0552 0.0538 0.0522 0.0514 0.0506 0.0500 0.0495 

[TRAIN] Epoch[2](265/375); Loss: 0.029391; Backpropagation: 0.2883 sec; Batch: 2.0853 sec
0.0692 0.0516 0.0420 0.0346 0.0296 0.0266 0.0250 0.0237 0.0227 0.0220 0.0214 0.0210 0.0206 0.0203 0.0201 0.0200 

[TRAIN] Epoch[2](266/375); Loss: 0.036063; Backpropagation: 0.2885 sec; Batch: 2.0989 sec
0.1030 0.0722 0.0509 0.0372 0.0326 0.0296 0.0282 0.0270 0.0261 0.0255 0.0248 0.0245 0.0242 0.0239 0.0237 0.0237 

[TRAIN] Epoch[2](267/375); Loss: 0.054056; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1126 0.0886 0.0715 0.0605 0.0546 0.0506 0.0478 0.0461 0.0445 0.0432 0.0423 0.0415 0.0409 0.0404 0.0400 0.0397 

[TRAIN] Epoch[2](268/375); Loss: 0.042645; Backpropagation: 0.2888 sec; Batch: 2.0735 sec
0.0972 0.0697 0.0545 0.0472 0.0425 0.0391 0.0368 0.0355 0.0345 0.0337 0.0330 0.0324 0.0320 0.0317 0.0315 0.0312 

[TRAIN] Epoch[2](269/375); Loss: 0.059756; Backpropagation: 0.2880 sec; Batch: 2.0866 sec
0.1129 0.0911 0.0765 0.0671 0.0616 0.0577 0.0548 0.0527 0.0510 0.0496 0.0485 0.0475 0.0469 0.0464 0.0461 0.0457 

[TRAIN] Epoch[2](270/375); Loss: 0.051508; Backpropagation: 0.2881 sec; Batch: 2.0795 sec
0.1598 0.1426 0.1043 0.0675 0.0434 0.0352 0.0311 0.0287 0.0280 0.0274 0.0267 0.0263 0.0260 0.0259 0.0258 0.0257 

[TRAIN] Epoch[2](271/375); Loss: 0.090644; Backpropagation: 0.2886 sec; Batch: 2.0777 sec
0.1722 0.1415 0.1182 0.1041 0.0943 0.0876 0.0824 0.0796 0.0775 0.0753 0.0733 0.0716 0.0699 0.0685 0.0677 0.0668 

[TRAIN] Epoch[2](272/375); Loss: 0.053237; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0984 0.0803 0.0661 0.0587 0.0544 0.0515 0.0492 0.0473 0.0459 0.0447 0.0439 0.0431 0.0426 0.0422 0.0419 0.0416 

[TRAIN] Epoch[2](273/375); Loss: 0.067771; Backpropagation: 0.2883 sec; Batch: 2.0761 sec
0.1184 0.1045 0.0878 0.0749 0.0690 0.0653 0.0620 0.0600 0.0584 0.0571 0.0561 0.0552 0.0546 0.0540 0.0536 0.0533 

[TRAIN] Epoch[2](274/375); Loss: 0.048763; Backpropagation: 0.2883 sec; Batch: 2.0811 sec
0.0952 0.0756 0.0628 0.0543 0.0494 0.0462 0.0440 0.0423 0.0410 0.0400 0.0392 0.0387 0.0383 0.0380 0.0377 0.0376 

[TRAIN] Epoch[2](275/375); Loss: 0.050266; Backpropagation: 0.2885 sec; Batch: 2.0782 sec
0.1019 0.0811 0.0649 0.0556 0.0506 0.0475 0.0453 0.0435 0.0418 0.0407 0.0397 0.0391 0.0387 0.0383 0.0379 0.0377 

[TRAIN] Epoch[2](276/375); Loss: 0.056702; Backpropagation: 0.2882 sec; Batch: 2.0779 sec
0.1156 0.0898 0.0729 0.0628 0.0573 0.0537 0.0506 0.0488 0.0471 0.0459 0.0450 0.0444 0.0439 0.0434 0.0431 0.0428 

[TRAIN] Epoch[2](277/375); Loss: 0.048970; Backpropagation: 0.2882 sec; Batch: 2.0777 sec
0.1189 0.0954 0.0685 0.0529 0.0464 0.0428 0.0403 0.0385 0.0374 0.0363 0.0354 0.0348 0.0345 0.0341 0.0338 0.0336 

[TRAIN] Epoch[2](278/375); Loss: 0.055971; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.1086 0.0902 0.0746 0.0650 0.0583 0.0533 0.0500 0.0479 0.0464 0.0452 0.0443 0.0435 0.0427 0.0422 0.0417 0.0415 

[TRAIN] Epoch[2](279/375); Loss: 0.055851; Backpropagation: 0.2883 sec; Batch: 2.0778 sec
0.1216 0.0953 0.0730 0.0623 0.0561 0.0523 0.0494 0.0471 0.0454 0.0439 0.0428 0.0419 0.0413 0.0408 0.0403 0.0400 

[TRAIN] Epoch[2](280/375); Loss: 0.056349; Backpropagation: 0.2885 sec; Batch: 2.0835 sec
0.0998 0.0872 0.0698 0.0615 0.0574 0.0539 0.0513 0.0498 0.0486 0.0477 0.0469 0.0463 0.0458 0.0455 0.0451 0.0449 

[TRAIN] Epoch[2](281/375); Loss: 0.052787; Backpropagation: 0.2889 sec; Batch: 2.0859 sec
0.1163 0.0970 0.0738 0.0611 0.0543 0.0488 0.0453 0.0428 0.0411 0.0398 0.0388 0.0380 0.0374 0.0370 0.0367 0.0364 

[TRAIN] Epoch[2](282/375); Loss: 0.079177; Backpropagation: 0.2886 sec; Batch: 2.0854 sec
0.1408 0.1155 0.1040 0.0954 0.0863 0.0793 0.0744 0.0705 0.0676 0.0656 0.0639 0.0626 0.0613 0.0605 0.0598 0.0593 

[TRAIN] Epoch[2](283/375); Loss: 0.066068; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1177 0.0989 0.0791 0.0705 0.0658 0.0630 0.0610 0.0591 0.0577 0.0567 0.0559 0.0552 0.0546 0.0542 0.0539 0.0537 

[TRAIN] Epoch[2](284/375); Loss: 0.056359; Backpropagation: 0.2884 sec; Batch: 2.0880 sec
0.1083 0.0912 0.0715 0.0628 0.0570 0.0534 0.0508 0.0488 0.0473 0.0462 0.0453 0.0447 0.0441 0.0437 0.0434 0.0432 

[TRAIN] Epoch[2](285/375); Loss: 0.052904; Backpropagation: 0.2884 sec; Batch: 2.0747 sec
0.1148 0.0886 0.0684 0.0581 0.0527 0.0489 0.0463 0.0447 0.0432 0.0420 0.0411 0.0403 0.0399 0.0395 0.0391 0.0389 

[TRAIN] Epoch[2](286/375); Loss: 0.040428; Backpropagation: 0.2882 sec; Batch: 2.0768 sec
0.0866 0.0694 0.0521 0.0445 0.0405 0.0381 0.0359 0.0341 0.0328 0.0318 0.0312 0.0305 0.0301 0.0299 0.0297 0.0296 

[TRAIN] Epoch[2](287/375); Loss: 0.045365; Backpropagation: 0.2884 sec; Batch: 2.0781 sec
0.1004 0.0877 0.0648 0.0504 0.0435 0.0404 0.0383 0.0366 0.0355 0.0344 0.0336 0.0328 0.0323 0.0320 0.0317 0.0315 

[TRAIN] Epoch[2](288/375); Loss: 0.061408; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.1255 0.0982 0.0800 0.0708 0.0635 0.0587 0.0554 0.0525 0.0506 0.0491 0.0479 0.0471 0.0464 0.0459 0.0455 0.0452 

[TRAIN] Epoch[2](289/375); Loss: 0.056881; Backpropagation: 0.2889 sec; Batch: 2.0821 sec
0.1101 0.0914 0.0714 0.0632 0.0575 0.0538 0.0514 0.0497 0.0480 0.0468 0.0459 0.0452 0.0445 0.0440 0.0437 0.0436 

[TRAIN] Epoch[2](290/375); Loss: 0.053118; Backpropagation: 0.2882 sec; Batch: 2.0763 sec
0.1253 0.1096 0.0833 0.0589 0.0498 0.0461 0.0426 0.0403 0.0390 0.0381 0.0373 0.0367 0.0362 0.0358 0.0355 0.0354 

[TRAIN] Epoch[2](291/375); Loss: 0.061963; Backpropagation: 0.2883 sec; Batch: 2.0771 sec
0.1461 0.1152 0.0801 0.0641 0.0580 0.0541 0.0519 0.0502 0.0490 0.0479 0.0470 0.0463 0.0459 0.0455 0.0451 0.0449 

[TRAIN] Epoch[2](292/375); Loss: 0.053160; Backpropagation: 0.2883 sec; Batch: 2.0781 sec
0.1055 0.0892 0.0746 0.0632 0.0560 0.0506 0.0467 0.0444 0.0428 0.0418 0.0408 0.0400 0.0394 0.0390 0.0386 0.0382 

[TRAIN] Epoch[2](293/375); Loss: 0.048634; Backpropagation: 0.2883 sec; Batch: 2.0806 sec
0.0994 0.0788 0.0612 0.0532 0.0486 0.0455 0.0433 0.0419 0.0407 0.0397 0.0389 0.0383 0.0378 0.0373 0.0370 0.0368 

[TRAIN] Epoch[2](294/375); Loss: 0.069281; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1267 0.1082 0.0838 0.0734 0.0683 0.0645 0.0626 0.0609 0.0600 0.0590 0.0581 0.0574 0.0569 0.0565 0.0561 0.0559 

[TRAIN] Epoch[2](295/375); Loss: 0.045374; Backpropagation: 0.2887 sec; Batch: 2.0887 sec
0.0972 0.0758 0.0580 0.0508 0.0441 0.0410 0.0394 0.0381 0.0368 0.0361 0.0356 0.0351 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[2](296/375); Loss: 0.069449; Backpropagation: 0.2881 sec; Batch: 2.0795 sec
0.1322 0.1203 0.0987 0.0827 0.0734 0.0658 0.0611 0.0584 0.0562 0.0545 0.0533 0.0523 0.0515 0.0508 0.0503 0.0499 

[TRAIN] Epoch[2](297/375); Loss: 0.053356; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.1004 0.0818 0.0650 0.0574 0.0531 0.0504 0.0486 0.0475 0.0462 0.0452 0.0443 0.0436 0.0430 0.0427 0.0424 0.0421 

[TRAIN] Epoch[2](298/375); Loss: 0.035714; Backpropagation: 0.2880 sec; Batch: 2.0739 sec
0.0862 0.0692 0.0491 0.0396 0.0344 0.0319 0.0300 0.0283 0.0273 0.0265 0.0258 0.0253 0.0248 0.0245 0.0243 0.0242 

[TRAIN] Epoch[2](299/375); Loss: 0.050291; Backpropagation: 0.2887 sec; Batch: 2.0804 sec
0.0963 0.0785 0.0627 0.0555 0.0514 0.0481 0.0457 0.0438 0.0423 0.0414 0.0408 0.0404 0.0399 0.0396 0.0393 0.0391 

[TRAIN] Epoch[2](300/375); Loss: 0.036428; Backpropagation: 0.2881 sec; Batch: 2.1128 sec
0.0844 0.0599 0.0490 0.0404 0.0361 0.0334 0.0316 0.0303 0.0292 0.0282 0.0275 0.0270 0.0267 0.0265 0.0263 0.0263 

[TRAIN] Epoch[2](301/375); Loss: 0.056522; Backpropagation: 0.2880 sec; Batch: 2.0743 sec
0.1442 0.1176 0.0819 0.0574 0.0513 0.0477 0.0453 0.0434 0.0420 0.0409 0.0400 0.0393 0.0387 0.0384 0.0382 0.0380 

[TRAIN] Epoch[2](302/375); Loss: 0.046514; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1018 0.0756 0.0599 0.0519 0.0463 0.0438 0.0412 0.0395 0.0381 0.0371 0.0361 0.0354 0.0348 0.0345 0.0342 0.0340 

[TRAIN] Epoch[2](303/375); Loss: 0.061854; Backpropagation: 0.2887 sec; Batch: 2.1032 sec
0.1307 0.1015 0.0780 0.0659 0.0606 0.0573 0.0548 0.0530 0.0515 0.0501 0.0490 0.0483 0.0478 0.0474 0.0470 0.0468 

[TRAIN] Epoch[2](304/375); Loss: 0.041035; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0982 0.0784 0.0555 0.0431 0.0383 0.0356 0.0339 0.0326 0.0316 0.0309 0.0304 0.0300 0.0298 0.0296 0.0294 0.0293 

[TRAIN] Epoch[2](305/375); Loss: 0.069659; Backpropagation: 0.2884 sec; Batch: 2.0822 sec
0.1346 0.1105 0.0895 0.0769 0.0707 0.0666 0.0634 0.0607 0.0588 0.0574 0.0562 0.0552 0.0543 0.0537 0.0532 0.0528 

[TRAIN] Epoch[2](306/375); Loss: 0.039346; Backpropagation: 0.2881 sec; Batch: 2.0859 sec
0.1033 0.0834 0.0541 0.0432 0.0379 0.0342 0.0317 0.0301 0.0287 0.0277 0.0269 0.0263 0.0259 0.0255 0.0253 0.0252 

[TRAIN] Epoch[2](307/375); Loss: 0.056682; Backpropagation: 0.2886 sec; Batch: 2.0769 sec
0.1148 0.0867 0.0694 0.0611 0.0569 0.0536 0.0510 0.0492 0.0479 0.0468 0.0460 0.0454 0.0450 0.0446 0.0443 0.0441 

[TRAIN] Epoch[2](308/375); Loss: 0.054232; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.1306 0.1053 0.0783 0.0566 0.0506 0.0468 0.0443 0.0426 0.0414 0.0403 0.0395 0.0390 0.0385 0.0382 0.0379 0.0377 

[TRAIN] Epoch[2](309/375); Loss: 0.056072; Backpropagation: 0.2883 sec; Batch: 2.0788 sec
0.1100 0.0880 0.0694 0.0601 0.0556 0.0526 0.0504 0.0490 0.0479 0.0467 0.0458 0.0451 0.0446 0.0443 0.0439 0.0437 

[TRAIN] Epoch[2](310/375); Loss: 0.066681; Backpropagation: 0.2882 sec; Batch: 2.0782 sec
0.1250 0.0979 0.0810 0.0726 0.0675 0.0641 0.0616 0.0596 0.0579 0.0565 0.0554 0.0546 0.0539 0.0534 0.0530 0.0527 

[TRAIN] Epoch[2](311/375); Loss: 0.049686; Backpropagation: 0.2884 sec; Batch: 2.1171 sec
0.0922 0.0810 0.0649 0.0544 0.0489 0.0461 0.0443 0.0429 0.0419 0.0410 0.0404 0.0400 0.0396 0.0393 0.0391 0.0389 

[TRAIN] Epoch[2](312/375); Loss: 0.054309; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1295 0.0884 0.0728 0.0628 0.0548 0.0500 0.0469 0.0446 0.0428 0.0415 0.0405 0.0398 0.0392 0.0387 0.0384 0.0381 

[TRAIN] Epoch[2](313/375); Loss: 0.044993; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.0965 0.0721 0.0603 0.0527 0.0463 0.0429 0.0399 0.0379 0.0364 0.0353 0.0345 0.0338 0.0333 0.0329 0.0326 0.0324 

[TRAIN] Epoch[2](314/375); Loss: 0.051236; Backpropagation: 0.2882 sec; Batch: 2.0804 sec
0.1143 0.0817 0.0648 0.0554 0.0498 0.0468 0.0448 0.0432 0.0421 0.0412 0.0404 0.0398 0.0393 0.0390 0.0387 0.0386 

[TRAIN] Epoch[2](315/375); Loss: 0.070079; Backpropagation: 0.2886 sec; Batch: 2.0751 sec
0.1221 0.1004 0.0863 0.0773 0.0724 0.0681 0.0653 0.0634 0.0617 0.0602 0.0589 0.0581 0.0574 0.0569 0.0565 0.0562 

[TRAIN] Epoch[2](316/375); Loss: 0.060839; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1221 0.0947 0.0786 0.0684 0.0621 0.0581 0.0551 0.0527 0.0510 0.0495 0.0484 0.0476 0.0470 0.0465 0.0461 0.0458 

[TRAIN] Epoch[2](317/375); Loss: 0.080633; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1661 0.1288 0.1081 0.0962 0.0861 0.0778 0.0720 0.0682 0.0655 0.0637 0.0620 0.0607 0.0597 0.0589 0.0584 0.0579 

[TRAIN] Epoch[2](318/375); Loss: 0.063717; Backpropagation: 0.2882 sec; Batch: 2.0816 sec
0.1311 0.0966 0.0800 0.0695 0.0637 0.0601 0.0572 0.0553 0.0537 0.0525 0.0515 0.0506 0.0499 0.0495 0.0492 0.0490 

[TRAIN] Epoch[2](319/375); Loss: 0.048810; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.1006 0.0728 0.0614 0.0559 0.0504 0.0471 0.0446 0.0426 0.0409 0.0395 0.0387 0.0380 0.0376 0.0372 0.0370 0.0368 

[TRAIN] Epoch[2](320/375); Loss: 0.044068; Backpropagation: 0.2885 sec; Batch: 2.0760 sec
0.0989 0.0710 0.0582 0.0509 0.0446 0.0411 0.0386 0.0369 0.0355 0.0344 0.0337 0.0330 0.0326 0.0322 0.0319 0.0317 

[TRAIN] Epoch[2](321/375); Loss: 0.055670; Backpropagation: 0.2886 sec; Batch: 2.0777 sec
0.1188 0.0886 0.0729 0.0620 0.0559 0.0520 0.0493 0.0473 0.0459 0.0448 0.0437 0.0429 0.0423 0.0418 0.0414 0.0412 

[TRAIN] Epoch[2](322/375); Loss: 0.048985; Backpropagation: 0.2886 sec; Batch: 2.0774 sec
0.1071 0.0809 0.0621 0.0535 0.0485 0.0451 0.0430 0.0416 0.0402 0.0392 0.0382 0.0376 0.0371 0.0368 0.0365 0.0364 

[TRAIN] Epoch[2](323/375); Loss: 0.043793; Backpropagation: 0.2886 sec; Batch: 2.0748 sec
0.0917 0.0687 0.0541 0.0476 0.0429 0.0403 0.0388 0.0376 0.0366 0.0358 0.0352 0.0348 0.0344 0.0342 0.0341 0.0340 

[TRAIN] Epoch[2](324/375); Loss: 0.038707; Backpropagation: 0.2886 sec; Batch: 2.0765 sec
0.0893 0.0703 0.0517 0.0422 0.0366 0.0342 0.0325 0.0313 0.0304 0.0297 0.0292 0.0288 0.0284 0.0283 0.0283 0.0282 

[TRAIN] Epoch[2](325/375); Loss: 0.059809; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1102 0.0863 0.0737 0.0662 0.0614 0.0580 0.0555 0.0535 0.0520 0.0508 0.0498 0.0490 0.0484 0.0477 0.0473 0.0471 

[TRAIN] Epoch[2](326/375); Loss: 0.035580; Backpropagation: 0.2883 sec; Batch: 2.1149 sec
0.0852 0.0596 0.0475 0.0397 0.0348 0.0322 0.0304 0.0292 0.0282 0.0274 0.0267 0.0263 0.0259 0.0256 0.0254 0.0252 

[TRAIN] Epoch[2](327/375); Loss: 0.049647; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1098 0.0843 0.0663 0.0565 0.0508 0.0467 0.0433 0.0411 0.0397 0.0384 0.0375 0.0368 0.0363 0.0359 0.0355 0.0352 

[TRAIN] Epoch[2](328/375); Loss: 0.055076; Backpropagation: 0.2885 sec; Batch: 2.1135 sec
0.1240 0.0868 0.0688 0.0595 0.0541 0.0503 0.0478 0.0461 0.0450 0.0440 0.0433 0.0428 0.0425 0.0422 0.0421 0.0419 

[TRAIN] Epoch[2](329/375); Loss: 0.038968; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.0882 0.0623 0.0495 0.0420 0.0376 0.0355 0.0339 0.0328 0.0319 0.0312 0.0305 0.0301 0.0298 0.0296 0.0294 0.0293 

[TRAIN] Epoch[2](330/375); Loss: 0.043475; Backpropagation: 0.2885 sec; Batch: 2.0782 sec
0.1117 0.0848 0.0649 0.0515 0.0428 0.0384 0.0352 0.0331 0.0315 0.0305 0.0297 0.0291 0.0286 0.0282 0.0279 0.0277 

[TRAIN] Epoch[2](331/375); Loss: 0.060419; Backpropagation: 0.2886 sec; Batch: 2.1014 sec
0.1118 0.0917 0.0771 0.0671 0.0615 0.0581 0.0554 0.0532 0.0517 0.0506 0.0496 0.0489 0.0483 0.0477 0.0472 0.0469 

[TRAIN] Epoch[2](332/375); Loss: 0.051009; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1143 0.0786 0.0629 0.0532 0.0497 0.0469 0.0449 0.0434 0.0422 0.0414 0.0407 0.0402 0.0398 0.0395 0.0393 0.0391 

[TRAIN] Epoch[2](333/375); Loss: 0.064708; Backpropagation: 0.2882 sec; Batch: 2.1100 sec
0.1258 0.1009 0.0832 0.0727 0.0666 0.0624 0.0591 0.0568 0.0549 0.0532 0.0518 0.0509 0.0501 0.0494 0.0489 0.0486 

[TRAIN] Epoch[2](334/375); Loss: 0.037513; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.0847 0.0622 0.0452 0.0395 0.0360 0.0340 0.0325 0.0314 0.0307 0.0301 0.0297 0.0293 0.0290 0.0288 0.0286 0.0285 

[TRAIN] Epoch[2](335/375); Loss: 0.037814; Backpropagation: 0.2883 sec; Batch: 2.1084 sec
0.0886 0.0607 0.0469 0.0399 0.0364 0.0342 0.0327 0.0314 0.0305 0.0299 0.0295 0.0292 0.0290 0.0288 0.0287 0.0286 

[TRAIN] Epoch[2](336/375); Loss: 0.054298; Backpropagation: 0.2887 sec; Batch: 2.0748 sec
0.1114 0.0830 0.0679 0.0592 0.0537 0.0507 0.0485 0.0467 0.0455 0.0446 0.0439 0.0433 0.0430 0.0427 0.0424 0.0422 

[TRAIN] Epoch[2](337/375); Loss: 0.030136; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0989 0.0605 0.0458 0.0337 0.0274 0.0240 0.0220 0.0207 0.0200 0.0193 0.0189 0.0186 0.0183 0.0181 0.0179 0.0178 

[TRAIN] Epoch[2](338/375); Loss: 0.037465; Backpropagation: 0.2883 sec; Batch: 2.0758 sec
0.0747 0.0591 0.0468 0.0405 0.0367 0.0346 0.0333 0.0324 0.0314 0.0308 0.0304 0.0301 0.0298 0.0297 0.0296 0.0294 

[TRAIN] Epoch[2](339/375); Loss: 0.047492; Backpropagation: 0.2880 sec; Batch: 2.0776 sec
0.0985 0.0747 0.0603 0.0511 0.0464 0.0437 0.0418 0.0405 0.0394 0.0387 0.0382 0.0377 0.0375 0.0373 0.0371 0.0370 

[TRAIN] Epoch[2](340/375); Loss: 0.045730; Backpropagation: 0.2884 sec; Batch: 2.0872 sec
0.0848 0.0678 0.0540 0.0487 0.0454 0.0435 0.0419 0.0407 0.0397 0.0390 0.0384 0.0380 0.0377 0.0375 0.0374 0.0373 

[TRAIN] Epoch[2](341/375); Loss: 0.062608; Backpropagation: 0.2882 sec; Batch: 2.0792 sec
0.1056 0.0844 0.0742 0.0687 0.0643 0.0615 0.0591 0.0571 0.0556 0.0547 0.0539 0.0532 0.0528 0.0525 0.0522 0.0519 

[TRAIN] Epoch[2](342/375); Loss: 0.055041; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1084 0.0816 0.0692 0.0610 0.0562 0.0530 0.0504 0.0484 0.0468 0.0455 0.0447 0.0440 0.0434 0.0429 0.0427 0.0426 

[TRAIN] Epoch[2](343/375); Loss: 0.051117; Backpropagation: 0.2881 sec; Batch: 2.0770 sec
0.1003 0.0791 0.0638 0.0569 0.0525 0.0492 0.0468 0.0451 0.0435 0.0422 0.0412 0.0403 0.0397 0.0393 0.0391 0.0389 

[TRAIN] Epoch[2](344/375); Loss: 0.038610; Backpropagation: 0.2882 sec; Batch: 2.1128 sec
0.1057 0.0697 0.0496 0.0415 0.0367 0.0337 0.0320 0.0304 0.0293 0.0284 0.0277 0.0272 0.0268 0.0265 0.0263 0.0262 

[TRAIN] Epoch[2](345/375); Loss: 0.043731; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.1068 0.0751 0.0567 0.0490 0.0435 0.0395 0.0370 0.0354 0.0342 0.0333 0.0325 0.0320 0.0315 0.0312 0.0310 0.0308 

[TRAIN] Epoch[2](346/375); Loss: 0.041644; Backpropagation: 0.2885 sec; Batch: 2.1184 sec
0.1035 0.0734 0.0546 0.0466 0.0403 0.0371 0.0348 0.0334 0.0323 0.0314 0.0307 0.0302 0.0298 0.0296 0.0294 0.0292 

[TRAIN] Epoch[2](347/375); Loss: 0.044585; Backpropagation: 0.2884 sec; Batch: 2.0773 sec
0.1336 0.0907 0.0591 0.0472 0.0403 0.0371 0.0345 0.0328 0.0316 0.0309 0.0302 0.0297 0.0293 0.0289 0.0288 0.0287 

[TRAIN] Epoch[2](348/375); Loss: 0.077062; Backpropagation: 0.2884 sec; Batch: 2.0813 sec
0.1599 0.1238 0.0994 0.0873 0.0786 0.0730 0.0687 0.0656 0.0635 0.0617 0.0604 0.0594 0.0587 0.0580 0.0576 0.0573 

[TRAIN] Epoch[2](349/375); Loss: 0.071747; Backpropagation: 0.2886 sec; Batch: 2.0875 sec
0.1336 0.1085 0.0874 0.0782 0.0726 0.0691 0.0662 0.0640 0.0622 0.0605 0.0593 0.0583 0.0576 0.0571 0.0567 0.0566 

[TRAIN] Epoch[2](350/375); Loss: 0.070148; Backpropagation: 0.2883 sec; Batch: 2.0763 sec
0.1811 0.1414 0.1078 0.0845 0.0687 0.0610 0.0560 0.0525 0.0501 0.0485 0.0471 0.0461 0.0452 0.0446 0.0441 0.0436 

[TRAIN] Epoch[2](351/375); Loss: 0.058668; Backpropagation: 0.2885 sec; Batch: 2.0765 sec
0.1508 0.1058 0.0807 0.0672 0.0570 0.0520 0.0488 0.0464 0.0446 0.0431 0.0419 0.0411 0.0405 0.0400 0.0396 0.0393 

[TRAIN] Epoch[2](352/375); Loss: 0.032443; Backpropagation: 0.2885 sec; Batch: 2.0881 sec
0.1009 0.0619 0.0409 0.0334 0.0291 0.0270 0.0253 0.0243 0.0235 0.0228 0.0223 0.0220 0.0217 0.0215 0.0214 0.0213 

[TRAIN] Epoch[2](353/375); Loss: 0.050068; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1327 0.0925 0.0623 0.0538 0.0471 0.0437 0.0412 0.0397 0.0382 0.0372 0.0365 0.0360 0.0355 0.0352 0.0349 0.0346 

[TRAIN] Epoch[2](354/375); Loss: 0.062566; Backpropagation: 0.2881 sec; Batch: 2.0971 sec
0.1472 0.1058 0.0813 0.0680 0.0605 0.0559 0.0532 0.0513 0.0498 0.0487 0.0477 0.0471 0.0466 0.0462 0.0460 0.0457 

[TRAIN] Epoch[2](355/375); Loss: 0.041651; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1278 0.0771 0.0528 0.0425 0.0376 0.0350 0.0332 0.0316 0.0305 0.0296 0.0289 0.0285 0.0281 0.0279 0.0277 0.0275 

[TRAIN] Epoch[2](356/375); Loss: 0.062621; Backpropagation: 0.2879 sec; Batch: 2.0810 sec
0.1429 0.1054 0.0808 0.0686 0.0616 0.0577 0.0550 0.0527 0.0507 0.0493 0.0480 0.0471 0.0462 0.0456 0.0452 0.0449 

[TRAIN] Epoch[2](357/375); Loss: 0.057773; Backpropagation: 0.2882 sec; Batch: 2.0817 sec
0.1341 0.0940 0.0685 0.0616 0.0565 0.0529 0.0504 0.0486 0.0473 0.0462 0.0453 0.0446 0.0441 0.0437 0.0434 0.0432 

[TRAIN] Epoch[2](358/375); Loss: 0.045807; Backpropagation: 0.2883 sec; Batch: 2.1094 sec
0.1165 0.0733 0.0550 0.0475 0.0435 0.0409 0.0390 0.0378 0.0369 0.0360 0.0353 0.0348 0.0345 0.0342 0.0339 0.0338 

[TRAIN] Epoch[2](359/375); Loss: 0.051219; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1533 0.0898 0.0633 0.0527 0.0473 0.0437 0.0413 0.0398 0.0385 0.0373 0.0366 0.0360 0.0355 0.0351 0.0348 0.0346 

[TRAIN] Epoch[2](360/375); Loss: 0.056465; Backpropagation: 0.2884 sec; Batch: 2.0780 sec
0.1027 0.0794 0.0692 0.0626 0.0584 0.0551 0.0526 0.0509 0.0492 0.0480 0.0471 0.0464 0.0459 0.0455 0.0453 0.0451 

[TRAIN] Epoch[2](361/375); Loss: 0.056756; Backpropagation: 0.2883 sec; Batch: 2.1136 sec
0.1227 0.0859 0.0701 0.0624 0.0568 0.0537 0.0510 0.0490 0.0475 0.0461 0.0451 0.0443 0.0438 0.0435 0.0432 0.0430 

[TRAIN] Epoch[2](362/375); Loss: 0.073274; Backpropagation: 0.2881 sec; Batch: 2.0747 sec
0.1560 0.1102 0.0914 0.0813 0.0728 0.0690 0.0662 0.0636 0.0614 0.0597 0.0584 0.0576 0.0569 0.0563 0.0559 0.0556 

[TRAIN] Epoch[2](363/375); Loss: 0.047772; Backpropagation: 0.2880 sec; Batch: 2.0739 sec
0.0976 0.0743 0.0596 0.0527 0.0484 0.0449 0.0426 0.0410 0.0398 0.0390 0.0382 0.0378 0.0374 0.0372 0.0369 0.0368 

[TRAIN] Epoch[2](364/375); Loss: 0.052969; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.1317 0.0818 0.0624 0.0565 0.0509 0.0478 0.0459 0.0443 0.0430 0.0420 0.0413 0.0406 0.0402 0.0399 0.0397 0.0395 

[TRAIN] Epoch[2](365/375); Loss: 0.066501; Backpropagation: 0.2883 sec; Batch: 2.0793 sec
0.1349 0.1035 0.0875 0.0784 0.0689 0.0630 0.0592 0.0566 0.0546 0.0532 0.0520 0.0513 0.0508 0.0504 0.0500 0.0497 

[TRAIN] Epoch[2](366/375); Loss: 0.041019; Backpropagation: 0.2880 sec; Batch: 2.0729 sec
0.0971 0.0660 0.0507 0.0446 0.0404 0.0379 0.0359 0.0344 0.0333 0.0323 0.0316 0.0310 0.0307 0.0304 0.0301 0.0299 

[TRAIN] Epoch[2](367/375); Loss: 0.058496; Backpropagation: 0.2881 sec; Batch: 2.0735 sec
0.1902 0.1149 0.0793 0.0696 0.0550 0.0487 0.0450 0.0420 0.0399 0.0383 0.0372 0.0363 0.0356 0.0350 0.0346 0.0343 

[TRAIN] Epoch[2](368/375); Loss: 0.063059; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.1642 0.1150 0.0821 0.0705 0.0609 0.0559 0.0523 0.0500 0.0480 0.0466 0.0455 0.0446 0.0440 0.0435 0.0431 0.0429 

[TRAIN] Epoch[2](369/375); Loss: 0.040929; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1366 0.0855 0.0561 0.0467 0.0382 0.0324 0.0303 0.0285 0.0271 0.0261 0.0255 0.0250 0.0246 0.0243 0.0241 0.0240 

[TRAIN] Epoch[2](370/375); Loss: 0.051248; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.1246 0.0897 0.0692 0.0548 0.0484 0.0448 0.0427 0.0413 0.0401 0.0393 0.0385 0.0379 0.0375 0.0372 0.0370 0.0369 

[TRAIN] Epoch[2](371/375); Loss: 0.080248; Backpropagation: 0.2882 sec; Batch: 2.0862 sec
0.2342 0.1704 0.1136 0.0917 0.0788 0.0686 0.0631 0.0593 0.0560 0.0537 0.0517 0.0504 0.0492 0.0484 0.0477 0.0472 

[TRAIN] Epoch[2](372/375); Loss: 0.056020; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1838 0.1158 0.0688 0.0579 0.0529 0.0463 0.0428 0.0405 0.0387 0.0375 0.0365 0.0358 0.0353 0.0349 0.0345 0.0343 

[TRAIN] Epoch[2](373/375); Loss: 0.065796; Backpropagation: 0.2883 sec; Batch: 2.0809 sec
0.1508 0.1121 0.0855 0.0744 0.0655 0.0597 0.0567 0.0542 0.0525 0.0511 0.0500 0.0492 0.0486 0.0479 0.0475 0.0472 

[TRAIN] Epoch[2](374/375); Loss: 0.046204; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1519 0.0983 0.0640 0.0530 0.0411 0.0367 0.0344 0.0323 0.0308 0.0297 0.0290 0.0284 0.0279 0.0275 0.0272 0.0270 

[TRAIN] Epoch[2](375/375); Loss: 0.046341; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.1231 0.0841 0.0633 0.0520 0.0447 0.0409 0.0382 0.0364 0.0350 0.0340 0.0329 0.0322 0.0317 0.0312 0.0309 0.0307 

[TRAIN] Epoch[3](1/375); Loss: 0.071459; Backpropagation: 0.2996 sec; Batch: 2.1390 sec
0.2208 0.1391 0.0904 0.0771 0.0689 0.0611 0.0573 0.0539 0.0512 0.0494 0.0479 0.0468 0.0458 0.0450 0.0445 0.0441 

[TRAIN] Epoch[3](2/375); Loss: 0.044250; Backpropagation: 0.2906 sec; Batch: 2.0868 sec
0.1424 0.0795 0.0685 0.0577 0.0395 0.0353 0.0328 0.0311 0.0299 0.0291 0.0283 0.0276 0.0271 0.0267 0.0264 0.0262 

[TRAIN] Epoch[3](3/375); Loss: 0.061651; Backpropagation: 0.2915 sec; Batch: 2.0785 sec
0.2073 0.1096 0.0787 0.0659 0.0564 0.0523 0.0483 0.0455 0.0436 0.0422 0.0411 0.0402 0.0395 0.0390 0.0386 0.0383 

[TRAIN] Epoch[3](4/375); Loss: 0.044017; Backpropagation: 0.2886 sec; Batch: 2.0773 sec
0.1099 0.0785 0.0605 0.0515 0.0436 0.0394 0.0367 0.0348 0.0335 0.0326 0.0317 0.0311 0.0306 0.0302 0.0299 0.0298 

[TRAIN] Epoch[3](5/375); Loss: 0.051182; Backpropagation: 0.2887 sec; Batch: 2.0757 sec
0.1395 0.0894 0.0696 0.0592 0.0498 0.0458 0.0426 0.0402 0.0384 0.0370 0.0361 0.0353 0.0346 0.0341 0.0337 0.0335 

[TRAIN] Epoch[3](6/375); Loss: 0.073035; Backpropagation: 0.2877 sec; Batch: 2.0734 sec
0.1479 0.1059 0.0916 0.0825 0.0740 0.0699 0.0664 0.0638 0.0618 0.0602 0.0591 0.0581 0.0575 0.0570 0.0566 0.0563 

[TRAIN] Epoch[3](7/375); Loss: 0.063968; Backpropagation: 0.2884 sec; Batch: 2.0822 sec
0.1314 0.0914 0.0776 0.0715 0.0642 0.0609 0.0582 0.0561 0.0544 0.0532 0.0522 0.0514 0.0509 0.0504 0.0500 0.0497 

[TRAIN] Epoch[3](8/375); Loss: 0.057635; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1404 0.0988 0.0767 0.0665 0.0564 0.0513 0.0485 0.0465 0.0449 0.0437 0.0428 0.0421 0.0415 0.0410 0.0407 0.0404 

[TRAIN] Epoch[3](9/375); Loss: 0.080791; Backpropagation: 0.2883 sec; Batch: 2.0810 sec
0.1872 0.1332 0.1065 0.0927 0.0794 0.0722 0.0694 0.0665 0.0644 0.0628 0.0617 0.0608 0.0599 0.0592 0.0586 0.0582 

[TRAIN] Epoch[3](10/375); Loss: 0.059475; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.1470 0.0986 0.0757 0.0650 0.0575 0.0537 0.0511 0.0492 0.0475 0.0463 0.0450 0.0440 0.0433 0.0428 0.0425 0.0421 

[TRAIN] Epoch[3](11/375); Loss: 0.028991; Backpropagation: 0.2880 sec; Batch: 2.0730 sec
0.0918 0.0552 0.0428 0.0325 0.0270 0.0243 0.0221 0.0207 0.0198 0.0192 0.0187 0.0183 0.0181 0.0179 0.0178 0.0177 

[TRAIN] Epoch[3](12/375); Loss: 0.057237; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.1462 0.0881 0.0701 0.0611 0.0542 0.0512 0.0491 0.0474 0.0462 0.0450 0.0442 0.0434 0.0429 0.0425 0.0422 0.0420 

[TRAIN] Epoch[3](13/375); Loss: 0.060501; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1422 0.1013 0.0833 0.0727 0.0623 0.0557 0.0518 0.0488 0.0469 0.0455 0.0444 0.0437 0.0430 0.0425 0.0421 0.0418 

[TRAIN] Epoch[3](14/375); Loss: 0.045906; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.1009 0.0693 0.0606 0.0528 0.0459 0.0427 0.0406 0.0390 0.0377 0.0367 0.0359 0.0352 0.0348 0.0344 0.0341 0.0339 

[TRAIN] Epoch[3](15/375); Loss: 0.039836; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0894 0.0598 0.0487 0.0418 0.0386 0.0366 0.0351 0.0339 0.0330 0.0324 0.0320 0.0316 0.0313 0.0311 0.0310 0.0309 

[TRAIN] Epoch[3](16/375); Loss: 0.069901; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1688 0.1167 0.0981 0.0840 0.0705 0.0632 0.0592 0.0564 0.0542 0.0526 0.0513 0.0503 0.0492 0.0485 0.0479 0.0476 

[TRAIN] Epoch[3](17/375); Loss: 0.045315; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1290 0.0741 0.0589 0.0486 0.0432 0.0399 0.0376 0.0358 0.0345 0.0335 0.0328 0.0322 0.0317 0.0314 0.0311 0.0308 

[TRAIN] Epoch[3](18/375); Loss: 0.050132; Backpropagation: 0.2886 sec; Batch: 2.0742 sec
0.1439 0.0800 0.0595 0.0521 0.0470 0.0441 0.0417 0.0402 0.0389 0.0381 0.0372 0.0366 0.0361 0.0358 0.0356 0.0354 

[TRAIN] Epoch[3](19/375); Loss: 0.048279; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1162 0.0788 0.0634 0.0548 0.0483 0.0445 0.0415 0.0394 0.0381 0.0370 0.0362 0.0357 0.0351 0.0348 0.0345 0.0342 

[TRAIN] Epoch[3](20/375); Loss: 0.087342; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.2008 0.1397 0.1116 0.0980 0.0881 0.0809 0.0764 0.0731 0.0706 0.0688 0.0674 0.0661 0.0650 0.0642 0.0636 0.0630 

[TRAIN] Epoch[3](21/375); Loss: 0.058757; Backpropagation: 0.2887 sec; Batch: 2.0747 sec
0.1213 0.0859 0.0715 0.0630 0.0577 0.0551 0.0528 0.0510 0.0498 0.0489 0.0482 0.0476 0.0472 0.0469 0.0467 0.0466 

[TRAIN] Epoch[3](22/375); Loss: 0.054895; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.1187 0.0806 0.0672 0.0586 0.0539 0.0511 0.0488 0.0472 0.0461 0.0451 0.0444 0.0439 0.0435 0.0432 0.0430 0.0429 

[TRAIN] Epoch[3](23/375); Loss: 0.054858; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1178 0.0886 0.0721 0.0611 0.0542 0.0508 0.0483 0.0464 0.0448 0.0437 0.0428 0.0421 0.0416 0.0413 0.0411 0.0409 

[TRAIN] Epoch[3](24/375); Loss: 0.069790; Backpropagation: 0.2881 sec; Batch: 2.0826 sec
0.1714 0.1135 0.0937 0.0793 0.0708 0.0653 0.0601 0.0568 0.0546 0.0529 0.0516 0.0505 0.0498 0.0492 0.0487 0.0484 

[TRAIN] Epoch[3](25/375); Loss: 0.043398; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1244 0.0732 0.0604 0.0468 0.0413 0.0380 0.0356 0.0337 0.0325 0.0314 0.0306 0.0300 0.0295 0.0292 0.0290 0.0288 

[TRAIN] Epoch[3](26/375); Loss: 0.047259; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.1112 0.0681 0.0589 0.0514 0.0473 0.0441 0.0417 0.0399 0.0387 0.0378 0.0371 0.0366 0.0362 0.0359 0.0357 0.0355 

[TRAIN] Epoch[3](27/375); Loss: 0.057341; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1355 0.0935 0.0751 0.0637 0.0568 0.0524 0.0496 0.0475 0.0460 0.0448 0.0437 0.0429 0.0422 0.0417 0.0413 0.0410 

[TRAIN] Epoch[3](28/375); Loss: 0.042711; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1050 0.0694 0.0570 0.0466 0.0415 0.0383 0.0363 0.0348 0.0337 0.0328 0.0322 0.0317 0.0314 0.0311 0.0308 0.0307 

[TRAIN] Epoch[3](29/375); Loss: 0.062831; Backpropagation: 0.2884 sec; Batch: 2.0765 sec
0.1504 0.1042 0.0837 0.0703 0.0630 0.0581 0.0546 0.0519 0.0499 0.0481 0.0470 0.0461 0.0453 0.0447 0.0441 0.0438 

[TRAIN] Epoch[3](30/375); Loss: 0.060367; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1447 0.0963 0.0788 0.0692 0.0614 0.0560 0.0524 0.0498 0.0481 0.0467 0.0456 0.0445 0.0439 0.0433 0.0428 0.0424 

[TRAIN] Epoch[3](31/375); Loss: 0.041756; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0852 0.0597 0.0519 0.0453 0.0413 0.0393 0.0376 0.0364 0.0355 0.0347 0.0342 0.0338 0.0336 0.0333 0.0332 0.0331 

[TRAIN] Epoch[3](32/375); Loss: 0.068277; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1367 0.1026 0.0853 0.0743 0.0682 0.0643 0.0617 0.0598 0.0581 0.0567 0.0556 0.0548 0.0542 0.0537 0.0533 0.0530 

[TRAIN] Epoch[3](33/375); Loss: 0.060998; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1413 0.0999 0.0816 0.0692 0.0609 0.0553 0.0526 0.0504 0.0487 0.0472 0.0462 0.0454 0.0449 0.0444 0.0441 0.0439 

[TRAIN] Epoch[3](34/375); Loss: 0.048817; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1107 0.0765 0.0632 0.0545 0.0496 0.0459 0.0431 0.0411 0.0395 0.0385 0.0376 0.0369 0.0365 0.0361 0.0358 0.0355 

[TRAIN] Epoch[3](35/375); Loss: 0.060704; Backpropagation: 0.2889 sec; Batch: 2.0752 sec
0.1279 0.0989 0.0821 0.0691 0.0612 0.0561 0.0529 0.0507 0.0494 0.0481 0.0472 0.0465 0.0459 0.0455 0.0451 0.0449 

[TRAIN] Epoch[3](36/375); Loss: 0.049670; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1005 0.0773 0.0664 0.0559 0.0505 0.0471 0.0443 0.0426 0.0412 0.0401 0.0394 0.0387 0.0382 0.0378 0.0374 0.0372 

[TRAIN] Epoch[3](37/375); Loss: 0.047419; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1132 0.0796 0.0639 0.0516 0.0475 0.0441 0.0408 0.0389 0.0373 0.0362 0.0354 0.0348 0.0343 0.0339 0.0337 0.0335 

[TRAIN] Epoch[3](38/375); Loss: 0.047874; Backpropagation: 0.2879 sec; Batch: 2.0746 sec
0.1013 0.0830 0.0654 0.0530 0.0469 0.0435 0.0413 0.0397 0.0385 0.0376 0.0369 0.0363 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[3](39/375); Loss: 0.043103; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0810 0.0640 0.0542 0.0483 0.0444 0.0416 0.0395 0.0380 0.0367 0.0358 0.0351 0.0347 0.0343 0.0341 0.0340 0.0339 

[TRAIN] Epoch[3](40/375); Loss: 0.034325; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0676 0.0562 0.0452 0.0386 0.0344 0.0322 0.0304 0.0295 0.0286 0.0278 0.0272 0.0268 0.0265 0.0262 0.0261 0.0259 

[TRAIN] Epoch[3](41/375); Loss: 0.054233; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.0998 0.0833 0.0700 0.0620 0.0558 0.0523 0.0496 0.0476 0.0461 0.0449 0.0440 0.0433 0.0428 0.0424 0.0421 0.0419 

[TRAIN] Epoch[3](42/375); Loss: 0.052044; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0874 0.0700 0.0615 0.0563 0.0531 0.0510 0.0493 0.0478 0.0467 0.0458 0.0450 0.0445 0.0440 0.0437 0.0435 0.0433 

[TRAIN] Epoch[3](43/375); Loss: 0.054309; Backpropagation: 0.2884 sec; Batch: 2.0798 sec
0.0938 0.0799 0.0686 0.0607 0.0559 0.0527 0.0505 0.0487 0.0473 0.0463 0.0454 0.0447 0.0441 0.0437 0.0434 0.0432 

[TRAIN] Epoch[3](44/375); Loss: 0.063205; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1190 0.0915 0.0795 0.0698 0.0642 0.0603 0.0577 0.0557 0.0542 0.0530 0.0521 0.0515 0.0510 0.0507 0.0506 0.0504 

[TRAIN] Epoch[3](45/375); Loss: 0.057250; Backpropagation: 0.2886 sec; Batch: 2.0752 sec
0.1234 0.0934 0.0774 0.0640 0.0576 0.0528 0.0499 0.0477 0.0462 0.0452 0.0443 0.0436 0.0431 0.0427 0.0424 0.0423 

[TRAIN] Epoch[3](46/375); Loss: 0.064016; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.1082 0.0958 0.0831 0.0711 0.0652 0.0619 0.0591 0.0571 0.0557 0.0544 0.0534 0.0528 0.0522 0.0517 0.0515 0.0513 

[TRAIN] Epoch[3](47/375); Loss: 0.073208; Backpropagation: 0.2882 sec; Batch: 2.0737 sec
0.1511 0.1157 0.1017 0.0865 0.0748 0.0690 0.0650 0.0620 0.0598 0.0580 0.0566 0.0554 0.0547 0.0541 0.0536 0.0532 

[TRAIN] Epoch[3](48/375); Loss: 0.059047; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1074 0.0873 0.0725 0.0641 0.0600 0.0564 0.0545 0.0529 0.0515 0.0504 0.0494 0.0486 0.0480 0.0476 0.0472 0.0470 

[TRAIN] Epoch[3](49/375); Loss: 0.054039; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.1091 0.0790 0.0665 0.0589 0.0539 0.0510 0.0492 0.0474 0.0461 0.0450 0.0441 0.0436 0.0431 0.0428 0.0426 0.0425 

[TRAIN] Epoch[3](50/375); Loss: 0.050873; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1115 0.0852 0.0704 0.0585 0.0517 0.0474 0.0445 0.0423 0.0407 0.0393 0.0384 0.0377 0.0371 0.0367 0.0364 0.0362 

[TRAIN] Epoch[3](51/375); Loss: 0.039569; Backpropagation: 0.2884 sec; Batch: 2.0734 sec
0.0848 0.0631 0.0522 0.0444 0.0398 0.0370 0.0349 0.0333 0.0324 0.0315 0.0309 0.0304 0.0300 0.0297 0.0294 0.0293 

[TRAIN] Epoch[3](52/375); Loss: 0.052229; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0898 0.0706 0.0617 0.0564 0.0526 0.0503 0.0487 0.0475 0.0466 0.0457 0.0451 0.0446 0.0443 0.0441 0.0438 0.0437 

[TRAIN] Epoch[3](53/375); Loss: 0.053230; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.1082 0.0851 0.0706 0.0615 0.0548 0.0510 0.0482 0.0458 0.0441 0.0427 0.0417 0.0407 0.0400 0.0395 0.0391 0.0388 

[TRAIN] Epoch[3](54/375); Loss: 0.050990; Backpropagation: 0.2879 sec; Batch: 2.0729 sec
0.1144 0.0832 0.0657 0.0573 0.0509 0.0471 0.0443 0.0422 0.0411 0.0401 0.0394 0.0387 0.0382 0.0380 0.0377 0.0376 

[TRAIN] Epoch[3](55/375); Loss: 0.054065; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1174 0.0840 0.0676 0.0594 0.0544 0.0510 0.0484 0.0461 0.0447 0.0434 0.0427 0.0420 0.0415 0.0411 0.0408 0.0406 

[TRAIN] Epoch[3](56/375); Loss: 0.058539; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1268 0.0907 0.0739 0.0642 0.0580 0.0542 0.0515 0.0498 0.0484 0.0473 0.0465 0.0458 0.0453 0.0449 0.0447 0.0445 

[TRAIN] Epoch[3](57/375); Loss: 0.058236; Backpropagation: 0.2888 sec; Batch: 2.0746 sec
0.1380 0.0973 0.0808 0.0699 0.0606 0.0543 0.0501 0.0475 0.0454 0.0438 0.0426 0.0415 0.0408 0.0401 0.0397 0.0394 

[TRAIN] Epoch[3](58/375); Loss: 0.057736; Backpropagation: 0.2888 sec; Batch: 2.0743 sec
0.1159 0.0895 0.0737 0.0642 0.0573 0.0540 0.0512 0.0494 0.0482 0.0471 0.0465 0.0460 0.0456 0.0453 0.0450 0.0448 

[TRAIN] Epoch[3](59/375); Loss: 0.055912; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.1098 0.0873 0.0738 0.0622 0.0565 0.0529 0.0501 0.0484 0.0469 0.0456 0.0448 0.0442 0.0436 0.0432 0.0428 0.0426 

[TRAIN] Epoch[3](60/375); Loss: 0.054341; Backpropagation: 0.2884 sec; Batch: 2.0768 sec
0.1059 0.0826 0.0703 0.0590 0.0545 0.0513 0.0489 0.0473 0.0461 0.0451 0.0443 0.0437 0.0430 0.0428 0.0425 0.0423 

[TRAIN] Epoch[3](61/375); Loss: 0.060868; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1182 0.0872 0.0759 0.0664 0.0615 0.0583 0.0557 0.0536 0.0522 0.0510 0.0503 0.0496 0.0490 0.0486 0.0484 0.0481 

[TRAIN] Epoch[3](62/375); Loss: 0.052927; Backpropagation: 0.2883 sec; Batch: 2.0754 sec
0.1181 0.0794 0.0658 0.0584 0.0531 0.0497 0.0469 0.0451 0.0438 0.0427 0.0419 0.0411 0.0407 0.0403 0.0400 0.0398 

[TRAIN] Epoch[3](63/375); Loss: 0.060964; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1141 0.0884 0.0742 0.0672 0.0623 0.0588 0.0562 0.0543 0.0528 0.0515 0.0505 0.0498 0.0493 0.0490 0.0486 0.0484 

[TRAIN] Epoch[3](64/375); Loss: 0.033014; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.0836 0.0615 0.0475 0.0389 0.0329 0.0295 0.0272 0.0255 0.0244 0.0237 0.0231 0.0226 0.0223 0.0220 0.0219 0.0217 

[TRAIN] Epoch[3](65/375); Loss: 0.058753; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1196 0.0927 0.0767 0.0665 0.0597 0.0553 0.0525 0.0503 0.0487 0.0475 0.0466 0.0458 0.0451 0.0447 0.0443 0.0440 

[TRAIN] Epoch[3](66/375); Loss: 0.052260; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1003 0.0779 0.0636 0.0565 0.0521 0.0494 0.0475 0.0460 0.0449 0.0440 0.0433 0.0428 0.0424 0.0420 0.0418 0.0416 

[TRAIN] Epoch[3](67/375); Loss: 0.049833; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.1082 0.0806 0.0661 0.0558 0.0497 0.0456 0.0432 0.0416 0.0405 0.0395 0.0388 0.0383 0.0378 0.0375 0.0371 0.0369 

[TRAIN] Epoch[3](68/375); Loss: 0.051971; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0906 0.0709 0.0634 0.0574 0.0528 0.0504 0.0485 0.0471 0.0459 0.0449 0.0442 0.0437 0.0433 0.0430 0.0428 0.0427 

[TRAIN] Epoch[3](69/375); Loss: 0.055102; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.1136 0.0870 0.0721 0.0626 0.0569 0.0527 0.0495 0.0473 0.0456 0.0442 0.0432 0.0424 0.0417 0.0412 0.0409 0.0406 

[TRAIN] Epoch[3](70/375); Loss: 0.054852; Backpropagation: 0.2882 sec; Batch: 2.0733 sec
0.1070 0.0811 0.0682 0.0610 0.0564 0.0530 0.0506 0.0486 0.0469 0.0456 0.0445 0.0438 0.0433 0.0429 0.0425 0.0423 

[TRAIN] Epoch[3](71/375); Loss: 0.047481; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1008 0.0678 0.0571 0.0502 0.0462 0.0434 0.0420 0.0410 0.0401 0.0396 0.0391 0.0388 0.0386 0.0384 0.0383 0.0382 

[TRAIN] Epoch[3](72/375); Loss: 0.043281; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0896 0.0629 0.0541 0.0478 0.0431 0.0406 0.0387 0.0375 0.0364 0.0357 0.0352 0.0347 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[3](73/375); Loss: 0.035162; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.0904 0.0691 0.0503 0.0379 0.0334 0.0305 0.0286 0.0272 0.0261 0.0254 0.0247 0.0243 0.0240 0.0237 0.0235 0.0234 

[TRAIN] Epoch[3](74/375); Loss: 0.044153; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0982 0.0771 0.0605 0.0499 0.0440 0.0403 0.0381 0.0362 0.0349 0.0340 0.0333 0.0327 0.0322 0.0319 0.0317 0.0316 

[TRAIN] Epoch[3](75/375); Loss: 0.049244; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.1065 0.0831 0.0684 0.0573 0.0499 0.0459 0.0432 0.0410 0.0393 0.0381 0.0373 0.0364 0.0359 0.0355 0.0352 0.0349 

[TRAIN] Epoch[3](76/375); Loss: 0.047117; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0931 0.0759 0.0603 0.0502 0.0463 0.0439 0.0419 0.0406 0.0396 0.0387 0.0381 0.0376 0.0372 0.0371 0.0369 0.0367 

[TRAIN] Epoch[3](77/375); Loss: 0.029849; Backpropagation: 0.2887 sec; Batch: 2.0743 sec
0.0648 0.0487 0.0391 0.0328 0.0295 0.0274 0.0260 0.0250 0.0243 0.0238 0.0233 0.0230 0.0227 0.0225 0.0224 0.0222 

[TRAIN] Epoch[3](78/375); Loss: 0.043449; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1026 0.0754 0.0583 0.0481 0.0421 0.0390 0.0368 0.0354 0.0342 0.0333 0.0327 0.0321 0.0317 0.0314 0.0312 0.0310 

[TRAIN] Epoch[3](79/375); Loss: 0.046774; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0861 0.0676 0.0572 0.0510 0.0474 0.0451 0.0432 0.0418 0.0406 0.0396 0.0389 0.0385 0.0381 0.0379 0.0377 0.0375 

[TRAIN] Epoch[3](80/375); Loss: 0.050001; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.1047 0.0887 0.0709 0.0567 0.0495 0.0457 0.0433 0.0412 0.0400 0.0387 0.0379 0.0373 0.0368 0.0364 0.0362 0.0360 

[TRAIN] Epoch[3](81/375); Loss: 0.045491; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1017 0.0735 0.0569 0.0498 0.0454 0.0426 0.0400 0.0384 0.0371 0.0362 0.0355 0.0349 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[3](82/375); Loss: 0.046025; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.0915 0.0730 0.0596 0.0510 0.0464 0.0434 0.0412 0.0397 0.0384 0.0375 0.0368 0.0362 0.0358 0.0355 0.0353 0.0351 

[TRAIN] Epoch[3](83/375); Loss: 0.057740; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.1271 0.0915 0.0706 0.0614 0.0569 0.0539 0.0511 0.0492 0.0477 0.0467 0.0459 0.0452 0.0446 0.0442 0.0440 0.0438 

[TRAIN] Epoch[3](84/375); Loss: 0.049573; Backpropagation: 0.2886 sec; Batch: 2.0825 sec
0.0923 0.0660 0.0578 0.0537 0.0503 0.0482 0.0464 0.0448 0.0437 0.0428 0.0421 0.0416 0.0412 0.0409 0.0408 0.0406 

[TRAIN] Epoch[3](85/375); Loss: 0.059487; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1277 0.0993 0.0755 0.0637 0.0582 0.0551 0.0525 0.0507 0.0491 0.0478 0.0468 0.0460 0.0454 0.0449 0.0446 0.0444 

[TRAIN] Epoch[3](86/375); Loss: 0.037277; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0885 0.0759 0.0539 0.0428 0.0361 0.0330 0.0307 0.0290 0.0278 0.0269 0.0263 0.0257 0.0253 0.0251 0.0249 0.0248 

[TRAIN] Epoch[3](87/375); Loss: 0.065362; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1286 0.0979 0.0815 0.0715 0.0650 0.0614 0.0592 0.0572 0.0557 0.0546 0.0536 0.0529 0.0523 0.0518 0.0515 0.0512 

[TRAIN] Epoch[3](88/375); Loss: 0.064940; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.1159 0.0926 0.0787 0.0704 0.0654 0.0623 0.0598 0.0579 0.0567 0.0558 0.0550 0.0545 0.0540 0.0536 0.0534 0.0532 

[TRAIN] Epoch[3](89/375); Loss: 0.079087; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1329 0.1114 0.0957 0.0872 0.0819 0.0778 0.0745 0.0719 0.0699 0.0686 0.0674 0.0665 0.0657 0.0651 0.0646 0.0642 

[TRAIN] Epoch[3](90/375); Loss: 0.057109; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1285 0.1000 0.0782 0.0612 0.0550 0.0509 0.0485 0.0469 0.0454 0.0444 0.0436 0.0429 0.0425 0.0421 0.0419 0.0417 

[TRAIN] Epoch[3](91/375); Loss: 0.068003; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1299 0.0982 0.0805 0.0731 0.0682 0.0650 0.0625 0.0606 0.0591 0.0578 0.0568 0.0562 0.0557 0.0552 0.0548 0.0545 

[TRAIN] Epoch[3](92/375); Loss: 0.055374; Backpropagation: 0.2885 sec; Batch: 2.0806 sec
0.1025 0.0855 0.0696 0.0608 0.0560 0.0528 0.0506 0.0489 0.0475 0.0464 0.0456 0.0448 0.0443 0.0439 0.0436 0.0433 

[TRAIN] Epoch[3](93/375); Loss: 0.043246; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0996 0.0763 0.0585 0.0489 0.0430 0.0398 0.0375 0.0356 0.0340 0.0329 0.0321 0.0315 0.0310 0.0307 0.0304 0.0302 

[TRAIN] Epoch[3](94/375); Loss: 0.039721; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.0739 0.0623 0.0499 0.0434 0.0401 0.0378 0.0361 0.0349 0.0339 0.0331 0.0325 0.0321 0.0317 0.0314 0.0313 0.0311 

[TRAIN] Epoch[3](95/375); Loss: 0.037135; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0920 0.0643 0.0505 0.0431 0.0371 0.0336 0.0314 0.0297 0.0285 0.0276 0.0268 0.0264 0.0261 0.0258 0.0256 0.0254 

[TRAIN] Epoch[3](96/375); Loss: 0.066205; Backpropagation: 0.2881 sec; Batch: 2.0735 sec
0.1202 0.1010 0.0825 0.0747 0.0687 0.0642 0.0611 0.0587 0.0568 0.0554 0.0542 0.0534 0.0527 0.0522 0.0518 0.0516 

[TRAIN] Epoch[3](97/375); Loss: 0.043516; Backpropagation: 0.2886 sec; Batch: 2.0742 sec
0.0872 0.0644 0.0537 0.0484 0.0434 0.0408 0.0390 0.0377 0.0368 0.0361 0.0356 0.0352 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[3](98/375); Loss: 0.042133; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.0977 0.0762 0.0541 0.0468 0.0420 0.0384 0.0362 0.0346 0.0333 0.0324 0.0317 0.0310 0.0304 0.0300 0.0297 0.0295 

[TRAIN] Epoch[3](99/375); Loss: 0.043139; Backpropagation: 0.2888 sec; Batch: 2.0751 sec
0.0934 0.0706 0.0548 0.0462 0.0425 0.0398 0.0378 0.0364 0.0353 0.0344 0.0338 0.0334 0.0331 0.0329 0.0328 0.0328 

[TRAIN] Epoch[3](100/375); Loss: 0.040215; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0964 0.0682 0.0521 0.0448 0.0398 0.0368 0.0346 0.0329 0.0318 0.0308 0.0301 0.0296 0.0292 0.0289 0.0288 0.0286 

[TRAIN] Epoch[3](101/375); Loss: 0.057512; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1208 0.0894 0.0763 0.0655 0.0591 0.0556 0.0521 0.0493 0.0474 0.0459 0.0448 0.0439 0.0432 0.0427 0.0423 0.0419 

[TRAIN] Epoch[3](102/375); Loss: 0.057954; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1133 0.0881 0.0727 0.0636 0.0578 0.0546 0.0523 0.0505 0.0491 0.0480 0.0473 0.0467 0.0462 0.0460 0.0457 0.0456 

[TRAIN] Epoch[3](103/375); Loss: 0.050867; Backpropagation: 0.2889 sec; Batch: 2.0741 sec
0.1123 0.0839 0.0648 0.0554 0.0502 0.0469 0.0445 0.0427 0.0414 0.0404 0.0395 0.0390 0.0385 0.0383 0.0381 0.0379 

[TRAIN] Epoch[3](104/375); Loss: 0.038504; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0880 0.0644 0.0518 0.0430 0.0386 0.0357 0.0336 0.0319 0.0306 0.0298 0.0292 0.0286 0.0281 0.0278 0.0275 0.0273 

[TRAIN] Epoch[3](105/375); Loss: 0.042244; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.0837 0.0680 0.0542 0.0477 0.0433 0.0403 0.0381 0.0365 0.0352 0.0343 0.0335 0.0329 0.0325 0.0321 0.0319 0.0317 

[TRAIN] Epoch[3](106/375); Loss: 0.064619; Backpropagation: 0.2884 sec; Batch: 2.0747 sec
0.1170 0.0950 0.0770 0.0688 0.0645 0.0618 0.0597 0.0578 0.0566 0.0554 0.0547 0.0540 0.0534 0.0530 0.0527 0.0525 

[TRAIN] Epoch[3](107/375); Loss: 0.061996; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.1240 0.0939 0.0748 0.0672 0.0625 0.0590 0.0562 0.0543 0.0527 0.0516 0.0507 0.0499 0.0494 0.0490 0.0486 0.0482 

[TRAIN] Epoch[3](108/375); Loss: 0.048158; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0955 0.0887 0.0607 0.0512 0.0467 0.0444 0.0424 0.0409 0.0396 0.0388 0.0380 0.0374 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[3](109/375); Loss: 0.049948; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1109 0.1016 0.0725 0.0553 0.0467 0.0430 0.0409 0.0394 0.0382 0.0372 0.0365 0.0359 0.0356 0.0354 0.0351 0.0350 

[TRAIN] Epoch[3](110/375); Loss: 0.047636; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1030 0.0752 0.0614 0.0537 0.0489 0.0453 0.0425 0.0404 0.0390 0.0379 0.0370 0.0364 0.0359 0.0355 0.0352 0.0349 

[TRAIN] Epoch[3](111/375); Loss: 0.045589; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1010 0.0715 0.0575 0.0507 0.0455 0.0422 0.0402 0.0385 0.0373 0.0364 0.0357 0.0352 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[3](112/375); Loss: 0.052484; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1011 0.0857 0.0660 0.0581 0.0529 0.0499 0.0474 0.0458 0.0443 0.0433 0.0424 0.0415 0.0409 0.0405 0.0401 0.0399 

[TRAIN] Epoch[3](113/375); Loss: 0.068907; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.1162 0.0986 0.0825 0.0759 0.0704 0.0672 0.0647 0.0626 0.0610 0.0597 0.0587 0.0579 0.0573 0.0569 0.0565 0.0563 

[TRAIN] Epoch[3](114/375); Loss: 0.042688; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.0939 0.0741 0.0548 0.0464 0.0419 0.0389 0.0371 0.0360 0.0346 0.0337 0.0330 0.0323 0.0320 0.0316 0.0314 0.0313 

[TRAIN] Epoch[3](115/375); Loss: 0.041957; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0939 0.0687 0.0540 0.0455 0.0420 0.0394 0.0375 0.0357 0.0342 0.0331 0.0322 0.0317 0.0313 0.0309 0.0307 0.0305 

[TRAIN] Epoch[3](116/375); Loss: 0.046166; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0861 0.0698 0.0573 0.0514 0.0478 0.0448 0.0426 0.0409 0.0395 0.0385 0.0378 0.0371 0.0367 0.0363 0.0361 0.0359 

[TRAIN] Epoch[3](117/375); Loss: 0.044397; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0783 0.0602 0.0530 0.0485 0.0451 0.0430 0.0413 0.0401 0.0392 0.0385 0.0380 0.0376 0.0373 0.0369 0.0368 0.0366 

[TRAIN] Epoch[3](118/375); Loss: 0.038865; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0946 0.0708 0.0503 0.0427 0.0385 0.0352 0.0333 0.0317 0.0305 0.0294 0.0286 0.0279 0.0275 0.0272 0.0269 0.0268 

[TRAIN] Epoch[3](119/375); Loss: 0.052375; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1017 0.0827 0.0666 0.0575 0.0527 0.0495 0.0474 0.0457 0.0442 0.0432 0.0424 0.0417 0.0412 0.0408 0.0405 0.0403 

[TRAIN] Epoch[3](120/375); Loss: 0.051246; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1218 0.0971 0.0656 0.0549 0.0492 0.0455 0.0431 0.0413 0.0400 0.0390 0.0381 0.0375 0.0371 0.0368 0.0366 0.0364 

[TRAIN] Epoch[3](121/375); Loss: 0.054138; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1105 0.0930 0.0720 0.0619 0.0550 0.0509 0.0481 0.0458 0.0442 0.0430 0.0419 0.0410 0.0403 0.0399 0.0395 0.0393 

[TRAIN] Epoch[3](122/375); Loss: 0.064301; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1320 0.1057 0.0794 0.0700 0.0645 0.0601 0.0577 0.0557 0.0538 0.0523 0.0512 0.0503 0.0496 0.0491 0.0488 0.0485 

[TRAIN] Epoch[3](123/375); Loss: 0.052894; Backpropagation: 0.2882 sec; Batch: 2.0766 sec
0.0961 0.0841 0.0656 0.0585 0.0536 0.0506 0.0485 0.0467 0.0454 0.0443 0.0433 0.0427 0.0422 0.0418 0.0416 0.0413 

[TRAIN] Epoch[3](124/375); Loss: 0.062106; Backpropagation: 0.2883 sec; Batch: 2.0758 sec
0.1211 0.1036 0.0747 0.0662 0.0617 0.0580 0.0557 0.0539 0.0524 0.0513 0.0504 0.0497 0.0493 0.0488 0.0485 0.0483 

[TRAIN] Epoch[3](125/375); Loss: 0.043575; Backpropagation: 0.2881 sec; Batch: 2.0738 sec
0.1193 0.0897 0.0579 0.0464 0.0400 0.0369 0.0345 0.0331 0.0317 0.0310 0.0303 0.0299 0.0295 0.0292 0.0290 0.0289 

[TRAIN] Epoch[3](126/375); Loss: 0.045695; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0899 0.0747 0.0572 0.0502 0.0464 0.0433 0.0415 0.0397 0.0383 0.0373 0.0365 0.0360 0.0355 0.0352 0.0349 0.0347 

[TRAIN] Epoch[3](127/375); Loss: 0.061940; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.1204 0.1046 0.0760 0.0675 0.0625 0.0588 0.0559 0.0537 0.0521 0.0508 0.0497 0.0489 0.0482 0.0477 0.0473 0.0470 

[TRAIN] Epoch[3](128/375); Loss: 0.058884; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1147 0.0976 0.0749 0.0643 0.0592 0.0552 0.0525 0.0507 0.0492 0.0481 0.0472 0.0465 0.0460 0.0456 0.0453 0.0451 

[TRAIN] Epoch[3](129/375); Loss: 0.055018; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1129 0.0902 0.0686 0.0598 0.0547 0.0512 0.0486 0.0469 0.0456 0.0446 0.0438 0.0433 0.0429 0.0426 0.0424 0.0421 

[TRAIN] Epoch[3](130/375); Loss: 0.048751; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.1031 0.0789 0.0628 0.0535 0.0487 0.0457 0.0434 0.0414 0.0402 0.0391 0.0383 0.0377 0.0373 0.0369 0.0366 0.0363 

[TRAIN] Epoch[3](131/375); Loss: 0.051485; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.1023 0.0866 0.0634 0.0554 0.0513 0.0482 0.0460 0.0444 0.0431 0.0421 0.0413 0.0407 0.0403 0.0399 0.0395 0.0392 

[TRAIN] Epoch[3](132/375); Loss: 0.051047; Backpropagation: 0.2887 sec; Batch: 2.0742 sec
0.1118 0.0881 0.0678 0.0567 0.0504 0.0470 0.0446 0.0428 0.0412 0.0401 0.0391 0.0384 0.0378 0.0373 0.0370 0.0367 

[TRAIN] Epoch[3](133/375); Loss: 0.067541; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.1285 0.1020 0.0818 0.0719 0.0677 0.0642 0.0618 0.0597 0.0583 0.0571 0.0560 0.0552 0.0547 0.0542 0.0539 0.0536 

[TRAIN] Epoch[3](134/375); Loss: 0.053164; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.1266 0.1145 0.0795 0.0588 0.0498 0.0458 0.0435 0.0411 0.0391 0.0378 0.0369 0.0363 0.0358 0.0353 0.0350 0.0347 

[TRAIN] Epoch[3](135/375); Loss: 0.052827; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.1076 0.0909 0.0664 0.0568 0.0518 0.0490 0.0467 0.0452 0.0437 0.0427 0.0420 0.0413 0.0408 0.0405 0.0402 0.0399 

[TRAIN] Epoch[3](136/375); Loss: 0.037293; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0879 0.0732 0.0496 0.0400 0.0353 0.0327 0.0311 0.0298 0.0288 0.0281 0.0276 0.0271 0.0267 0.0265 0.0262 0.0261 

[TRAIN] Epoch[3](137/375); Loss: 0.033633; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0733 0.0578 0.0433 0.0372 0.0335 0.0311 0.0295 0.0282 0.0272 0.0265 0.0259 0.0254 0.0251 0.0249 0.0247 0.0246 

[TRAIN] Epoch[3](138/375); Loss: 0.057945; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1321 0.1202 0.0891 0.0668 0.0575 0.0515 0.0474 0.0448 0.0429 0.0415 0.0405 0.0397 0.0390 0.0385 0.0381 0.0377 

[TRAIN] Epoch[3](139/375); Loss: 0.039843; Backpropagation: 0.2881 sec; Batch: 2.0735 sec
0.0823 0.0703 0.0526 0.0459 0.0404 0.0368 0.0351 0.0335 0.0322 0.0313 0.0305 0.0299 0.0295 0.0292 0.0290 0.0289 

[TRAIN] Epoch[3](140/375); Loss: 0.048392; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1033 0.0841 0.0607 0.0519 0.0471 0.0444 0.0423 0.0408 0.0395 0.0386 0.0379 0.0374 0.0369 0.0366 0.0365 0.0363 

[TRAIN] Epoch[3](141/375); Loss: 0.058650; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1101 0.0963 0.0715 0.0633 0.0586 0.0555 0.0531 0.0514 0.0501 0.0489 0.0480 0.0472 0.0466 0.0462 0.0459 0.0457 

[TRAIN] Epoch[3](142/375); Loss: 0.051614; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.0945 0.0770 0.0624 0.0559 0.0519 0.0493 0.0474 0.0459 0.0449 0.0440 0.0432 0.0426 0.0422 0.0418 0.0415 0.0413 

[TRAIN] Epoch[3](143/375); Loss: 0.050577; Backpropagation: 0.2886 sec; Batch: 2.0748 sec
0.1109 0.0894 0.0638 0.0527 0.0476 0.0449 0.0434 0.0421 0.0412 0.0404 0.0398 0.0393 0.0388 0.0385 0.0383 0.0381 

[TRAIN] Epoch[3](144/375); Loss: 0.052819; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1300 0.1035 0.0717 0.0566 0.0503 0.0467 0.0441 0.0420 0.0404 0.0391 0.0382 0.0374 0.0369 0.0363 0.0360 0.0357 

[TRAIN] Epoch[3](145/375); Loss: 0.058895; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.1335 0.1117 0.0770 0.0620 0.0556 0.0520 0.0495 0.0478 0.0467 0.0456 0.0448 0.0441 0.0435 0.0431 0.0428 0.0426 

[TRAIN] Epoch[3](146/375); Loss: 0.044147; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.0935 0.0742 0.0538 0.0470 0.0431 0.0407 0.0389 0.0376 0.0366 0.0358 0.0352 0.0347 0.0343 0.0339 0.0337 0.0335 

[TRAIN] Epoch[3](147/375); Loss: 0.057748; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1094 0.0948 0.0687 0.0620 0.0570 0.0541 0.0522 0.0506 0.0493 0.0482 0.0474 0.0468 0.0464 0.0460 0.0457 0.0454 

[TRAIN] Epoch[3](148/375); Loss: 0.058376; Backpropagation: 0.2886 sec; Batch: 2.0743 sec
0.1174 0.0912 0.0712 0.0617 0.0576 0.0545 0.0523 0.0506 0.0494 0.0485 0.0479 0.0472 0.0466 0.0463 0.0460 0.0457 

[TRAIN] Epoch[3](149/375); Loss: 0.046534; Backpropagation: 0.2880 sec; Batch: 2.0737 sec
0.1103 0.0853 0.0596 0.0495 0.0443 0.0412 0.0393 0.0376 0.0365 0.0358 0.0351 0.0346 0.0343 0.0340 0.0337 0.0335 

[TRAIN] Epoch[3](150/375); Loss: 0.039487; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0869 0.0625 0.0488 0.0419 0.0389 0.0367 0.0348 0.0337 0.0327 0.0320 0.0314 0.0309 0.0306 0.0302 0.0299 0.0298 

[TRAIN] Epoch[3](151/375); Loss: 0.059030; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.1377 0.1131 0.0797 0.0637 0.0569 0.0526 0.0497 0.0478 0.0460 0.0447 0.0437 0.0429 0.0423 0.0417 0.0412 0.0410 

[TRAIN] Epoch[3](152/375); Loss: 0.042189; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0943 0.0731 0.0536 0.0458 0.0420 0.0392 0.0370 0.0352 0.0340 0.0330 0.0323 0.0317 0.0313 0.0311 0.0308 0.0306 

[TRAIN] Epoch[3](153/375); Loss: 0.050106; Backpropagation: 0.2880 sec; Batch: 2.0731 sec
0.1151 0.0960 0.0696 0.0555 0.0486 0.0441 0.0417 0.0401 0.0389 0.0379 0.0370 0.0363 0.0357 0.0353 0.0350 0.0347 

[TRAIN] Epoch[3](154/375); Loss: 0.052143; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1128 0.0955 0.0686 0.0570 0.0513 0.0481 0.0454 0.0434 0.0419 0.0407 0.0398 0.0389 0.0384 0.0379 0.0375 0.0373 

[TRAIN] Epoch[3](155/375); Loss: 0.045659; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.1040 0.0833 0.0591 0.0499 0.0450 0.0419 0.0395 0.0377 0.0363 0.0352 0.0344 0.0336 0.0332 0.0328 0.0325 0.0323 

[TRAIN] Epoch[3](156/375); Loss: 0.062011; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1061 0.0895 0.0767 0.0685 0.0637 0.0605 0.0583 0.0562 0.0545 0.0532 0.0523 0.0515 0.0508 0.0504 0.0501 0.0499 

[TRAIN] Epoch[3](157/375); Loss: 0.045179; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0931 0.0769 0.0566 0.0496 0.0455 0.0422 0.0402 0.0385 0.0372 0.0363 0.0356 0.0350 0.0345 0.0341 0.0338 0.0336 

[TRAIN] Epoch[3](158/375); Loss: 0.046742; Backpropagation: 0.2879 sec; Batch: 2.0735 sec
0.0830 0.0713 0.0576 0.0513 0.0482 0.0455 0.0433 0.0417 0.0404 0.0394 0.0387 0.0381 0.0377 0.0374 0.0371 0.0369 

[TRAIN] Epoch[3](159/375); Loss: 0.048149; Backpropagation: 0.2880 sec; Batch: 2.0736 sec
0.1061 0.0703 0.0597 0.0536 0.0479 0.0446 0.0424 0.0408 0.0398 0.0391 0.0385 0.0381 0.0377 0.0374 0.0372 0.0371 

[TRAIN] Epoch[3](160/375); Loss: 0.060920; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.1227 0.1061 0.0777 0.0663 0.0606 0.0568 0.0540 0.0518 0.0502 0.0490 0.0482 0.0474 0.0467 0.0461 0.0457 0.0453 

[TRAIN] Epoch[3](161/375); Loss: 0.067033; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.1319 0.1159 0.0945 0.0785 0.0695 0.0627 0.0589 0.0564 0.0541 0.0525 0.0515 0.0505 0.0497 0.0490 0.0486 0.0482 

[TRAIN] Epoch[3](162/375); Loss: 0.049868; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.1046 0.0788 0.0629 0.0555 0.0505 0.0474 0.0451 0.0432 0.0415 0.0402 0.0393 0.0386 0.0382 0.0377 0.0373 0.0371 

[TRAIN] Epoch[3](163/375); Loss: 0.059832; Backpropagation: 0.2887 sec; Batch: 2.0735 sec
0.1213 0.0952 0.0740 0.0658 0.0608 0.0570 0.0544 0.0519 0.0502 0.0488 0.0478 0.0470 0.0463 0.0458 0.0456 0.0453 

[TRAIN] Epoch[3](164/375); Loss: 0.022286; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.0616 0.0495 0.0317 0.0249 0.0206 0.0186 0.0174 0.0164 0.0157 0.0151 0.0147 0.0144 0.0142 0.0140 0.0139 0.0138 

[TRAIN] Epoch[3](165/375); Loss: 0.069463; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1332 0.1149 0.0888 0.0760 0.0697 0.0654 0.0623 0.0602 0.0586 0.0571 0.0559 0.0550 0.0543 0.0537 0.0533 0.0530 

[TRAIN] Epoch[3](166/375); Loss: 0.047373; Backpropagation: 0.2881 sec; Batch: 2.0735 sec
0.0973 0.0788 0.0597 0.0525 0.0483 0.0450 0.0426 0.0406 0.0391 0.0380 0.0372 0.0366 0.0360 0.0357 0.0354 0.0352 

[TRAIN] Epoch[3](167/375); Loss: 0.059788; Backpropagation: 0.2880 sec; Batch: 2.0738 sec
0.1175 0.0992 0.0755 0.0651 0.0600 0.0563 0.0535 0.0516 0.0502 0.0488 0.0479 0.0471 0.0465 0.0461 0.0458 0.0456 

[TRAIN] Epoch[3](168/375); Loss: 0.055532; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1308 0.0976 0.0751 0.0627 0.0561 0.0512 0.0478 0.0454 0.0434 0.0420 0.0410 0.0402 0.0395 0.0390 0.0385 0.0382 

[TRAIN] Epoch[3](169/375); Loss: 0.049009; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1020 0.0770 0.0596 0.0512 0.0479 0.0454 0.0437 0.0420 0.0411 0.0404 0.0399 0.0393 0.0390 0.0387 0.0386 0.0384 

[TRAIN] Epoch[3](170/375); Loss: 0.051541; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1000 0.0818 0.0644 0.0566 0.0523 0.0493 0.0471 0.0453 0.0437 0.0426 0.0415 0.0408 0.0402 0.0399 0.0396 0.0394 

[TRAIN] Epoch[3](171/375); Loss: 0.058047; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.1086 0.0854 0.0711 0.0645 0.0598 0.0564 0.0540 0.0518 0.0502 0.0489 0.0478 0.0470 0.0464 0.0459 0.0456 0.0453 

[TRAIN] Epoch[3](172/375); Loss: 0.073715; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.1400 0.1059 0.0911 0.0806 0.0751 0.0714 0.0684 0.0659 0.0638 0.0622 0.0611 0.0601 0.0593 0.0587 0.0582 0.0578 

[TRAIN] Epoch[3](173/375); Loss: 0.052943; Backpropagation: 0.2885 sec; Batch: 2.0817 sec
0.1075 0.0853 0.0681 0.0587 0.0541 0.0504 0.0476 0.0454 0.0439 0.0429 0.0419 0.0412 0.0407 0.0401 0.0398 0.0396 

[TRAIN] Epoch[3](174/375); Loss: 0.033747; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0932 0.0585 0.0431 0.0358 0.0319 0.0295 0.0278 0.0265 0.0256 0.0249 0.0244 0.0241 0.0238 0.0237 0.0235 0.0235 

[TRAIN] Epoch[3](175/375); Loss: 0.044820; Backpropagation: 0.2877 sec; Batch: 2.0730 sec
0.0930 0.0737 0.0563 0.0486 0.0445 0.0417 0.0399 0.0384 0.0373 0.0363 0.0356 0.0350 0.0346 0.0343 0.0341 0.0339 

[TRAIN] Epoch[3](176/375); Loss: 0.047191; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1021 0.0806 0.0591 0.0503 0.0458 0.0433 0.0414 0.0400 0.0387 0.0377 0.0370 0.0365 0.0361 0.0358 0.0355 0.0354 

[TRAIN] Epoch[3](177/375); Loss: 0.046083; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.1061 0.0863 0.0605 0.0499 0.0444 0.0414 0.0394 0.0375 0.0362 0.0352 0.0345 0.0339 0.0335 0.0332 0.0328 0.0327 

[TRAIN] Epoch[3](178/375); Loss: 0.046980; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0968 0.0789 0.0591 0.0505 0.0460 0.0431 0.0414 0.0399 0.0388 0.0380 0.0374 0.0370 0.0366 0.0363 0.0361 0.0359 

[TRAIN] Epoch[3](179/375); Loss: 0.056006; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1071 0.0833 0.0696 0.0619 0.0579 0.0545 0.0518 0.0496 0.0480 0.0467 0.0457 0.0449 0.0443 0.0439 0.0436 0.0433 

[TRAIN] Epoch[3](180/375); Loss: 0.049522; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1026 0.0813 0.0628 0.0544 0.0493 0.0461 0.0440 0.0424 0.0410 0.0399 0.0392 0.0385 0.0381 0.0378 0.0376 0.0374 

[TRAIN] Epoch[3](181/375); Loss: 0.051540; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.0863 0.0717 0.0611 0.0565 0.0532 0.0506 0.0485 0.0471 0.0460 0.0449 0.0442 0.0436 0.0432 0.0429 0.0426 0.0423 

[TRAIN] Epoch[3](182/375); Loss: 0.048403; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1048 0.0801 0.0650 0.0558 0.0500 0.0461 0.0430 0.0407 0.0391 0.0377 0.0367 0.0360 0.0355 0.0350 0.0347 0.0344 

[TRAIN] Epoch[3](183/375); Loss: 0.049624; Backpropagation: 0.2887 sec; Batch: 2.0749 sec
0.1147 0.0857 0.0638 0.0545 0.0493 0.0456 0.0427 0.0410 0.0397 0.0384 0.0375 0.0369 0.0365 0.0361 0.0359 0.0357 

[TRAIN] Epoch[3](184/375); Loss: 0.047806; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0891 0.0724 0.0569 0.0510 0.0479 0.0453 0.0436 0.0422 0.0413 0.0405 0.0399 0.0395 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[3](185/375); Loss: 0.066186; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1197 0.0983 0.0831 0.0740 0.0681 0.0644 0.0612 0.0589 0.0572 0.0559 0.0547 0.0538 0.0530 0.0526 0.0522 0.0519 

[TRAIN] Epoch[3](186/375); Loss: 0.061476; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.1301 0.1044 0.0806 0.0692 0.0629 0.0582 0.0548 0.0520 0.0499 0.0483 0.0472 0.0463 0.0456 0.0451 0.0447 0.0444 

[TRAIN] Epoch[3](187/375); Loss: 0.029082; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0828 0.0581 0.0386 0.0314 0.0271 0.0244 0.0227 0.0217 0.0210 0.0205 0.0201 0.0197 0.0195 0.0193 0.0192 0.0191 

[TRAIN] Epoch[3](188/375); Loss: 0.045404; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.0950 0.0739 0.0581 0.0505 0.0462 0.0429 0.0407 0.0390 0.0375 0.0363 0.0356 0.0350 0.0345 0.0341 0.0337 0.0335 

[TRAIN] Epoch[3](189/375); Loss: 0.036851; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0855 0.0647 0.0498 0.0424 0.0368 0.0331 0.0310 0.0298 0.0288 0.0280 0.0274 0.0270 0.0267 0.0265 0.0263 0.0261 

[TRAIN] Epoch[3](190/375); Loss: 0.039497; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.0873 0.0644 0.0499 0.0432 0.0390 0.0364 0.0345 0.0331 0.0322 0.0314 0.0309 0.0305 0.0301 0.0299 0.0297 0.0295 

[TRAIN] Epoch[3](191/375); Loss: 0.045210; Backpropagation: 0.2887 sec; Batch: 2.0750 sec
0.0946 0.0655 0.0534 0.0469 0.0437 0.0417 0.0404 0.0394 0.0387 0.0381 0.0376 0.0371 0.0368 0.0365 0.0364 0.0364 

[TRAIN] Epoch[3](192/375); Loss: 0.056062; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1074 0.0881 0.0690 0.0611 0.0569 0.0538 0.0511 0.0493 0.0478 0.0467 0.0457 0.0450 0.0443 0.0438 0.0435 0.0432 

[TRAIN] Epoch[3](193/375); Loss: 0.039414; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.0932 0.0662 0.0503 0.0421 0.0382 0.0356 0.0337 0.0324 0.0313 0.0307 0.0302 0.0298 0.0295 0.0292 0.0291 0.0290 

[TRAIN] Epoch[3](194/375); Loss: 0.066928; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1227 0.1018 0.0815 0.0731 0.0683 0.0644 0.0617 0.0596 0.0579 0.0565 0.0555 0.0546 0.0539 0.0534 0.0531 0.0528 

[TRAIN] Epoch[3](195/375); Loss: 0.058768; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1253 0.1008 0.0773 0.0661 0.0601 0.0544 0.0506 0.0482 0.0468 0.0458 0.0450 0.0445 0.0441 0.0439 0.0437 0.0436 

[TRAIN] Epoch[3](196/375); Loss: 0.038111; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0894 0.0743 0.0509 0.0427 0.0377 0.0346 0.0323 0.0306 0.0294 0.0284 0.0276 0.0271 0.0266 0.0263 0.0260 0.0258 

[TRAIN] Epoch[3](197/375); Loss: 0.060483; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.1114 0.0920 0.0760 0.0682 0.0625 0.0586 0.0554 0.0531 0.0515 0.0502 0.0493 0.0487 0.0482 0.0478 0.0475 0.0473 

[TRAIN] Epoch[3](198/375); Loss: 0.042925; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0870 0.0690 0.0546 0.0479 0.0434 0.0405 0.0386 0.0369 0.0356 0.0347 0.0341 0.0335 0.0331 0.0328 0.0326 0.0325 

[TRAIN] Epoch[3](199/375); Loss: 0.044277; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1056 0.0940 0.0699 0.0523 0.0428 0.0375 0.0352 0.0336 0.0323 0.0311 0.0303 0.0296 0.0291 0.0287 0.0284 0.0282 

[TRAIN] Epoch[3](200/375); Loss: 0.041115; Backpropagation: 0.2880 sec; Batch: 2.0739 sec
0.0817 0.0676 0.0508 0.0456 0.0417 0.0390 0.0371 0.0358 0.0345 0.0335 0.0327 0.0322 0.0318 0.0315 0.0313 0.0311 

[TRAIN] Epoch[3](201/375); Loss: 0.053354; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0983 0.0797 0.0655 0.0584 0.0545 0.0516 0.0494 0.0475 0.0461 0.0449 0.0441 0.0435 0.0430 0.0426 0.0423 0.0421 

[TRAIN] Epoch[3](202/375); Loss: 0.045917; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.0825 0.0670 0.0564 0.0505 0.0469 0.0441 0.0422 0.0409 0.0398 0.0390 0.0383 0.0379 0.0376 0.0374 0.0371 0.0370 

[TRAIN] Epoch[3](203/375); Loss: 0.044770; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0998 0.0725 0.0560 0.0483 0.0438 0.0412 0.0393 0.0379 0.0368 0.0359 0.0351 0.0347 0.0342 0.0338 0.0336 0.0334 

[TRAIN] Epoch[3](204/375); Loss: 0.064376; Backpropagation: 0.2887 sec; Batch: 2.0738 sec
0.1170 0.0904 0.0774 0.0699 0.0651 0.0623 0.0599 0.0577 0.0562 0.0550 0.0543 0.0537 0.0532 0.0529 0.0527 0.0525 

[TRAIN] Epoch[3](205/375); Loss: 0.050101; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1189 0.0980 0.0763 0.0584 0.0478 0.0430 0.0407 0.0388 0.0375 0.0365 0.0356 0.0349 0.0343 0.0339 0.0337 0.0334 

[TRAIN] Epoch[3](206/375); Loss: 0.049123; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1113 0.0761 0.0611 0.0525 0.0481 0.0450 0.0430 0.0416 0.0404 0.0395 0.0387 0.0383 0.0379 0.0376 0.0375 0.0373 

[TRAIN] Epoch[3](207/375); Loss: 0.042819; Backpropagation: 0.2884 sec; Batch: 2.0751 sec
0.0817 0.0616 0.0519 0.0461 0.0434 0.0412 0.0395 0.0380 0.0369 0.0361 0.0355 0.0351 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[3](208/375); Loss: 0.048558; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.0921 0.0679 0.0573 0.0521 0.0493 0.0470 0.0451 0.0436 0.0425 0.0416 0.0408 0.0402 0.0398 0.0394 0.0392 0.0391 

[TRAIN] Epoch[3](209/375); Loss: 0.050385; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.1064 0.0811 0.0653 0.0571 0.0517 0.0479 0.0451 0.0431 0.0416 0.0402 0.0392 0.0384 0.0379 0.0374 0.0370 0.0368 

[TRAIN] Epoch[3](210/375); Loss: 0.041947; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0877 0.0687 0.0537 0.0460 0.0421 0.0394 0.0375 0.0359 0.0346 0.0337 0.0330 0.0325 0.0320 0.0317 0.0314 0.0313 

[TRAIN] Epoch[3](211/375); Loss: 0.038351; Backpropagation: 0.2876 sec; Batch: 2.0735 sec
0.0857 0.0681 0.0500 0.0427 0.0383 0.0356 0.0335 0.0318 0.0306 0.0296 0.0289 0.0283 0.0280 0.0277 0.0275 0.0274 

[TRAIN] Epoch[3](212/375); Loss: 0.037550; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.0787 0.0582 0.0457 0.0397 0.0371 0.0350 0.0337 0.0326 0.0316 0.0309 0.0303 0.0299 0.0296 0.0294 0.0292 0.0291 

[TRAIN] Epoch[3](213/375); Loss: 0.059212; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1230 0.1059 0.0858 0.0694 0.0611 0.0551 0.0502 0.0479 0.0466 0.0452 0.0442 0.0435 0.0430 0.0425 0.0422 0.0420 

[TRAIN] Epoch[3](214/375); Loss: 0.034493; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.0869 0.0600 0.0434 0.0365 0.0331 0.0310 0.0293 0.0281 0.0273 0.0265 0.0258 0.0253 0.0250 0.0248 0.0246 0.0244 

[TRAIN] Epoch[3](215/375); Loss: 0.046094; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0958 0.0751 0.0589 0.0514 0.0472 0.0441 0.0418 0.0397 0.0381 0.0370 0.0360 0.0353 0.0347 0.0344 0.0341 0.0339 

[TRAIN] Epoch[3](216/375); Loss: 0.045966; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.0936 0.0713 0.0565 0.0508 0.0469 0.0439 0.0417 0.0400 0.0386 0.0375 0.0368 0.0363 0.0358 0.0355 0.0352 0.0350 

[TRAIN] Epoch[3](217/375); Loss: 0.044659; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1096 0.0714 0.0547 0.0478 0.0439 0.0411 0.0391 0.0373 0.0360 0.0349 0.0342 0.0336 0.0332 0.0328 0.0326 0.0324 

[TRAIN] Epoch[3](218/375); Loss: 0.060103; Backpropagation: 0.2880 sec; Batch: 2.0725 sec
0.1329 0.1090 0.0813 0.0689 0.0605 0.0547 0.0512 0.0492 0.0475 0.0460 0.0449 0.0442 0.0435 0.0430 0.0426 0.0423 

[TRAIN] Epoch[3](219/375); Loss: 0.055951; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0997 0.0826 0.0707 0.0624 0.0570 0.0541 0.0517 0.0497 0.0483 0.0472 0.0465 0.0458 0.0454 0.0450 0.0447 0.0445 

[TRAIN] Epoch[3](220/375); Loss: 0.038963; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0830 0.0689 0.0506 0.0430 0.0390 0.0362 0.0341 0.0327 0.0315 0.0306 0.0300 0.0294 0.0290 0.0287 0.0285 0.0283 

[TRAIN] Epoch[3](221/375); Loss: 0.035619; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0829 0.0623 0.0450 0.0374 0.0338 0.0319 0.0306 0.0295 0.0287 0.0280 0.0275 0.0269 0.0266 0.0264 0.0262 0.0261 

[TRAIN] Epoch[3](222/375); Loss: 0.043483; Backpropagation: 0.2880 sec; Batch: 2.0736 sec
0.0826 0.0648 0.0533 0.0477 0.0443 0.0417 0.0397 0.0385 0.0374 0.0366 0.0358 0.0353 0.0349 0.0346 0.0344 0.0342 

[TRAIN] Epoch[3](223/375); Loss: 0.035777; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0736 0.0491 0.0417 0.0372 0.0350 0.0335 0.0324 0.0315 0.0309 0.0303 0.0300 0.0297 0.0295 0.0294 0.0293 0.0293 

[TRAIN] Epoch[3](224/375); Loss: 0.044397; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1073 0.0777 0.0601 0.0495 0.0438 0.0399 0.0369 0.0354 0.0342 0.0334 0.0328 0.0323 0.0320 0.0318 0.0316 0.0315 

[TRAIN] Epoch[3](225/375); Loss: 0.026221; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.0713 0.0421 0.0328 0.0275 0.0249 0.0232 0.0220 0.0211 0.0204 0.0199 0.0196 0.0192 0.0191 0.0189 0.0188 0.0187 

[TRAIN] Epoch[3](226/375); Loss: 0.046408; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.0913 0.0689 0.0579 0.0519 0.0481 0.0452 0.0428 0.0407 0.0394 0.0383 0.0375 0.0369 0.0364 0.0360 0.0357 0.0354 

[TRAIN] Epoch[3](227/375); Loss: 0.051120; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.1062 0.0818 0.0635 0.0541 0.0501 0.0477 0.0457 0.0441 0.0429 0.0418 0.0411 0.0405 0.0401 0.0397 0.0394 0.0392 

[TRAIN] Epoch[3](228/375); Loss: 0.052194; Backpropagation: 0.2884 sec; Batch: 2.0730 sec
0.0992 0.0804 0.0625 0.0557 0.0523 0.0495 0.0477 0.0463 0.0451 0.0441 0.0432 0.0426 0.0421 0.0417 0.0415 0.0413 

[TRAIN] Epoch[3](229/375); Loss: 0.032191; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0696 0.0491 0.0399 0.0351 0.0320 0.0302 0.0289 0.0278 0.0269 0.0261 0.0256 0.0252 0.0249 0.0248 0.0246 0.0244 

[TRAIN] Epoch[3](230/375); Loss: 0.034698; Backpropagation: 0.2881 sec; Batch: 2.0726 sec
0.0923 0.0623 0.0452 0.0372 0.0332 0.0306 0.0289 0.0277 0.0266 0.0257 0.0251 0.0246 0.0243 0.0241 0.0238 0.0237 

[TRAIN] Epoch[3](231/375); Loss: 0.055006; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.1089 0.0843 0.0669 0.0593 0.0550 0.0521 0.0500 0.0482 0.0469 0.0458 0.0450 0.0443 0.0438 0.0435 0.0432 0.0430 

[TRAIN] Epoch[3](232/375); Loss: 0.047219; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1010 0.0814 0.0629 0.0532 0.0478 0.0443 0.0417 0.0398 0.0383 0.0371 0.0362 0.0354 0.0348 0.0343 0.0339 0.0337 

[TRAIN] Epoch[3](233/375); Loss: 0.033323; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0838 0.0543 0.0398 0.0349 0.0320 0.0301 0.0287 0.0274 0.0266 0.0260 0.0256 0.0252 0.0250 0.0247 0.0246 0.0244 

[TRAIN] Epoch[3](234/375); Loss: 0.055249; Backpropagation: 0.2882 sec; Batch: 2.0726 sec
0.0992 0.0761 0.0655 0.0590 0.0552 0.0531 0.0514 0.0500 0.0490 0.0481 0.0473 0.0468 0.0463 0.0459 0.0456 0.0454 

[TRAIN] Epoch[3](235/375); Loss: 0.033791; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0929 0.0620 0.0438 0.0349 0.0311 0.0290 0.0276 0.0265 0.0256 0.0250 0.0245 0.0241 0.0237 0.0235 0.0233 0.0232 

[TRAIN] Epoch[3](236/375); Loss: 0.043662; Backpropagation: 0.2880 sec; Batch: 2.0741 sec
0.0917 0.0717 0.0563 0.0479 0.0430 0.0404 0.0385 0.0370 0.0360 0.0350 0.0344 0.0338 0.0335 0.0333 0.0331 0.0329 

[TRAIN] Epoch[3](237/375); Loss: 0.069846; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1226 0.1029 0.0863 0.0761 0.0707 0.0665 0.0642 0.0622 0.0607 0.0596 0.0587 0.0581 0.0577 0.0573 0.0570 0.0570 

[TRAIN] Epoch[3](238/375); Loss: 0.043181; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0878 0.0680 0.0525 0.0466 0.0429 0.0404 0.0387 0.0373 0.0363 0.0355 0.0349 0.0345 0.0342 0.0339 0.0337 0.0336 

[TRAIN] Epoch[3](239/375); Loss: 0.055997; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.1260 0.0934 0.0699 0.0610 0.0556 0.0520 0.0491 0.0471 0.0456 0.0443 0.0433 0.0426 0.0420 0.0416 0.0413 0.0411 

[TRAIN] Epoch[3](240/375); Loss: 0.039736; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1142 0.0783 0.0531 0.0427 0.0367 0.0337 0.0314 0.0299 0.0288 0.0280 0.0273 0.0268 0.0265 0.0263 0.0261 0.0260 

[TRAIN] Epoch[3](241/375); Loss: 0.044891; Backpropagation: 0.2883 sec; Batch: 2.0762 sec
0.0992 0.0713 0.0543 0.0476 0.0434 0.0410 0.0391 0.0380 0.0372 0.0364 0.0359 0.0354 0.0351 0.0349 0.0347 0.0347 

[TRAIN] Epoch[3](242/375); Loss: 0.042709; Backpropagation: 0.2880 sec; Batch: 2.0736 sec
0.0872 0.0679 0.0538 0.0475 0.0432 0.0406 0.0385 0.0369 0.0355 0.0346 0.0339 0.0334 0.0330 0.0327 0.0325 0.0323 

[TRAIN] Epoch[3](243/375); Loss: 0.044677; Backpropagation: 0.2882 sec; Batch: 2.0724 sec
0.0976 0.0741 0.0548 0.0472 0.0433 0.0409 0.0391 0.0378 0.0368 0.0359 0.0353 0.0349 0.0346 0.0343 0.0341 0.0340 

[TRAIN] Epoch[3](244/375); Loss: 0.055509; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.1008 0.0817 0.0661 0.0594 0.0551 0.0525 0.0507 0.0494 0.0483 0.0475 0.0470 0.0465 0.0461 0.0459 0.0457 0.0455 

[TRAIN] Epoch[3](245/375); Loss: 0.030891; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0736 0.0533 0.0393 0.0340 0.0306 0.0285 0.0269 0.0257 0.0246 0.0237 0.0231 0.0226 0.0223 0.0221 0.0220 0.0220 

[TRAIN] Epoch[3](246/375); Loss: 0.048192; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1027 0.0793 0.0624 0.0527 0.0477 0.0446 0.0425 0.0409 0.0395 0.0385 0.0377 0.0371 0.0367 0.0364 0.0362 0.0361 

[TRAIN] Epoch[3](247/375); Loss: 0.043726; Backpropagation: 0.2881 sec; Batch: 2.0730 sec
0.0952 0.0686 0.0525 0.0466 0.0427 0.0404 0.0386 0.0373 0.0363 0.0356 0.0351 0.0347 0.0344 0.0341 0.0339 0.0338 

[TRAIN] Epoch[3](248/375); Loss: 0.062588; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1077 0.0939 0.0759 0.0682 0.0640 0.0605 0.0581 0.0562 0.0548 0.0537 0.0527 0.0520 0.0514 0.0510 0.0508 0.0506 

[TRAIN] Epoch[3](249/375); Loss: 0.052349; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0925 0.0753 0.0616 0.0565 0.0530 0.0505 0.0486 0.0472 0.0461 0.0452 0.0445 0.0439 0.0436 0.0433 0.0431 0.0429 

[TRAIN] Epoch[3](250/375); Loss: 0.042916; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.0832 0.0632 0.0532 0.0476 0.0441 0.0416 0.0397 0.0381 0.0369 0.0358 0.0351 0.0344 0.0340 0.0336 0.0333 0.0331 

[TRAIN] Epoch[3](251/375); Loss: 0.040315; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1054 0.0717 0.0504 0.0419 0.0380 0.0353 0.0334 0.0321 0.0313 0.0305 0.0300 0.0295 0.0292 0.0290 0.0288 0.0287 

[TRAIN] Epoch[3](252/375); Loss: 0.069731; Backpropagation: 0.3008 sec; Batch: 2.0885 sec
0.1502 0.1268 0.0996 0.0823 0.0717 0.0627 0.0577 0.0555 0.0538 0.0529 0.0518 0.0510 0.0504 0.0500 0.0497 0.0494 

[TRAIN] Epoch[3](253/375); Loss: 0.061295; Backpropagation: 0.2879 sec; Batch: 2.0736 sec
0.1167 0.1022 0.0840 0.0699 0.0625 0.0578 0.0546 0.0521 0.0503 0.0491 0.0481 0.0474 0.0470 0.0466 0.0463 0.0461 

[TRAIN] Epoch[3](254/375); Loss: 0.064090; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1482 0.1268 0.0937 0.0732 0.0623 0.0548 0.0517 0.0498 0.0482 0.0470 0.0462 0.0455 0.0450 0.0446 0.0444 0.0441 

[TRAIN] Epoch[3](255/375); Loss: 0.064130; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1225 0.0970 0.0800 0.0708 0.0644 0.0610 0.0583 0.0564 0.0548 0.0535 0.0525 0.0518 0.0512 0.0509 0.0506 0.0505 

[TRAIN] Epoch[3](256/375); Loss: 0.042481; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0899 0.0655 0.0512 0.0454 0.0421 0.0396 0.0379 0.0366 0.0356 0.0348 0.0343 0.0339 0.0336 0.0333 0.0331 0.0329 

[TRAIN] Epoch[3](257/375); Loss: 0.056580; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.1023 0.0839 0.0693 0.0614 0.0570 0.0542 0.0523 0.0504 0.0492 0.0481 0.0473 0.0467 0.0462 0.0459 0.0456 0.0454 

[TRAIN] Epoch[3](258/375); Loss: 0.049447; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.1231 0.0824 0.0626 0.0517 0.0470 0.0442 0.0421 0.0405 0.0393 0.0384 0.0377 0.0371 0.0367 0.0363 0.0361 0.0359 

[TRAIN] Epoch[3](259/375); Loss: 0.040708; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.0820 0.0624 0.0516 0.0454 0.0416 0.0386 0.0369 0.0354 0.0341 0.0333 0.0325 0.0321 0.0317 0.0314 0.0312 0.0310 

[TRAIN] Epoch[3](260/375); Loss: 0.040445; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0906 0.0685 0.0528 0.0447 0.0399 0.0372 0.0352 0.0338 0.0326 0.0316 0.0309 0.0304 0.0301 0.0298 0.0296 0.0295 

[TRAIN] Epoch[3](261/375); Loss: 0.036742; Backpropagation: 0.2886 sec; Batch: 2.0730 sec
0.0825 0.0541 0.0428 0.0379 0.0357 0.0340 0.0328 0.0318 0.0311 0.0304 0.0299 0.0294 0.0292 0.0289 0.0288 0.0287 

[TRAIN] Epoch[3](262/375); Loss: 0.050273; Backpropagation: 0.2880 sec; Batch: 2.0723 sec
0.1077 0.0807 0.0631 0.0544 0.0498 0.0468 0.0445 0.0428 0.0415 0.0405 0.0397 0.0392 0.0388 0.0385 0.0382 0.0381 

[TRAIN] Epoch[3](263/375); Loss: 0.065223; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1401 0.1045 0.0841 0.0723 0.0655 0.0608 0.0574 0.0552 0.0533 0.0521 0.0511 0.0504 0.0498 0.0493 0.0490 0.0488 

[TRAIN] Epoch[3](264/375); Loss: 0.046003; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0877 0.0688 0.0568 0.0498 0.0458 0.0434 0.0417 0.0403 0.0391 0.0385 0.0380 0.0376 0.0373 0.0371 0.0371 0.0370 

[TRAIN] Epoch[3](265/375); Loss: 0.036298; Backpropagation: 0.2882 sec; Batch: 2.0723 sec
0.0737 0.0594 0.0463 0.0409 0.0368 0.0342 0.0324 0.0310 0.0300 0.0293 0.0286 0.0281 0.0278 0.0276 0.0274 0.0272 

[TRAIN] Epoch[3](266/375); Loss: 0.045999; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0973 0.0807 0.0626 0.0531 0.0467 0.0426 0.0400 0.0381 0.0367 0.0356 0.0349 0.0343 0.0338 0.0335 0.0332 0.0330 

[TRAIN] Epoch[3](267/375); Loss: 0.054385; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0927 0.0760 0.0644 0.0580 0.0549 0.0527 0.0508 0.0494 0.0485 0.0476 0.0469 0.0463 0.0459 0.0456 0.0453 0.0451 

[TRAIN] Epoch[3](268/375); Loss: 0.036992; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.0813 0.0571 0.0474 0.0410 0.0378 0.0353 0.0333 0.0317 0.0305 0.0296 0.0288 0.0283 0.0279 0.0275 0.0272 0.0270 

[TRAIN] Epoch[3](269/375); Loss: 0.055819; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1061 0.0890 0.0706 0.0618 0.0563 0.0526 0.0503 0.0486 0.0473 0.0462 0.0453 0.0447 0.0441 0.0437 0.0433 0.0431 

[TRAIN] Epoch[3](270/375); Loss: 0.050387; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1011 0.0761 0.0608 0.0547 0.0505 0.0476 0.0455 0.0440 0.0429 0.0419 0.0412 0.0406 0.0402 0.0398 0.0396 0.0395 

[TRAIN] Epoch[3](271/375); Loss: 0.059261; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.1081 0.0863 0.0727 0.0648 0.0601 0.0570 0.0546 0.0528 0.0514 0.0504 0.0495 0.0489 0.0485 0.0480 0.0477 0.0474 

[TRAIN] Epoch[3](272/375); Loss: 0.062001; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.1234 0.1094 0.0905 0.0790 0.0709 0.0640 0.0588 0.0539 0.0496 0.0464 0.0440 0.0423 0.0411 0.0402 0.0395 0.0391 

[TRAIN] Epoch[3](273/375); Loss: 0.048865; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1080 0.0848 0.0655 0.0544 0.0488 0.0450 0.0425 0.0406 0.0393 0.0382 0.0373 0.0365 0.0359 0.0354 0.0350 0.0347 

[TRAIN] Epoch[3](274/375); Loss: 0.073066; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1390 0.1184 0.0955 0.0837 0.0753 0.0695 0.0657 0.0628 0.0608 0.0593 0.0583 0.0574 0.0567 0.0560 0.0555 0.0551 

[TRAIN] Epoch[3](275/375); Loss: 0.057554; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1211 0.0916 0.0733 0.0642 0.0584 0.0545 0.0519 0.0497 0.0479 0.0465 0.0453 0.0444 0.0437 0.0432 0.0427 0.0424 

[TRAIN] Epoch[3](276/375); Loss: 0.048456; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0970 0.0769 0.0624 0.0552 0.0501 0.0465 0.0437 0.0417 0.0401 0.0391 0.0383 0.0377 0.0372 0.0368 0.0365 0.0362 

[TRAIN] Epoch[3](277/375); Loss: 0.028711; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0671 0.0438 0.0346 0.0304 0.0279 0.0261 0.0251 0.0241 0.0235 0.0231 0.0227 0.0224 0.0223 0.0221 0.0221 0.0220 

[TRAIN] Epoch[3](278/375); Loss: 0.038216; Backpropagation: 0.2881 sec; Batch: 2.0742 sec
0.0824 0.0651 0.0498 0.0421 0.0381 0.0351 0.0332 0.0319 0.0310 0.0301 0.0296 0.0291 0.0288 0.0285 0.0283 0.0282 

[TRAIN] Epoch[3](279/375); Loss: 0.038558; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0890 0.0619 0.0480 0.0405 0.0373 0.0348 0.0334 0.0321 0.0315 0.0309 0.0304 0.0300 0.0296 0.0294 0.0292 0.0290 

[TRAIN] Epoch[3](280/375); Loss: 0.030054; Backpropagation: 0.2879 sec; Batch: 2.0738 sec
0.0778 0.0566 0.0411 0.0335 0.0287 0.0260 0.0243 0.0233 0.0225 0.0219 0.0215 0.0212 0.0209 0.0207 0.0205 0.0204 

[TRAIN] Epoch[3](281/375); Loss: 0.028708; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.0725 0.0497 0.0360 0.0308 0.0277 0.0257 0.0242 0.0232 0.0224 0.0218 0.0214 0.0211 0.0209 0.0208 0.0206 0.0205 

[TRAIN] Epoch[3](282/375); Loss: 0.034306; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0883 0.0619 0.0451 0.0371 0.0333 0.0308 0.0289 0.0276 0.0265 0.0257 0.0249 0.0244 0.0239 0.0237 0.0235 0.0233 

[TRAIN] Epoch[3](283/375); Loss: 0.038930; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.1009 0.0736 0.0520 0.0425 0.0371 0.0338 0.0320 0.0307 0.0296 0.0286 0.0280 0.0275 0.0271 0.0268 0.0265 0.0264 

[TRAIN] Epoch[3](284/375); Loss: 0.039971; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.0941 0.0676 0.0527 0.0450 0.0403 0.0371 0.0346 0.0328 0.0316 0.0306 0.0299 0.0294 0.0289 0.0285 0.0283 0.0281 

[TRAIN] Epoch[3](285/375); Loss: 0.067920; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1139 0.0954 0.0807 0.0745 0.0701 0.0667 0.0640 0.0621 0.0603 0.0592 0.0581 0.0573 0.0567 0.0562 0.0559 0.0556 

[TRAIN] Epoch[3](286/375); Loss: 0.032399; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0934 0.0623 0.0417 0.0325 0.0291 0.0268 0.0253 0.0245 0.0239 0.0234 0.0230 0.0227 0.0226 0.0224 0.0224 0.0224 

[TRAIN] Epoch[3](287/375); Loss: 0.043835; Backpropagation: 0.2880 sec; Batch: 2.0741 sec
0.0854 0.0703 0.0547 0.0478 0.0443 0.0414 0.0395 0.0380 0.0370 0.0361 0.0354 0.0348 0.0345 0.0342 0.0340 0.0339 

[TRAIN] Epoch[3](288/375); Loss: 0.049132; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.0909 0.0734 0.0621 0.0545 0.0503 0.0469 0.0449 0.0433 0.0420 0.0410 0.0402 0.0398 0.0395 0.0393 0.0391 0.0390 

[TRAIN] Epoch[3](289/375); Loss: 0.040095; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.1016 0.0688 0.0508 0.0436 0.0396 0.0363 0.0341 0.0326 0.0315 0.0305 0.0298 0.0292 0.0288 0.0284 0.0281 0.0279 

[TRAIN] Epoch[3](290/375); Loss: 0.044568; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1019 0.0770 0.0577 0.0496 0.0451 0.0415 0.0389 0.0371 0.0356 0.0344 0.0335 0.0328 0.0324 0.0321 0.0318 0.0315 

[TRAIN] Epoch[3](291/375); Loss: 0.062705; Backpropagation: 0.2880 sec; Batch: 2.0725 sec
0.1121 0.0868 0.0746 0.0683 0.0639 0.0605 0.0581 0.0564 0.0552 0.0543 0.0535 0.0527 0.0522 0.0519 0.0515 0.0513 

[TRAIN] Epoch[3](292/375); Loss: 0.042765; Backpropagation: 0.2880 sec; Batch: 2.0735 sec
0.0823 0.0621 0.0514 0.0458 0.0429 0.0407 0.0391 0.0378 0.0369 0.0362 0.0356 0.0352 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[3](293/375); Loss: 0.039011; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0790 0.0627 0.0486 0.0429 0.0389 0.0364 0.0347 0.0335 0.0324 0.0318 0.0313 0.0309 0.0306 0.0303 0.0302 0.0300 

[TRAIN] Epoch[3](294/375); Loss: 0.053627; Backpropagation: 0.2880 sec; Batch: 2.0734 sec
0.1234 0.1009 0.0786 0.0633 0.0544 0.0489 0.0452 0.0428 0.0410 0.0393 0.0380 0.0373 0.0367 0.0363 0.0360 0.0358 

[TRAIN] Epoch[3](295/375); Loss: 0.059446; Backpropagation: 0.2886 sec; Batch: 2.0742 sec
0.1287 0.0959 0.0761 0.0657 0.0591 0.0552 0.0525 0.0501 0.0485 0.0473 0.0465 0.0459 0.0454 0.0450 0.0447 0.0445 

[TRAIN] Epoch[3](296/375); Loss: 0.041644; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.0815 0.0632 0.0524 0.0465 0.0423 0.0394 0.0376 0.0361 0.0352 0.0345 0.0338 0.0333 0.0329 0.0327 0.0325 0.0324 

[TRAIN] Epoch[3](297/375); Loss: 0.054345; Backpropagation: 0.2882 sec; Batch: 2.0737 sec
0.1167 0.0920 0.0710 0.0605 0.0538 0.0496 0.0469 0.0452 0.0439 0.0429 0.0421 0.0415 0.0412 0.0409 0.0406 0.0405 

[TRAIN] Epoch[3](298/375); Loss: 0.050256; Backpropagation: 0.2887 sec; Batch: 2.0726 sec
0.0914 0.0725 0.0618 0.0550 0.0513 0.0488 0.0466 0.0450 0.0436 0.0427 0.0420 0.0414 0.0409 0.0406 0.0403 0.0402 

[TRAIN] Epoch[3](299/375); Loss: 0.051509; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1117 0.0971 0.0812 0.0688 0.0614 0.0543 0.0488 0.0434 0.0392 0.0360 0.0336 0.0318 0.0305 0.0294 0.0287 0.0283 

[TRAIN] Epoch[3](300/375); Loss: 0.059851; Backpropagation: 0.2885 sec; Batch: 2.0797 sec
0.1051 0.0846 0.0719 0.0650 0.0606 0.0578 0.0557 0.0542 0.0528 0.0517 0.0508 0.0502 0.0498 0.0494 0.0492 0.0489 

[TRAIN] Epoch[3](301/375); Loss: 0.040976; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0860 0.0642 0.0506 0.0449 0.0410 0.0381 0.0364 0.0352 0.0341 0.0333 0.0328 0.0324 0.0320 0.0317 0.0316 0.0315 

[TRAIN] Epoch[3](302/375); Loss: 0.040278; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.0786 0.0569 0.0487 0.0437 0.0405 0.0384 0.0367 0.0354 0.0346 0.0339 0.0335 0.0331 0.0328 0.0327 0.0325 0.0324 

[TRAIN] Epoch[3](303/375); Loss: 0.050467; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1199 0.0841 0.0658 0.0571 0.0505 0.0462 0.0436 0.0413 0.0396 0.0385 0.0378 0.0372 0.0368 0.0365 0.0363 0.0361 

[TRAIN] Epoch[3](304/375); Loss: 0.048387; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.0848 0.0688 0.0575 0.0520 0.0489 0.0466 0.0449 0.0435 0.0425 0.0418 0.0412 0.0408 0.0405 0.0402 0.0401 0.0399 

[TRAIN] Epoch[3](305/375); Loss: 0.054905; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.1138 0.0924 0.0740 0.0620 0.0556 0.0516 0.0490 0.0469 0.0451 0.0437 0.0425 0.0415 0.0409 0.0403 0.0398 0.0394 

[TRAIN] Epoch[3](306/375); Loss: 0.053785; Backpropagation: 0.2882 sec; Batch: 2.0725 sec
0.1315 0.1058 0.0782 0.0630 0.0531 0.0468 0.0431 0.0412 0.0398 0.0387 0.0380 0.0373 0.0368 0.0362 0.0358 0.0354 

[TRAIN] Epoch[3](307/375); Loss: 0.044396; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0868 0.0654 0.0524 0.0466 0.0437 0.0414 0.0398 0.0387 0.0380 0.0375 0.0371 0.0369 0.0367 0.0365 0.0364 0.0364 

[TRAIN] Epoch[3](308/375); Loss: 0.036608; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0939 0.0665 0.0486 0.0404 0.0358 0.0329 0.0306 0.0291 0.0280 0.0270 0.0265 0.0260 0.0255 0.0252 0.0250 0.0248 

[TRAIN] Epoch[3](309/375); Loss: 0.044803; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0990 0.0724 0.0574 0.0505 0.0456 0.0425 0.0402 0.0381 0.0364 0.0353 0.0344 0.0338 0.0333 0.0329 0.0326 0.0324 

[TRAIN] Epoch[3](310/375); Loss: 0.037896; Backpropagation: 0.2886 sec; Batch: 2.0739 sec
0.0702 0.0518 0.0454 0.0413 0.0382 0.0365 0.0351 0.0340 0.0331 0.0324 0.0321 0.0317 0.0314 0.0312 0.0310 0.0310 

[TRAIN] Epoch[3](311/375); Loss: 0.036127; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0937 0.0627 0.0464 0.0384 0.0344 0.0321 0.0303 0.0290 0.0281 0.0274 0.0267 0.0262 0.0259 0.0257 0.0255 0.0254 

[TRAIN] Epoch[3](312/375); Loss: 0.041647; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0878 0.0666 0.0545 0.0477 0.0425 0.0392 0.0367 0.0351 0.0340 0.0332 0.0325 0.0320 0.0315 0.0312 0.0310 0.0308 

[TRAIN] Epoch[3](313/375); Loss: 0.062639; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.1280 0.0990 0.0816 0.0696 0.0619 0.0578 0.0554 0.0535 0.0520 0.0510 0.0501 0.0494 0.0488 0.0484 0.0481 0.0478 

[TRAIN] Epoch[3](314/375); Loss: 0.062705; Backpropagation: 0.2880 sec; Batch: 2.0735 sec
0.1229 0.1036 0.0820 0.0699 0.0634 0.0593 0.0562 0.0538 0.0523 0.0509 0.0498 0.0489 0.0482 0.0477 0.0473 0.0470 

[TRAIN] Epoch[3](315/375); Loss: 0.040503; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.0966 0.0716 0.0551 0.0454 0.0398 0.0365 0.0342 0.0326 0.0315 0.0306 0.0299 0.0295 0.0291 0.0288 0.0285 0.0283 

[TRAIN] Epoch[3](316/375); Loss: 0.050290; Backpropagation: 0.2880 sec; Batch: 2.0726 sec
0.0932 0.0711 0.0605 0.0550 0.0517 0.0492 0.0471 0.0453 0.0438 0.0427 0.0419 0.0413 0.0409 0.0405 0.0403 0.0401 

[TRAIN] Epoch[3](317/375); Loss: 0.036855; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.0736 0.0561 0.0456 0.0391 0.0362 0.0344 0.0331 0.0319 0.0311 0.0306 0.0301 0.0298 0.0297 0.0295 0.0295 0.0295 

[TRAIN] Epoch[3](318/375); Loss: 0.057282; Backpropagation: 0.2887 sec; Batch: 2.0733 sec
0.1009 0.0822 0.0704 0.0628 0.0585 0.0557 0.0533 0.0515 0.0500 0.0488 0.0481 0.0474 0.0470 0.0467 0.0466 0.0465 

[TRAIN] Epoch[3](319/375); Loss: 0.041198; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0892 0.0662 0.0526 0.0457 0.0415 0.0389 0.0367 0.0352 0.0337 0.0327 0.0320 0.0315 0.0312 0.0309 0.0307 0.0305 

[TRAIN] Epoch[3](320/375); Loss: 0.050292; Backpropagation: 0.2884 sec; Batch: 2.0729 sec
0.0951 0.0748 0.0621 0.0552 0.0513 0.0481 0.0457 0.0442 0.0429 0.0420 0.0414 0.0409 0.0406 0.0403 0.0401 0.0401 

[TRAIN] Epoch[3](321/375); Loss: 0.049716; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.0945 0.0692 0.0612 0.0551 0.0509 0.0480 0.0459 0.0441 0.0428 0.0419 0.0412 0.0407 0.0403 0.0401 0.0399 0.0398 

[TRAIN] Epoch[3](322/375); Loss: 0.043229; Backpropagation: 0.2882 sec; Batch: 2.0733 sec
0.0895 0.0661 0.0531 0.0466 0.0427 0.0402 0.0384 0.0372 0.0363 0.0355 0.0350 0.0346 0.0343 0.0341 0.0340 0.0340 

[TRAIN] Epoch[3](323/375); Loss: 0.043864; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1019 0.0722 0.0571 0.0480 0.0429 0.0403 0.0384 0.0368 0.0355 0.0345 0.0336 0.0329 0.0324 0.0320 0.0318 0.0316 

[TRAIN] Epoch[3](324/375); Loss: 0.037177; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0755 0.0553 0.0458 0.0406 0.0375 0.0354 0.0338 0.0325 0.0315 0.0308 0.0302 0.0297 0.0294 0.0291 0.0289 0.0288 

[TRAIN] Epoch[3](325/375); Loss: 0.054377; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.1030 0.0797 0.0663 0.0588 0.0550 0.0523 0.0501 0.0484 0.0471 0.0460 0.0451 0.0445 0.0440 0.0436 0.0432 0.0430 

[TRAIN] Epoch[3](326/375); Loss: 0.051043; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.1011 0.0769 0.0623 0.0557 0.0515 0.0485 0.0463 0.0447 0.0435 0.0425 0.0417 0.0411 0.0406 0.0403 0.0400 0.0398 

[TRAIN] Epoch[3](327/375); Loss: 0.045693; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.1012 0.0758 0.0587 0.0519 0.0465 0.0427 0.0400 0.0382 0.0368 0.0358 0.0351 0.0344 0.0339 0.0336 0.0333 0.0332 

[TRAIN] Epoch[3](328/375); Loss: 0.052843; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1005 0.0798 0.0632 0.0559 0.0519 0.0492 0.0477 0.0465 0.0456 0.0448 0.0442 0.0438 0.0434 0.0432 0.0430 0.0428 

[TRAIN] Epoch[3](329/375); Loss: 0.065365; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.1166 0.0978 0.0801 0.0719 0.0667 0.0630 0.0605 0.0584 0.0568 0.0555 0.0545 0.0537 0.0532 0.0527 0.0524 0.0521 

[TRAIN] Epoch[3](330/375); Loss: 0.040735; Backpropagation: 0.2886 sec; Batch: 2.0732 sec
0.1057 0.0796 0.0606 0.0461 0.0389 0.0347 0.0326 0.0311 0.0300 0.0290 0.0283 0.0277 0.0273 0.0269 0.0267 0.0264 

[TRAIN] Epoch[3](331/375); Loss: 0.050685; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.1048 0.0868 0.0642 0.0569 0.0510 0.0471 0.0446 0.0428 0.0416 0.0405 0.0396 0.0390 0.0385 0.0381 0.0378 0.0376 

[TRAIN] Epoch[3](332/375); Loss: 0.036088; Backpropagation: 0.2888 sec; Batch: 2.0737 sec
0.0645 0.0505 0.0421 0.0380 0.0358 0.0344 0.0333 0.0325 0.0320 0.0315 0.0310 0.0307 0.0305 0.0303 0.0302 0.0301 

[TRAIN] Epoch[3](333/375); Loss: 0.057037; Backpropagation: 0.2882 sec; Batch: 2.0724 sec
0.1109 0.0936 0.0740 0.0636 0.0578 0.0539 0.0513 0.0493 0.0479 0.0466 0.0456 0.0447 0.0440 0.0435 0.0431 0.0428 

[TRAIN] Epoch[3](334/375); Loss: 0.042888; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0928 0.0706 0.0559 0.0477 0.0429 0.0399 0.0379 0.0362 0.0351 0.0341 0.0333 0.0327 0.0322 0.0319 0.0316 0.0314 

[TRAIN] Epoch[3](335/375); Loss: 0.045524; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0823 0.0650 0.0561 0.0509 0.0468 0.0440 0.0421 0.0406 0.0396 0.0387 0.0380 0.0374 0.0370 0.0368 0.0366 0.0365 

[TRAIN] Epoch[3](336/375); Loss: 0.041556; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0790 0.0622 0.0504 0.0449 0.0420 0.0397 0.0380 0.0368 0.0357 0.0349 0.0343 0.0339 0.0336 0.0333 0.0332 0.0330 

[TRAIN] Epoch[3](337/375); Loss: 0.042189; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0918 0.0742 0.0546 0.0458 0.0421 0.0391 0.0371 0.0353 0.0340 0.0332 0.0324 0.0319 0.0314 0.0310 0.0307 0.0305 

[TRAIN] Epoch[3](338/375); Loss: 0.058652; Backpropagation: 0.2884 sec; Batch: 2.0734 sec
0.1348 0.1071 0.0813 0.0658 0.0600 0.0540 0.0503 0.0476 0.0456 0.0442 0.0431 0.0421 0.0414 0.0407 0.0404 0.0400 

[TRAIN] Epoch[3](339/375); Loss: 0.027019; Backpropagation: 0.2889 sec; Batch: 2.0736 sec
0.0686 0.0556 0.0371 0.0293 0.0257 0.0234 0.0220 0.0209 0.0200 0.0195 0.0190 0.0186 0.0184 0.0182 0.0180 0.0179 

[TRAIN] Epoch[3](340/375); Loss: 0.056535; Backpropagation: 0.2886 sec; Batch: 2.0726 sec
0.1059 0.0842 0.0707 0.0622 0.0578 0.0544 0.0520 0.0502 0.0488 0.0475 0.0465 0.0458 0.0453 0.0448 0.0444 0.0441 

[TRAIN] Epoch[3](341/375); Loss: 0.053204; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1292 0.1158 0.0889 0.0705 0.0599 0.0502 0.0431 0.0387 0.0359 0.0339 0.0328 0.0317 0.0309 0.0303 0.0298 0.0295 

[TRAIN] Epoch[3](342/375); Loss: 0.042847; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.0948 0.0724 0.0522 0.0448 0.0408 0.0386 0.0371 0.0360 0.0352 0.0344 0.0340 0.0335 0.0332 0.0330 0.0328 0.0326 

[TRAIN] Epoch[3](343/375); Loss: 0.043349; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0887 0.0693 0.0545 0.0476 0.0432 0.0406 0.0386 0.0372 0.0362 0.0354 0.0347 0.0341 0.0337 0.0334 0.0332 0.0330 

[TRAIN] Epoch[3](344/375); Loss: 0.035990; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0787 0.0634 0.0480 0.0400 0.0359 0.0331 0.0312 0.0297 0.0287 0.0279 0.0273 0.0269 0.0266 0.0264 0.0262 0.0260 

[TRAIN] Epoch[3](345/375); Loss: 0.055543; Backpropagation: 0.2881 sec; Batch: 2.0731 sec
0.1111 0.0900 0.0711 0.0606 0.0553 0.0519 0.0497 0.0479 0.0465 0.0454 0.0445 0.0437 0.0432 0.0428 0.0426 0.0423 

[TRAIN] Epoch[3](346/375); Loss: 0.036323; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0748 0.0572 0.0453 0.0399 0.0367 0.0343 0.0325 0.0311 0.0303 0.0296 0.0290 0.0286 0.0283 0.0281 0.0279 0.0278 

[TRAIN] Epoch[3](347/375); Loss: 0.067026; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.1346 0.1101 0.0908 0.0771 0.0672 0.0601 0.0577 0.0562 0.0548 0.0539 0.0530 0.0523 0.0517 0.0513 0.0510 0.0506 

[TRAIN] Epoch[3](348/375); Loss: 0.040181; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.0896 0.0612 0.0490 0.0426 0.0392 0.0373 0.0357 0.0343 0.0334 0.0326 0.0320 0.0317 0.0313 0.0311 0.0309 0.0308 

[TRAIN] Epoch[3](349/375); Loss: 0.046483; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0832 0.0703 0.0560 0.0499 0.0468 0.0445 0.0429 0.0417 0.0406 0.0397 0.0390 0.0385 0.0381 0.0378 0.0375 0.0372 

[TRAIN] Epoch[3](350/375); Loss: 0.032371; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0751 0.0539 0.0408 0.0349 0.0315 0.0294 0.0280 0.0269 0.0262 0.0255 0.0249 0.0246 0.0243 0.0242 0.0240 0.0238 

[TRAIN] Epoch[3](351/375); Loss: 0.054231; Backpropagation: 0.2879 sec; Batch: 2.0735 sec
0.0961 0.0799 0.0661 0.0590 0.0553 0.0526 0.0505 0.0490 0.0478 0.0465 0.0455 0.0448 0.0442 0.0438 0.0434 0.0432 

[TRAIN] Epoch[3](352/375); Loss: 0.053044; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1078 0.0883 0.0661 0.0569 0.0522 0.0498 0.0475 0.0459 0.0444 0.0433 0.0423 0.0417 0.0412 0.0407 0.0404 0.0401 

[TRAIN] Epoch[3](353/375); Loss: 0.046459; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0771 0.0630 0.0552 0.0513 0.0483 0.0463 0.0444 0.0428 0.0416 0.0406 0.0398 0.0393 0.0389 0.0386 0.0383 0.0381 

[TRAIN] Epoch[3](354/375); Loss: 0.054969; Backpropagation: 0.2887 sec; Batch: 2.0730 sec
0.1067 0.0840 0.0690 0.0610 0.0560 0.0524 0.0495 0.0478 0.0464 0.0454 0.0446 0.0440 0.0436 0.0433 0.0430 0.0428 

[TRAIN] Epoch[3](355/375); Loss: 0.038899; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0768 0.0631 0.0499 0.0424 0.0393 0.0368 0.0350 0.0338 0.0327 0.0317 0.0311 0.0305 0.0302 0.0299 0.0297 0.0295 

[TRAIN] Epoch[3](356/375); Loss: 0.048148; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1071 0.0758 0.0613 0.0517 0.0472 0.0448 0.0425 0.0408 0.0395 0.0385 0.0378 0.0373 0.0369 0.0366 0.0363 0.0361 

[TRAIN] Epoch[3](357/375); Loss: 0.054657; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1159 0.0883 0.0702 0.0595 0.0548 0.0514 0.0488 0.0467 0.0452 0.0439 0.0429 0.0423 0.0418 0.0413 0.0410 0.0407 

[TRAIN] Epoch[3](358/375); Loss: 0.060456; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.1086 0.0909 0.0730 0.0646 0.0604 0.0575 0.0553 0.0537 0.0524 0.0516 0.0509 0.0503 0.0499 0.0496 0.0494 0.0492 

[TRAIN] Epoch[3](359/375); Loss: 0.065377; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.1158 0.0957 0.0793 0.0720 0.0671 0.0638 0.0611 0.0590 0.0572 0.0558 0.0549 0.0540 0.0532 0.0527 0.0523 0.0520 

[TRAIN] Epoch[3](360/375); Loss: 0.048857; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.0985 0.0753 0.0605 0.0534 0.0497 0.0468 0.0442 0.0424 0.0411 0.0402 0.0393 0.0387 0.0383 0.0380 0.0378 0.0376 

[TRAIN] Epoch[3](361/375); Loss: 0.048392; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.1040 0.0849 0.0608 0.0507 0.0467 0.0438 0.0420 0.0408 0.0397 0.0387 0.0380 0.0375 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[3](362/375); Loss: 0.045098; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.0979 0.0758 0.0575 0.0484 0.0442 0.0416 0.0398 0.0382 0.0369 0.0361 0.0353 0.0348 0.0343 0.0339 0.0335 0.0334 

[TRAIN] Epoch[3](363/375); Loss: 0.032568; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0926 0.0588 0.0407 0.0340 0.0307 0.0282 0.0266 0.0255 0.0245 0.0239 0.0233 0.0229 0.0226 0.0224 0.0222 0.0221 

[TRAIN] Epoch[3](364/375); Loss: 0.052741; Backpropagation: 0.2880 sec; Batch: 2.0733 sec
0.1091 0.0868 0.0683 0.0571 0.0527 0.0495 0.0474 0.0454 0.0438 0.0426 0.0415 0.0409 0.0403 0.0398 0.0395 0.0392 

[TRAIN] Epoch[3](365/375); Loss: 0.049112; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1055 0.0796 0.0625 0.0537 0.0489 0.0458 0.0435 0.0416 0.0402 0.0392 0.0385 0.0380 0.0376 0.0373 0.0370 0.0368 

[TRAIN] Epoch[3](366/375); Loss: 0.056081; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.1017 0.0830 0.0684 0.0607 0.0566 0.0540 0.0518 0.0502 0.0489 0.0477 0.0469 0.0462 0.0458 0.0454 0.0452 0.0450 

[TRAIN] Epoch[3](367/375); Loss: 0.078902; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1591 0.1369 0.1080 0.0893 0.0790 0.0723 0.0687 0.0660 0.0642 0.0625 0.0612 0.0602 0.0595 0.0589 0.0584 0.0581 

[TRAIN] Epoch[3](368/375); Loss: 0.041398; Backpropagation: 0.2883 sec; Batch: 2.0759 sec
0.0964 0.0674 0.0537 0.0443 0.0401 0.0378 0.0360 0.0347 0.0334 0.0327 0.0320 0.0315 0.0310 0.0307 0.0304 0.0302 

[TRAIN] Epoch[3](369/375); Loss: 0.047583; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1004 0.0721 0.0583 0.0508 0.0474 0.0443 0.0423 0.0410 0.0400 0.0392 0.0385 0.0379 0.0376 0.0374 0.0372 0.0370 

[TRAIN] Epoch[3](370/375); Loss: 0.045862; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0892 0.0719 0.0566 0.0500 0.0462 0.0433 0.0415 0.0400 0.0388 0.0380 0.0373 0.0368 0.0364 0.0361 0.0359 0.0357 

[TRAIN] Epoch[3](371/375); Loss: 0.049545; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0916 0.0723 0.0594 0.0544 0.0508 0.0477 0.0456 0.0442 0.0430 0.0421 0.0414 0.0407 0.0403 0.0400 0.0397 0.0395 

[TRAIN] Epoch[3](372/375); Loss: 0.054212; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1041 0.0877 0.0681 0.0594 0.0549 0.0516 0.0491 0.0475 0.0460 0.0447 0.0438 0.0431 0.0424 0.0420 0.0416 0.0414 

[TRAIN] Epoch[3](373/375); Loss: 0.030039; Backpropagation: 0.2886 sec; Batch: 2.0743 sec
0.0682 0.0503 0.0366 0.0315 0.0287 0.0273 0.0261 0.0253 0.0246 0.0240 0.0237 0.0233 0.0230 0.0228 0.0227 0.0226 

[TRAIN] Epoch[3](374/375); Loss: 0.052510; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.1110 0.0834 0.0662 0.0566 0.0522 0.0495 0.0473 0.0453 0.0438 0.0426 0.0417 0.0410 0.0405 0.0401 0.0397 0.0394 

[TRAIN] Epoch[3](375/375); Loss: 0.040465; Backpropagation: 0.2880 sec; Batch: 2.0731 sec
0.0848 0.0662 0.0509 0.0438 0.0404 0.0381 0.0362 0.0346 0.0335 0.0326 0.0320 0.0314 0.0310 0.0308 0.0306 0.0304 

[TRAIN] Epoch[4](1/375); Loss: 0.067253; Backpropagation: 0.3006 sec; Batch: 2.1410 sec
0.1630 0.1508 0.1095 0.0864 0.0725 0.0619 0.0530 0.0474 0.0448 0.0435 0.0422 0.0412 0.0406 0.0401 0.0397 0.0394 

[TRAIN] Epoch[4](2/375); Loss: 0.050891; Backpropagation: 0.2906 sec; Batch: 2.0918 sec
0.1001 0.0794 0.0658 0.0573 0.0522 0.0488 0.0460 0.0439 0.0426 0.0415 0.0407 0.0399 0.0394 0.0391 0.0389 0.0388 

[TRAIN] Epoch[4](3/375); Loss: 0.056825; Backpropagation: 0.2903 sec; Batch: 2.0784 sec
0.1344 0.1187 0.0908 0.0722 0.0610 0.0516 0.0463 0.0431 0.0406 0.0386 0.0373 0.0361 0.0353 0.0348 0.0343 0.0340 

[TRAIN] Epoch[4](4/375); Loss: 0.047263; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.0990 0.0771 0.0580 0.0511 0.0472 0.0445 0.0423 0.0404 0.0392 0.0383 0.0375 0.0369 0.0365 0.0362 0.0361 0.0359 

[TRAIN] Epoch[4](5/375); Loss: 0.074885; Backpropagation: 0.2907 sec; Batch: 2.0778 sec
0.1427 0.1101 0.0918 0.0826 0.0768 0.0725 0.0688 0.0662 0.0644 0.0628 0.0615 0.0605 0.0600 0.0595 0.0592 0.0588 

[TRAIN] Epoch[4](6/375); Loss: 0.051456; Backpropagation: 0.2907 sec; Batch: 2.0789 sec
0.0979 0.0760 0.0627 0.0561 0.0526 0.0500 0.0478 0.0461 0.0445 0.0433 0.0423 0.0416 0.0411 0.0407 0.0404 0.0402 

[TRAIN] Epoch[4](7/375); Loss: 0.043111; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.0840 0.0634 0.0523 0.0458 0.0430 0.0411 0.0396 0.0382 0.0373 0.0364 0.0357 0.0352 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[4](8/375); Loss: 0.061536; Backpropagation: 0.2887 sec; Batch: 2.0777 sec
0.1332 0.0999 0.0767 0.0656 0.0604 0.0570 0.0545 0.0524 0.0507 0.0497 0.0488 0.0481 0.0474 0.0470 0.0467 0.0465 

[TRAIN] Epoch[4](9/375); Loss: 0.052840; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.1166 0.1029 0.0806 0.0649 0.0551 0.0472 0.0433 0.0410 0.0396 0.0384 0.0372 0.0365 0.0361 0.0357 0.0353 0.0351 

[TRAIN] Epoch[4](10/375); Loss: 0.047219; Backpropagation: 0.2882 sec; Batch: 2.1079 sec
0.0968 0.0718 0.0586 0.0517 0.0480 0.0451 0.0427 0.0410 0.0398 0.0388 0.0380 0.0374 0.0369 0.0366 0.0363 0.0361 

[TRAIN] Epoch[4](11/375); Loss: 0.066156; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1283 0.0988 0.0814 0.0714 0.0663 0.0625 0.0600 0.0580 0.0564 0.0554 0.0545 0.0538 0.0534 0.0530 0.0527 0.0525 

[TRAIN] Epoch[4](12/375); Loss: 0.047839; Backpropagation: 0.2884 sec; Batch: 2.0768 sec
0.1080 0.0816 0.0642 0.0543 0.0485 0.0446 0.0415 0.0394 0.0379 0.0368 0.0360 0.0354 0.0349 0.0344 0.0341 0.0338 

[TRAIN] Epoch[4](13/375); Loss: 0.057650; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1120 0.0874 0.0702 0.0617 0.0575 0.0547 0.0525 0.0507 0.0493 0.0482 0.0475 0.0468 0.0464 0.0460 0.0458 0.0455 

[TRAIN] Epoch[4](14/375); Loss: 0.033358; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0926 0.0611 0.0439 0.0344 0.0315 0.0289 0.0270 0.0258 0.0249 0.0243 0.0238 0.0234 0.0232 0.0231 0.0230 0.0229 

[TRAIN] Epoch[4](15/375); Loss: 0.054713; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.1078 0.0811 0.0670 0.0590 0.0549 0.0522 0.0500 0.0482 0.0469 0.0458 0.0449 0.0443 0.0438 0.0434 0.0431 0.0429 

[TRAIN] Epoch[4](16/375); Loss: 0.041811; Backpropagation: 0.2881 sec; Batch: 2.0768 sec
0.0959 0.0758 0.0502 0.0438 0.0400 0.0375 0.0358 0.0347 0.0338 0.0329 0.0323 0.0318 0.0314 0.0312 0.0310 0.0309 

[TRAIN] Epoch[4](17/375); Loss: 0.043894; Backpropagation: 0.2886 sec; Batch: 2.0824 sec
0.0835 0.0657 0.0535 0.0482 0.0443 0.0418 0.0401 0.0387 0.0376 0.0368 0.0362 0.0357 0.0354 0.0352 0.0350 0.0348 

[TRAIN] Epoch[4](18/375); Loss: 0.049061; Backpropagation: 0.2886 sec; Batch: 2.0776 sec
0.0890 0.0719 0.0588 0.0528 0.0495 0.0470 0.0450 0.0436 0.0428 0.0419 0.0413 0.0408 0.0404 0.0402 0.0400 0.0398 

[TRAIN] Epoch[4](19/375); Loss: 0.060049; Backpropagation: 0.2887 sec; Batch: 2.0775 sec
0.1151 0.0935 0.0744 0.0651 0.0614 0.0574 0.0545 0.0524 0.0508 0.0496 0.0487 0.0482 0.0478 0.0475 0.0473 0.0471 

[TRAIN] Epoch[4](20/375); Loss: 0.057272; Backpropagation: 0.2887 sec; Batch: 2.0746 sec
0.1099 0.0878 0.0715 0.0629 0.0577 0.0544 0.0518 0.0500 0.0488 0.0477 0.0469 0.0461 0.0456 0.0453 0.0450 0.0449 

[TRAIN] Epoch[4](21/375); Loss: 0.040184; Backpropagation: 0.2885 sec; Batch: 2.0875 sec
0.1027 0.0763 0.0572 0.0429 0.0377 0.0347 0.0326 0.0312 0.0302 0.0294 0.0288 0.0284 0.0280 0.0277 0.0276 0.0275 

[TRAIN] Epoch[4](22/375); Loss: 0.049137; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1011 0.0766 0.0597 0.0529 0.0489 0.0463 0.0443 0.0427 0.0414 0.0405 0.0397 0.0390 0.0386 0.0383 0.0382 0.0380 

[TRAIN] Epoch[4](23/375); Loss: 0.043902; Backpropagation: 0.2886 sec; Batch: 2.0778 sec
0.1020 0.0811 0.0567 0.0468 0.0422 0.0393 0.0375 0.0359 0.0348 0.0338 0.0331 0.0326 0.0321 0.0318 0.0315 0.0313 

[TRAIN] Epoch[4](24/375); Loss: 0.035794; Backpropagation: 0.2882 sec; Batch: 2.0772 sec
0.0764 0.0581 0.0458 0.0392 0.0360 0.0334 0.0315 0.0303 0.0294 0.0288 0.0281 0.0277 0.0274 0.0271 0.0269 0.0267 

[TRAIN] Epoch[4](25/375); Loss: 0.055664; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.1103 0.0855 0.0701 0.0619 0.0564 0.0532 0.0505 0.0488 0.0470 0.0457 0.0449 0.0443 0.0436 0.0431 0.0428 0.0425 

[TRAIN] Epoch[4](26/375); Loss: 0.054329; Backpropagation: 0.2888 sec; Batch: 2.0788 sec
0.1115 0.0790 0.0655 0.0593 0.0547 0.0514 0.0493 0.0475 0.0459 0.0449 0.0442 0.0437 0.0434 0.0431 0.0430 0.0428 

[TRAIN] Epoch[4](27/375); Loss: 0.040542; Backpropagation: 0.2884 sec; Batch: 2.0765 sec
0.0895 0.0622 0.0507 0.0436 0.0398 0.0376 0.0358 0.0345 0.0336 0.0329 0.0323 0.0318 0.0315 0.0312 0.0310 0.0309 

[TRAIN] Epoch[4](28/375); Loss: 0.053481; Backpropagation: 0.2888 sec; Batch: 2.0878 sec
0.1094 0.0894 0.0680 0.0581 0.0533 0.0496 0.0471 0.0454 0.0442 0.0433 0.0424 0.0417 0.0413 0.0410 0.0407 0.0406 

[TRAIN] Epoch[4](29/375); Loss: 0.047744; Backpropagation: 0.2885 sec; Batch: 2.0824 sec
0.0967 0.0773 0.0603 0.0523 0.0473 0.0442 0.0421 0.0407 0.0397 0.0388 0.0382 0.0378 0.0374 0.0372 0.0370 0.0369 

[TRAIN] Epoch[4](30/375); Loss: 0.043300; Backpropagation: 0.2885 sec; Batch: 2.0895 sec
0.0905 0.0720 0.0560 0.0484 0.0444 0.0412 0.0387 0.0368 0.0354 0.0343 0.0335 0.0330 0.0326 0.0322 0.0320 0.0318 

[TRAIN] Epoch[4](31/375); Loss: 0.039976; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.0910 0.0740 0.0514 0.0442 0.0403 0.0372 0.0348 0.0328 0.0315 0.0305 0.0298 0.0291 0.0287 0.0283 0.0281 0.0279 

[TRAIN] Epoch[4](32/375); Loss: 0.054116; Backpropagation: 0.2884 sec; Batch: 2.0790 sec
0.1072 0.0829 0.0658 0.0583 0.0541 0.0517 0.0495 0.0477 0.0462 0.0452 0.0442 0.0435 0.0430 0.0425 0.0422 0.0419 

[TRAIN] Epoch[4](33/375); Loss: 0.067260; Backpropagation: 0.2887 sec; Batch: 2.0776 sec
0.1332 0.1200 0.0989 0.0812 0.0705 0.0629 0.0576 0.0546 0.0527 0.0515 0.0503 0.0496 0.0489 0.0484 0.0480 0.0477 

[TRAIN] Epoch[4](34/375); Loss: 0.048243; Backpropagation: 0.2883 sec; Batch: 2.0770 sec
0.0962 0.0773 0.0607 0.0519 0.0473 0.0448 0.0429 0.0415 0.0404 0.0397 0.0390 0.0386 0.0382 0.0379 0.0378 0.0376 

[TRAIN] Epoch[4](35/375); Loss: 0.048309; Backpropagation: 0.2885 sec; Batch: 2.0865 sec
0.1009 0.0815 0.0621 0.0537 0.0488 0.0452 0.0429 0.0410 0.0396 0.0385 0.0377 0.0370 0.0366 0.0361 0.0359 0.0356 

[TRAIN] Epoch[4](36/375); Loss: 0.037887; Backpropagation: 0.2883 sec; Batch: 2.0775 sec
0.0920 0.0597 0.0483 0.0422 0.0378 0.0352 0.0330 0.0314 0.0302 0.0294 0.0287 0.0282 0.0279 0.0276 0.0274 0.0272 

[TRAIN] Epoch[4](37/375); Loss: 0.048066; Backpropagation: 0.2884 sec; Batch: 2.1011 sec
0.0905 0.0697 0.0576 0.0517 0.0484 0.0459 0.0442 0.0427 0.0416 0.0408 0.0402 0.0398 0.0394 0.0391 0.0389 0.0387 

[TRAIN] Epoch[4](38/375); Loss: 0.033664; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0667 0.0518 0.0450 0.0381 0.0343 0.0318 0.0301 0.0290 0.0282 0.0274 0.0268 0.0264 0.0261 0.0258 0.0257 0.0255 

[TRAIN] Epoch[4](39/375); Loss: 0.053742; Backpropagation: 0.2884 sec; Batch: 2.0751 sec
0.0972 0.0789 0.0644 0.0582 0.0543 0.0514 0.0494 0.0479 0.0466 0.0457 0.0451 0.0447 0.0444 0.0441 0.0438 0.0437 

[TRAIN] Epoch[4](40/375); Loss: 0.034032; Backpropagation: 0.2885 sec; Batch: 2.1079 sec
0.0865 0.0541 0.0402 0.0353 0.0325 0.0305 0.0291 0.0282 0.0274 0.0267 0.0261 0.0259 0.0257 0.0255 0.0254 0.0253 

[TRAIN] Epoch[4](41/375); Loss: 0.067386; Backpropagation: 0.2894 sec; Batch: 2.1160 sec
0.1204 0.0990 0.0824 0.0736 0.0678 0.0643 0.0619 0.0602 0.0586 0.0575 0.0566 0.0559 0.0554 0.0551 0.0548 0.0547 

[TRAIN] Epoch[4](42/375); Loss: 0.054207; Backpropagation: 0.2884 sec; Batch: 2.0855 sec
0.1106 0.0862 0.0708 0.0609 0.0554 0.0520 0.0489 0.0463 0.0447 0.0435 0.0426 0.0419 0.0414 0.0410 0.0406 0.0404 

[TRAIN] Epoch[4](43/375); Loss: 0.065864; Backpropagation: 0.2883 sec; Batch: 2.0842 sec
0.1259 0.1013 0.0833 0.0737 0.0682 0.0637 0.0603 0.0579 0.0558 0.0543 0.0532 0.0523 0.0516 0.0511 0.0507 0.0505 

[TRAIN] Epoch[4](44/375); Loss: 0.042834; Backpropagation: 0.2883 sec; Batch: 2.0781 sec
0.0833 0.0622 0.0512 0.0466 0.0438 0.0415 0.0395 0.0381 0.0371 0.0361 0.0354 0.0348 0.0343 0.0340 0.0338 0.0336 

[TRAIN] Epoch[4](45/375); Loss: 0.042373; Backpropagation: 0.2882 sec; Batch: 2.0800 sec
0.1018 0.0748 0.0560 0.0460 0.0412 0.0382 0.0362 0.0346 0.0334 0.0324 0.0316 0.0310 0.0306 0.0303 0.0301 0.0299 

[TRAIN] Epoch[4](46/375); Loss: 0.045132; Backpropagation: 0.2885 sec; Batch: 2.0865 sec
0.0887 0.0679 0.0541 0.0487 0.0453 0.0429 0.0412 0.0397 0.0386 0.0377 0.0372 0.0367 0.0363 0.0360 0.0357 0.0356 

[TRAIN] Epoch[4](47/375); Loss: 0.035214; Backpropagation: 0.2890 sec; Batch: 2.0740 sec
0.0871 0.0643 0.0458 0.0392 0.0344 0.0323 0.0301 0.0286 0.0273 0.0263 0.0256 0.0251 0.0247 0.0244 0.0242 0.0241 

[TRAIN] Epoch[4](48/375); Loss: 0.043115; Backpropagation: 0.2887 sec; Batch: 2.0962 sec
0.0958 0.0733 0.0550 0.0464 0.0425 0.0398 0.0375 0.0359 0.0347 0.0340 0.0334 0.0329 0.0325 0.0322 0.0320 0.0318 

[TRAIN] Epoch[4](49/375); Loss: 0.053779; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0935 0.0792 0.0659 0.0586 0.0549 0.0522 0.0500 0.0482 0.0469 0.0459 0.0453 0.0447 0.0443 0.0439 0.0436 0.0434 

[TRAIN] Epoch[4](50/375); Loss: 0.040662; Backpropagation: 0.2885 sec; Batch: 2.0726 sec
0.0925 0.0664 0.0504 0.0438 0.0402 0.0377 0.0359 0.0343 0.0332 0.0324 0.0317 0.0311 0.0306 0.0303 0.0301 0.0299 

[TRAIN] Epoch[4](51/375); Loss: 0.063510; Backpropagation: 0.2887 sec; Batch: 2.0750 sec
0.1302 0.1075 0.0804 0.0694 0.0640 0.0597 0.0565 0.0543 0.0526 0.0511 0.0500 0.0491 0.0484 0.0479 0.0476 0.0474 

[TRAIN] Epoch[4](52/375); Loss: 0.044457; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0885 0.0718 0.0558 0.0487 0.0442 0.0416 0.0398 0.0383 0.0373 0.0363 0.0356 0.0351 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[4](53/375); Loss: 0.070769; Backpropagation: 0.2883 sec; Batch: 2.0773 sec
0.1347 0.1100 0.0887 0.0772 0.0710 0.0672 0.0643 0.0620 0.0602 0.0590 0.0579 0.0570 0.0564 0.0559 0.0555 0.0553 

[TRAIN] Epoch[4](54/375); Loss: 0.035526; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.0717 0.0561 0.0421 0.0381 0.0357 0.0340 0.0325 0.0310 0.0301 0.0294 0.0287 0.0283 0.0279 0.0277 0.0275 0.0274 

[TRAIN] Epoch[4](55/375); Loss: 0.027317; Backpropagation: 0.2884 sec; Batch: 2.1039 sec
0.0753 0.0495 0.0343 0.0282 0.0255 0.0239 0.0226 0.0215 0.0207 0.0202 0.0198 0.0194 0.0192 0.0190 0.0189 0.0188 

[TRAIN] Epoch[4](56/375); Loss: 0.060623; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1307 0.1006 0.0779 0.0651 0.0599 0.0563 0.0536 0.0514 0.0497 0.0485 0.0474 0.0467 0.0461 0.0456 0.0452 0.0450 

[TRAIN] Epoch[4](57/375); Loss: 0.030336; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.0681 0.0521 0.0392 0.0321 0.0297 0.0273 0.0258 0.0250 0.0244 0.0239 0.0235 0.0232 0.0230 0.0228 0.0227 0.0227 

[TRAIN] Epoch[4](58/375); Loss: 0.040105; Backpropagation: 0.2882 sec; Batch: 2.0787 sec
0.0781 0.0626 0.0485 0.0427 0.0396 0.0378 0.0362 0.0351 0.0342 0.0335 0.0329 0.0325 0.0323 0.0320 0.0319 0.0317 

[TRAIN] Epoch[4](59/375); Loss: 0.057522; Backpropagation: 0.2884 sec; Batch: 2.0760 sec
0.1149 0.0898 0.0719 0.0642 0.0589 0.0551 0.0523 0.0501 0.0484 0.0470 0.0460 0.0452 0.0447 0.0442 0.0439 0.0436 

[TRAIN] Epoch[4](60/375); Loss: 0.038850; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0767 0.0605 0.0479 0.0422 0.0388 0.0364 0.0347 0.0336 0.0327 0.0321 0.0317 0.0313 0.0310 0.0308 0.0307 0.0306 

[TRAIN] Epoch[4](61/375); Loss: 0.054586; Backpropagation: 0.2888 sec; Batch: 2.1110 sec
0.1168 0.0973 0.0753 0.0635 0.0557 0.0503 0.0473 0.0452 0.0433 0.0419 0.0410 0.0402 0.0395 0.0391 0.0386 0.0384 

[TRAIN] Epoch[4](62/375); Loss: 0.043584; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.0984 0.0717 0.0535 0.0470 0.0428 0.0402 0.0383 0.0366 0.0356 0.0347 0.0340 0.0335 0.0331 0.0328 0.0326 0.0325 

[TRAIN] Epoch[4](63/375); Loss: 0.030668; Backpropagation: 0.2889 sec; Batch: 2.0786 sec
0.0945 0.0577 0.0391 0.0331 0.0289 0.0263 0.0244 0.0231 0.0220 0.0214 0.0207 0.0203 0.0200 0.0198 0.0197 0.0196 

[TRAIN] Epoch[4](64/375); Loss: 0.056813; Backpropagation: 0.2886 sec; Batch: 2.0742 sec
0.1135 0.0929 0.0709 0.0620 0.0568 0.0537 0.0511 0.0490 0.0476 0.0463 0.0455 0.0448 0.0443 0.0438 0.0435 0.0432 

[TRAIN] Epoch[4](65/375); Loss: 0.061532; Backpropagation: 0.2883 sec; Batch: 2.0874 sec
0.1077 0.0850 0.0735 0.0670 0.0631 0.0600 0.0577 0.0558 0.0543 0.0532 0.0524 0.0518 0.0513 0.0508 0.0506 0.0503 

[TRAIN] Epoch[4](66/375); Loss: 0.036652; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.0825 0.0600 0.0471 0.0404 0.0369 0.0342 0.0320 0.0306 0.0297 0.0288 0.0282 0.0277 0.0274 0.0272 0.0269 0.0268 

[TRAIN] Epoch[4](67/375); Loss: 0.043093; Backpropagation: 0.2888 sec; Batch: 2.0741 sec
0.0758 0.0651 0.0523 0.0463 0.0431 0.0411 0.0397 0.0386 0.0376 0.0369 0.0362 0.0358 0.0355 0.0353 0.0351 0.0350 

[TRAIN] Epoch[4](68/375); Loss: 0.035128; Backpropagation: 0.2883 sec; Batch: 2.0726 sec
0.0826 0.0586 0.0453 0.0377 0.0337 0.0317 0.0301 0.0289 0.0280 0.0275 0.0270 0.0266 0.0263 0.0261 0.0260 0.0259 

[TRAIN] Epoch[4](69/375); Loss: 0.048507; Backpropagation: 0.2883 sec; Batch: 2.0798 sec
0.0914 0.0736 0.0618 0.0540 0.0498 0.0467 0.0442 0.0427 0.0414 0.0403 0.0395 0.0388 0.0384 0.0380 0.0378 0.0376 

[TRAIN] Epoch[4](70/375); Loss: 0.059484; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1042 0.0885 0.0737 0.0662 0.0616 0.0581 0.0556 0.0535 0.0518 0.0504 0.0495 0.0487 0.0481 0.0476 0.0473 0.0471 

[TRAIN] Epoch[4](71/375); Loss: 0.040504; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.0820 0.0658 0.0530 0.0457 0.0416 0.0385 0.0361 0.0345 0.0333 0.0324 0.0317 0.0312 0.0309 0.0306 0.0305 0.0303 

[TRAIN] Epoch[4](72/375); Loss: 0.061543; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1124 0.0994 0.0830 0.0709 0.0631 0.0577 0.0551 0.0529 0.0514 0.0501 0.0493 0.0488 0.0482 0.0478 0.0475 0.0472 

[TRAIN] Epoch[4](73/375); Loss: 0.062123; Backpropagation: 0.2887 sec; Batch: 2.0749 sec
0.1177 0.0956 0.0788 0.0685 0.0637 0.0598 0.0572 0.0551 0.0531 0.0516 0.0504 0.0496 0.0489 0.0484 0.0480 0.0478 

[TRAIN] Epoch[4](74/375); Loss: 0.056575; Backpropagation: 0.2885 sec; Batch: 2.1049 sec
0.1166 0.0858 0.0711 0.0629 0.0578 0.0537 0.0509 0.0489 0.0473 0.0461 0.0453 0.0447 0.0441 0.0436 0.0434 0.0432 

[TRAIN] Epoch[4](75/375); Loss: 0.049067; Backpropagation: 0.2884 sec; Batch: 2.0784 sec
0.0965 0.0778 0.0625 0.0546 0.0504 0.0474 0.0449 0.0428 0.0414 0.0402 0.0392 0.0383 0.0378 0.0374 0.0371 0.0368 

[TRAIN] Epoch[4](76/375); Loss: 0.056025; Backpropagation: 0.2883 sec; Batch: 2.0787 sec
0.1079 0.0852 0.0687 0.0618 0.0578 0.0545 0.0515 0.0492 0.0476 0.0466 0.0456 0.0448 0.0443 0.0439 0.0436 0.0433 

[TRAIN] Epoch[4](77/375); Loss: 0.035816; Backpropagation: 0.2884 sec; Batch: 2.0764 sec
0.0818 0.0605 0.0457 0.0394 0.0357 0.0331 0.0313 0.0299 0.0288 0.0281 0.0274 0.0269 0.0265 0.0262 0.0260 0.0258 

[TRAIN] Epoch[4](78/375); Loss: 0.039581; Backpropagation: 0.2888 sec; Batch: 2.1099 sec
0.0878 0.0673 0.0525 0.0439 0.0389 0.0363 0.0345 0.0329 0.0319 0.0310 0.0303 0.0298 0.0294 0.0291 0.0289 0.0287 

[TRAIN] Epoch[4](79/375); Loss: 0.054888; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1135 0.0843 0.0708 0.0606 0.0555 0.0517 0.0491 0.0473 0.0460 0.0448 0.0438 0.0431 0.0425 0.0420 0.0417 0.0415 

[TRAIN] Epoch[4](80/375); Loss: 0.046620; Backpropagation: 0.2885 sec; Batch: 2.0775 sec
0.0953 0.0640 0.0541 0.0492 0.0460 0.0441 0.0425 0.0413 0.0403 0.0396 0.0390 0.0386 0.0384 0.0381 0.0379 0.0378 

[TRAIN] Epoch[4](81/375); Loss: 0.043507; Backpropagation: 0.2884 sec; Batch: 2.0796 sec
0.0981 0.0765 0.0590 0.0497 0.0444 0.0408 0.0379 0.0359 0.0344 0.0331 0.0323 0.0316 0.0311 0.0307 0.0304 0.0302 

[TRAIN] Epoch[4](82/375); Loss: 0.030033; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.0739 0.0466 0.0345 0.0317 0.0290 0.0273 0.0261 0.0252 0.0245 0.0240 0.0235 0.0232 0.0230 0.0228 0.0226 0.0225 

[TRAIN] Epoch[4](83/375); Loss: 0.048543; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.0870 0.0690 0.0581 0.0529 0.0498 0.0473 0.0453 0.0438 0.0426 0.0417 0.0409 0.0403 0.0399 0.0396 0.0393 0.0392 

[TRAIN] Epoch[4](84/375); Loss: 0.029759; Backpropagation: 0.2886 sec; Batch: 2.0739 sec
0.0687 0.0524 0.0377 0.0319 0.0290 0.0272 0.0255 0.0243 0.0236 0.0231 0.0227 0.0224 0.0222 0.0220 0.0218 0.0218 

[TRAIN] Epoch[4](85/375); Loss: 0.038546; Backpropagation: 0.2886 sec; Batch: 2.0726 sec
0.0815 0.0626 0.0481 0.0407 0.0375 0.0355 0.0338 0.0328 0.0320 0.0313 0.0308 0.0304 0.0302 0.0300 0.0298 0.0298 

[TRAIN] Epoch[4](86/375); Loss: 0.064081; Backpropagation: 0.2885 sec; Batch: 2.0852 sec
0.1048 0.0895 0.0752 0.0697 0.0656 0.0629 0.0606 0.0588 0.0573 0.0562 0.0553 0.0547 0.0542 0.0537 0.0535 0.0533 

[TRAIN] Epoch[4](87/375); Loss: 0.037287; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.0916 0.0676 0.0504 0.0413 0.0363 0.0332 0.0311 0.0297 0.0287 0.0280 0.0274 0.0269 0.0265 0.0262 0.0260 0.0259 

[TRAIN] Epoch[4](88/375); Loss: 0.045595; Backpropagation: 0.2888 sec; Batch: 2.0747 sec
0.0933 0.0701 0.0560 0.0492 0.0457 0.0430 0.0410 0.0397 0.0384 0.0375 0.0369 0.0364 0.0360 0.0357 0.0354 0.0353 

[TRAIN] Epoch[4](89/375); Loss: 0.034291; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0774 0.0580 0.0443 0.0378 0.0345 0.0321 0.0302 0.0288 0.0278 0.0268 0.0260 0.0256 0.0252 0.0249 0.0247 0.0246 

[TRAIN] Epoch[4](90/375); Loss: 0.037549; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0755 0.0624 0.0479 0.0411 0.0376 0.0354 0.0337 0.0324 0.0312 0.0303 0.0297 0.0293 0.0289 0.0287 0.0285 0.0283 

[TRAIN] Epoch[4](91/375); Loss: 0.036510; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.0979 0.0651 0.0482 0.0400 0.0354 0.0323 0.0301 0.0287 0.0277 0.0268 0.0262 0.0257 0.0254 0.0251 0.0249 0.0248 

[TRAIN] Epoch[4](92/375); Loss: 0.031569; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.0764 0.0505 0.0393 0.0335 0.0309 0.0290 0.0274 0.0261 0.0253 0.0247 0.0243 0.0240 0.0237 0.0235 0.0234 0.0233 

[TRAIN] Epoch[4](93/375); Loss: 0.051350; Backpropagation: 0.2883 sec; Batch: 2.0878 sec
0.0980 0.0782 0.0640 0.0565 0.0522 0.0493 0.0471 0.0453 0.0438 0.0428 0.0420 0.0414 0.0408 0.0404 0.0401 0.0398 

[TRAIN] Epoch[4](94/375); Loss: 0.051341; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.0904 0.0778 0.0607 0.0551 0.0512 0.0490 0.0472 0.0458 0.0448 0.0440 0.0434 0.0429 0.0425 0.0423 0.0422 0.0420 

[TRAIN] Epoch[4](95/375); Loss: 0.053670; Backpropagation: 0.2885 sec; Batch: 2.0769 sec
0.0983 0.0815 0.0673 0.0599 0.0550 0.0520 0.0497 0.0476 0.0460 0.0448 0.0439 0.0433 0.0428 0.0425 0.0422 0.0419 

[TRAIN] Epoch[4](96/375); Loss: 0.040533; Backpropagation: 0.2882 sec; Batch: 2.0770 sec
0.0773 0.0603 0.0497 0.0440 0.0411 0.0390 0.0372 0.0360 0.0348 0.0340 0.0333 0.0329 0.0325 0.0323 0.0321 0.0320 

[TRAIN] Epoch[4](97/375); Loss: 0.034082; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0799 0.0504 0.0409 0.0375 0.0337 0.0314 0.0301 0.0289 0.0280 0.0274 0.0269 0.0265 0.0262 0.0260 0.0258 0.0256 

[TRAIN] Epoch[4](98/375); Loss: 0.041237; Backpropagation: 0.2886 sec; Batch: 2.0752 sec
0.0883 0.0668 0.0528 0.0449 0.0410 0.0384 0.0366 0.0352 0.0340 0.0331 0.0324 0.0319 0.0315 0.0313 0.0310 0.0308 

[TRAIN] Epoch[4](99/375); Loss: 0.036171; Backpropagation: 0.2880 sec; Batch: 2.0743 sec
0.0868 0.0603 0.0458 0.0386 0.0351 0.0329 0.0313 0.0300 0.0291 0.0283 0.0276 0.0272 0.0268 0.0265 0.0263 0.0261 

[TRAIN] Epoch[4](100/375); Loss: 0.036674; Backpropagation: 0.2884 sec; Batch: 2.0766 sec
0.0649 0.0481 0.0435 0.0391 0.0368 0.0352 0.0340 0.0332 0.0326 0.0321 0.0317 0.0314 0.0312 0.0311 0.0309 0.0308 

[TRAIN] Epoch[4](101/375); Loss: 0.042613; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.0900 0.0642 0.0523 0.0461 0.0425 0.0401 0.0383 0.0368 0.0357 0.0350 0.0343 0.0338 0.0335 0.0332 0.0330 0.0329 

[TRAIN] Epoch[4](102/375); Loss: 0.045621; Backpropagation: 0.2884 sec; Batch: 2.1165 sec
0.0925 0.0731 0.0563 0.0484 0.0450 0.0427 0.0411 0.0396 0.0384 0.0375 0.0368 0.0363 0.0359 0.0356 0.0354 0.0352 

[TRAIN] Epoch[4](103/375); Loss: 0.041719; Backpropagation: 0.2880 sec; Batch: 2.0737 sec
0.0892 0.0679 0.0545 0.0467 0.0425 0.0392 0.0369 0.0352 0.0340 0.0331 0.0323 0.0318 0.0315 0.0312 0.0309 0.0307 

[TRAIN] Epoch[4](104/375); Loss: 0.053099; Backpropagation: 0.2886 sec; Batch: 2.1175 sec
0.0959 0.0806 0.0680 0.0608 0.0551 0.0514 0.0490 0.0468 0.0455 0.0443 0.0433 0.0426 0.0422 0.0417 0.0413 0.0410 

[TRAIN] Epoch[4](105/375); Loss: 0.052104; Backpropagation: 0.2888 sec; Batch: 2.0748 sec
0.1185 0.1004 0.0732 0.0589 0.0519 0.0470 0.0440 0.0421 0.0402 0.0388 0.0378 0.0371 0.0365 0.0361 0.0357 0.0354 

[TRAIN] Epoch[4](106/375); Loss: 0.051099; Backpropagation: 0.2886 sec; Batch: 2.0770 sec
0.1006 0.0812 0.0630 0.0540 0.0507 0.0482 0.0460 0.0443 0.0431 0.0423 0.0416 0.0411 0.0407 0.0405 0.0403 0.0401 

[TRAIN] Epoch[4](107/375); Loss: 0.036921; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0897 0.0641 0.0483 0.0406 0.0364 0.0337 0.0317 0.0301 0.0290 0.0281 0.0275 0.0270 0.0266 0.0262 0.0260 0.0258 

[TRAIN] Epoch[4](108/375); Loss: 0.043909; Backpropagation: 0.2882 sec; Batch: 2.1101 sec
0.0929 0.0682 0.0549 0.0481 0.0439 0.0411 0.0390 0.0376 0.0364 0.0356 0.0351 0.0345 0.0342 0.0339 0.0337 0.0335 

[TRAIN] Epoch[4](109/375); Loss: 0.059119; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1049 0.0847 0.0725 0.0645 0.0601 0.0570 0.0548 0.0530 0.0516 0.0506 0.0497 0.0492 0.0488 0.0484 0.0481 0.0479 

[TRAIN] Epoch[4](110/375); Loss: 0.038145; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0898 0.0707 0.0536 0.0422 0.0373 0.0344 0.0324 0.0307 0.0294 0.0285 0.0277 0.0272 0.0269 0.0267 0.0265 0.0264 

[TRAIN] Epoch[4](111/375); Loss: 0.060852; Backpropagation: 0.2887 sec; Batch: 2.1033 sec
0.1142 0.0901 0.0755 0.0674 0.0630 0.0592 0.0563 0.0540 0.0522 0.0509 0.0499 0.0492 0.0485 0.0481 0.0477 0.0474 

[TRAIN] Epoch[4](112/375); Loss: 0.035945; Backpropagation: 0.2885 sec; Batch: 2.0765 sec
0.0858 0.0561 0.0451 0.0397 0.0364 0.0337 0.0317 0.0301 0.0289 0.0281 0.0275 0.0270 0.0266 0.0264 0.0262 0.0260 

[TRAIN] Epoch[4](113/375); Loss: 0.053796; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0901 0.0741 0.0624 0.0575 0.0545 0.0520 0.0502 0.0489 0.0480 0.0473 0.0467 0.0463 0.0461 0.0458 0.0456 0.0454 

[TRAIN] Epoch[4](114/375); Loss: 0.041936; Backpropagation: 0.2883 sec; Batch: 2.0773 sec
0.0911 0.0689 0.0522 0.0442 0.0408 0.0384 0.0367 0.0354 0.0344 0.0337 0.0332 0.0329 0.0326 0.0324 0.0322 0.0320 

[TRAIN] Epoch[4](115/375); Loss: 0.042632; Backpropagation: 0.2884 sec; Batch: 2.0781 sec
0.0869 0.0685 0.0565 0.0490 0.0441 0.0407 0.0380 0.0362 0.0348 0.0339 0.0333 0.0327 0.0323 0.0320 0.0317 0.0316 

[TRAIN] Epoch[4](116/375); Loss: 0.040057; Backpropagation: 0.2884 sec; Batch: 2.0774 sec
0.0958 0.0708 0.0516 0.0444 0.0398 0.0370 0.0348 0.0330 0.0315 0.0305 0.0297 0.0291 0.0287 0.0283 0.0281 0.0279 

[TRAIN] Epoch[4](117/375); Loss: 0.040225; Backpropagation: 0.2880 sec; Batch: 2.0826 sec
0.0673 0.0551 0.0478 0.0434 0.0410 0.0391 0.0375 0.0365 0.0358 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 0.0338 

[TRAIN] Epoch[4](118/375); Loss: 0.061598; Backpropagation: 0.2886 sec; Batch: 2.0735 sec
0.1199 0.0891 0.0732 0.0663 0.0624 0.0592 0.0566 0.0547 0.0532 0.0520 0.0511 0.0504 0.0500 0.0495 0.0491 0.0489 

[TRAIN] Epoch[4](119/375); Loss: 0.036403; Backpropagation: 0.2884 sec; Batch: 2.0775 sec
0.0773 0.0580 0.0466 0.0397 0.0362 0.0338 0.0324 0.0311 0.0303 0.0295 0.0288 0.0283 0.0280 0.0276 0.0275 0.0274 

[TRAIN] Epoch[4](120/375); Loss: 0.060331; Backpropagation: 0.2886 sec; Batch: 2.0812 sec
0.1257 0.0941 0.0764 0.0655 0.0600 0.0562 0.0539 0.0520 0.0505 0.0492 0.0482 0.0475 0.0470 0.0466 0.0463 0.0461 

[TRAIN] Epoch[4](121/375); Loss: 0.051834; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1005 0.0811 0.0651 0.0576 0.0529 0.0495 0.0468 0.0451 0.0437 0.0427 0.0419 0.0413 0.0408 0.0404 0.0401 0.0399 

[TRAIN] Epoch[4](122/375); Loss: 0.059896; Backpropagation: 0.2882 sec; Batch: 2.0778 sec
0.1122 0.0874 0.0729 0.0636 0.0604 0.0572 0.0548 0.0530 0.0518 0.0507 0.0501 0.0495 0.0491 0.0488 0.0486 0.0484 

[TRAIN] Epoch[4](123/375); Loss: 0.045019; Backpropagation: 0.2880 sec; Batch: 2.0771 sec
0.1073 0.0737 0.0579 0.0496 0.0450 0.0416 0.0391 0.0374 0.0359 0.0347 0.0340 0.0335 0.0331 0.0327 0.0325 0.0323 

[TRAIN] Epoch[4](124/375); Loss: 0.054196; Backpropagation: 0.2887 sec; Batch: 2.0831 sec
0.1313 0.0949 0.0734 0.0605 0.0535 0.0488 0.0460 0.0440 0.0423 0.0410 0.0400 0.0392 0.0387 0.0382 0.0378 0.0375 

[TRAIN] Epoch[4](125/375); Loss: 0.044939; Backpropagation: 0.2885 sec; Batch: 2.0810 sec
0.0964 0.0715 0.0567 0.0491 0.0452 0.0421 0.0401 0.0383 0.0371 0.0362 0.0354 0.0348 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[4](126/375); Loss: 0.057475; Backpropagation: 0.2885 sec; Batch: 2.0813 sec
0.1037 0.0827 0.0696 0.0629 0.0585 0.0554 0.0533 0.0515 0.0499 0.0489 0.0482 0.0477 0.0472 0.0468 0.0467 0.0465 

[TRAIN] Epoch[4](127/375); Loss: 0.049980; Backpropagation: 0.2881 sec; Batch: 2.0730 sec
0.0979 0.0729 0.0601 0.0532 0.0503 0.0478 0.0457 0.0441 0.0429 0.0421 0.0415 0.0409 0.0405 0.0402 0.0400 0.0398 

[TRAIN] Epoch[4](128/375); Loss: 0.059159; Backpropagation: 0.2884 sec; Batch: 2.0782 sec
0.1108 0.0895 0.0759 0.0666 0.0606 0.0565 0.0540 0.0518 0.0503 0.0492 0.0482 0.0475 0.0470 0.0465 0.0461 0.0459 

[TRAIN] Epoch[4](129/375); Loss: 0.035540; Backpropagation: 0.2884 sec; Batch: 2.0813 sec
0.0774 0.0525 0.0442 0.0392 0.0358 0.0335 0.0319 0.0306 0.0296 0.0288 0.0283 0.0278 0.0276 0.0273 0.0271 0.0270 

[TRAIN] Epoch[4](130/375); Loss: 0.032649; Backpropagation: 0.2888 sec; Batch: 2.1106 sec
0.0863 0.0580 0.0410 0.0339 0.0305 0.0285 0.0269 0.0259 0.0251 0.0246 0.0242 0.0239 0.0236 0.0234 0.0233 0.0232 

[TRAIN] Epoch[4](131/375); Loss: 0.035033; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.0758 0.0550 0.0417 0.0375 0.0344 0.0325 0.0311 0.0300 0.0292 0.0286 0.0281 0.0278 0.0275 0.0273 0.0271 0.0270 

[TRAIN] Epoch[4](132/375); Loss: 0.030781; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0707 0.0513 0.0400 0.0345 0.0313 0.0290 0.0270 0.0256 0.0247 0.0239 0.0232 0.0228 0.0224 0.0222 0.0220 0.0218 

[TRAIN] Epoch[4](133/375); Loss: 0.056877; Backpropagation: 0.2885 sec; Batch: 2.1132 sec
0.1122 0.0885 0.0718 0.0631 0.0588 0.0546 0.0517 0.0494 0.0479 0.0468 0.0458 0.0448 0.0442 0.0437 0.0434 0.0432 

[TRAIN] Epoch[4](134/375); Loss: 0.053800; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.1170 0.0857 0.0689 0.0589 0.0541 0.0502 0.0476 0.0456 0.0441 0.0431 0.0422 0.0415 0.0410 0.0406 0.0402 0.0400 

[TRAIN] Epoch[4](135/375); Loss: 0.061590; Backpropagation: 0.2884 sec; Batch: 2.0773 sec
0.1074 0.0864 0.0730 0.0664 0.0625 0.0598 0.0577 0.0560 0.0545 0.0534 0.0525 0.0518 0.0514 0.0511 0.0508 0.0506 

[TRAIN] Epoch[4](136/375); Loss: 0.060161; Backpropagation: 0.2886 sec; Batch: 2.1147 sec
0.1176 0.0859 0.0722 0.0649 0.0608 0.0576 0.0553 0.0535 0.0518 0.0506 0.0498 0.0492 0.0487 0.0484 0.0482 0.0480 

[TRAIN] Epoch[4](137/375); Loss: 0.040840; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0895 0.0668 0.0524 0.0454 0.0418 0.0390 0.0366 0.0347 0.0333 0.0322 0.0314 0.0308 0.0303 0.0300 0.0297 0.0295 

[TRAIN] Epoch[4](138/375); Loss: 0.034380; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.0686 0.0501 0.0412 0.0367 0.0341 0.0326 0.0312 0.0301 0.0294 0.0287 0.0284 0.0281 0.0279 0.0278 0.0276 0.0275 

[TRAIN] Epoch[4](139/375); Loss: 0.048366; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.0959 0.0746 0.0609 0.0536 0.0490 0.0459 0.0436 0.0420 0.0409 0.0398 0.0390 0.0385 0.0380 0.0376 0.0374 0.0371 

[TRAIN] Epoch[4](140/375); Loss: 0.052409; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1011 0.0744 0.0628 0.0569 0.0535 0.0506 0.0483 0.0467 0.0453 0.0445 0.0436 0.0430 0.0424 0.0420 0.0418 0.0416 

[TRAIN] Epoch[4](141/375); Loss: 0.040994; Backpropagation: 0.2888 sec; Batch: 2.0742 sec
0.0959 0.0637 0.0502 0.0436 0.0404 0.0382 0.0362 0.0347 0.0335 0.0326 0.0320 0.0315 0.0311 0.0309 0.0307 0.0306 

[TRAIN] Epoch[4](142/375); Loss: 0.061908; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.1153 0.0893 0.0749 0.0668 0.0629 0.0598 0.0575 0.0555 0.0540 0.0526 0.0516 0.0509 0.0504 0.0500 0.0496 0.0494 

[TRAIN] Epoch[4](143/375); Loss: 0.040695; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0919 0.0696 0.0526 0.0439 0.0399 0.0372 0.0354 0.0338 0.0327 0.0319 0.0313 0.0308 0.0304 0.0301 0.0299 0.0298 

[TRAIN] Epoch[4](144/375); Loss: 0.033454; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0655 0.0477 0.0384 0.0353 0.0334 0.0315 0.0302 0.0295 0.0290 0.0286 0.0282 0.0279 0.0277 0.0275 0.0274 0.0274 

[TRAIN] Epoch[4](145/375); Loss: 0.060010; Backpropagation: 0.2889 sec; Batch: 2.0756 sec
0.1156 0.0857 0.0712 0.0640 0.0599 0.0569 0.0547 0.0530 0.0518 0.0509 0.0503 0.0498 0.0495 0.0491 0.0490 0.0488 

[TRAIN] Epoch[4](146/375); Loss: 0.049770; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0998 0.0770 0.0626 0.0542 0.0503 0.0473 0.0450 0.0432 0.0418 0.0409 0.0401 0.0395 0.0390 0.0387 0.0385 0.0383 

[TRAIN] Epoch[4](147/375); Loss: 0.051506; Backpropagation: 0.2881 sec; Batch: 2.0771 sec
0.0990 0.0755 0.0619 0.0564 0.0523 0.0493 0.0472 0.0455 0.0441 0.0433 0.0426 0.0420 0.0416 0.0413 0.0411 0.0410 

[TRAIN] Epoch[4](148/375); Loss: 0.033631; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0886 0.0564 0.0415 0.0352 0.0318 0.0298 0.0283 0.0271 0.0264 0.0258 0.0252 0.0248 0.0245 0.0243 0.0242 0.0241 

[TRAIN] Epoch[4](149/375); Loss: 0.067202; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1344 0.1035 0.0860 0.0755 0.0693 0.0642 0.0610 0.0585 0.0565 0.0547 0.0537 0.0528 0.0520 0.0514 0.0510 0.0507 

[TRAIN] Epoch[4](150/375); Loss: 0.055903; Backpropagation: 0.2887 sec; Batch: 2.0746 sec
0.1331 0.0905 0.0694 0.0591 0.0542 0.0510 0.0485 0.0466 0.0452 0.0441 0.0432 0.0426 0.0421 0.0419 0.0417 0.0414 

[TRAIN] Epoch[4](151/375); Loss: 0.077996; Backpropagation: 0.2895 sec; Batch: 2.0772 sec
0.1641 0.1381 0.1128 0.0952 0.0803 0.0712 0.0662 0.0627 0.0605 0.0592 0.0580 0.0571 0.0563 0.0558 0.0554 0.0551 

[TRAIN] Epoch[4](152/375); Loss: 0.051781; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.0937 0.0719 0.0617 0.0566 0.0530 0.0504 0.0484 0.0467 0.0455 0.0445 0.0438 0.0432 0.0427 0.0424 0.0422 0.0419 

[TRAIN] Epoch[4](153/375); Loss: 0.034987; Backpropagation: 0.2884 sec; Batch: 2.0769 sec
0.0888 0.0578 0.0435 0.0375 0.0339 0.0316 0.0298 0.0286 0.0276 0.0269 0.0264 0.0259 0.0256 0.0254 0.0253 0.0251 

[TRAIN] Epoch[4](154/375); Loss: 0.045747; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0863 0.0673 0.0558 0.0500 0.0465 0.0439 0.0419 0.0404 0.0394 0.0386 0.0378 0.0374 0.0370 0.0367 0.0365 0.0364 

[TRAIN] Epoch[4](155/375); Loss: 0.067708; Backpropagation: 0.2886 sec; Batch: 2.0778 sec
0.1319 0.1168 0.0936 0.0776 0.0682 0.0616 0.0584 0.0566 0.0549 0.0537 0.0528 0.0522 0.0517 0.0514 0.0511 0.0509 

[TRAIN] Epoch[4](156/375); Loss: 0.042841; Backpropagation: 0.2884 sec; Batch: 2.1136 sec
0.0896 0.0593 0.0526 0.0464 0.0430 0.0407 0.0390 0.0377 0.0365 0.0356 0.0350 0.0345 0.0342 0.0339 0.0337 0.0336 

[TRAIN] Epoch[4](157/375); Loss: 0.052641; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.1060 0.0786 0.0622 0.0557 0.0526 0.0503 0.0482 0.0466 0.0453 0.0442 0.0434 0.0426 0.0422 0.0417 0.0414 0.0412 

[TRAIN] Epoch[4](158/375); Loss: 0.042349; Backpropagation: 0.2885 sec; Batch: 2.0772 sec
0.0716 0.0571 0.0496 0.0455 0.0430 0.0413 0.0399 0.0388 0.0378 0.0371 0.0367 0.0363 0.0360 0.0358 0.0356 0.0355 

[TRAIN] Epoch[4](159/375); Loss: 0.041966; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.0846 0.0663 0.0544 0.0471 0.0430 0.0400 0.0377 0.0361 0.0350 0.0340 0.0333 0.0327 0.0322 0.0319 0.0317 0.0315 

[TRAIN] Epoch[4](160/375); Loss: 0.056968; Backpropagation: 0.2888 sec; Batch: 2.1104 sec
0.1107 0.0858 0.0701 0.0610 0.0568 0.0541 0.0520 0.0502 0.0488 0.0477 0.0470 0.0463 0.0458 0.0454 0.0451 0.0448 

[TRAIN] Epoch[4](161/375); Loss: 0.055252; Backpropagation: 0.2880 sec; Batch: 2.0738 sec
0.1256 0.0881 0.0704 0.0593 0.0543 0.0504 0.0477 0.0459 0.0447 0.0439 0.0432 0.0427 0.0423 0.0420 0.0418 0.0416 

[TRAIN] Epoch[4](162/375); Loss: 0.041450; Backpropagation: 0.2884 sec; Batch: 2.0769 sec
0.0868 0.0605 0.0487 0.0432 0.0403 0.0386 0.0373 0.0362 0.0354 0.0347 0.0343 0.0339 0.0336 0.0334 0.0332 0.0332 

[TRAIN] Epoch[4](163/375); Loss: 0.038640; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0905 0.0607 0.0482 0.0413 0.0378 0.0357 0.0338 0.0325 0.0315 0.0306 0.0300 0.0296 0.0293 0.0290 0.0289 0.0288 

[TRAIN] Epoch[4](164/375); Loss: 0.051610; Backpropagation: 0.2887 sec; Batch: 2.1100 sec
0.0947 0.0785 0.0639 0.0570 0.0529 0.0500 0.0474 0.0457 0.0441 0.0432 0.0424 0.0419 0.0415 0.0411 0.0408 0.0406 

[TRAIN] Epoch[4](165/375); Loss: 0.042325; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1094 0.0676 0.0534 0.0448 0.0404 0.0378 0.0359 0.0345 0.0335 0.0326 0.0320 0.0315 0.0312 0.0310 0.0308 0.0307 

[TRAIN] Epoch[4](166/375); Loss: 0.060666; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.1199 0.1001 0.0815 0.0701 0.0627 0.0572 0.0536 0.0516 0.0499 0.0484 0.0475 0.0467 0.0460 0.0456 0.0452 0.0449 

[TRAIN] Epoch[4](167/375); Loss: 0.044697; Backpropagation: 0.2884 sec; Batch: 2.0752 sec
0.0935 0.0730 0.0588 0.0496 0.0443 0.0416 0.0392 0.0377 0.0366 0.0357 0.0351 0.0346 0.0342 0.0339 0.0337 0.0334 

[TRAIN] Epoch[4](168/375); Loss: 0.057892; Backpropagation: 0.2888 sec; Batch: 2.1081 sec
0.1076 0.0829 0.0702 0.0632 0.0591 0.0561 0.0536 0.0516 0.0502 0.0491 0.0483 0.0477 0.0472 0.0468 0.0465 0.0463 

[TRAIN] Epoch[4](169/375); Loss: 0.043423; Backpropagation: 0.2882 sec; Batch: 2.0924 sec
0.0875 0.0652 0.0543 0.0470 0.0430 0.0405 0.0389 0.0375 0.0365 0.0358 0.0354 0.0350 0.0348 0.0345 0.0344 0.0343 

[TRAIN] Epoch[4](170/375); Loss: 0.041459; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0709 0.0582 0.0504 0.0460 0.0431 0.0409 0.0390 0.0375 0.0364 0.0355 0.0349 0.0346 0.0343 0.0341 0.0339 0.0338 

[TRAIN] Epoch[4](171/375); Loss: 0.080219; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1441 0.1177 0.0997 0.0890 0.0825 0.0782 0.0748 0.0719 0.0695 0.0678 0.0665 0.0656 0.0649 0.0643 0.0638 0.0633 

[TRAIN] Epoch[4](172/375); Loss: 0.042063; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0888 0.0658 0.0524 0.0457 0.0419 0.0393 0.0376 0.0363 0.0352 0.0343 0.0336 0.0331 0.0327 0.0324 0.0321 0.0320 

[TRAIN] Epoch[4](173/375); Loss: 0.037768; Backpropagation: 0.2884 sec; Batch: 2.0833 sec
0.0888 0.0560 0.0451 0.0396 0.0368 0.0349 0.0332 0.0321 0.0311 0.0305 0.0300 0.0297 0.0294 0.0292 0.0290 0.0289 

[TRAIN] Epoch[4](174/375); Loss: 0.046989; Backpropagation: 0.2887 sec; Batch: 2.0749 sec
0.0981 0.0758 0.0615 0.0530 0.0476 0.0439 0.0414 0.0396 0.0384 0.0374 0.0368 0.0362 0.0359 0.0356 0.0353 0.0352 

[TRAIN] Epoch[4](175/375); Loss: 0.058500; Backpropagation: 0.2879 sec; Batch: 2.0763 sec
0.1182 0.0914 0.0741 0.0652 0.0600 0.0562 0.0532 0.0510 0.0489 0.0476 0.0465 0.0458 0.0451 0.0446 0.0443 0.0439 

[TRAIN] Epoch[4](176/375); Loss: 0.036433; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.0775 0.0550 0.0462 0.0403 0.0369 0.0343 0.0325 0.0313 0.0304 0.0295 0.0290 0.0286 0.0282 0.0279 0.0277 0.0275 

[TRAIN] Epoch[4](177/375); Loss: 0.052895; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0982 0.0757 0.0651 0.0586 0.0545 0.0512 0.0487 0.0469 0.0456 0.0447 0.0439 0.0433 0.0429 0.0426 0.0423 0.0421 

[TRAIN] Epoch[4](178/375); Loss: 0.041863; Backpropagation: 0.2886 sec; Batch: 2.0764 sec
0.0868 0.0656 0.0513 0.0451 0.0417 0.0390 0.0373 0.0361 0.0351 0.0344 0.0338 0.0333 0.0329 0.0326 0.0324 0.0323 

[TRAIN] Epoch[4](179/375); Loss: 0.062894; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1171 0.0907 0.0776 0.0692 0.0645 0.0613 0.0583 0.0561 0.0545 0.0531 0.0520 0.0513 0.0508 0.0503 0.0498 0.0496 

[TRAIN] Epoch[4](180/375); Loss: 0.045998; Backpropagation: 0.2885 sec; Batch: 2.0766 sec
0.1077 0.0812 0.0609 0.0495 0.0443 0.0411 0.0390 0.0376 0.0363 0.0355 0.0349 0.0342 0.0338 0.0335 0.0332 0.0331 

[TRAIN] Epoch[4](181/375); Loss: 0.036057; Backpropagation: 0.2886 sec; Batch: 2.0783 sec
0.0856 0.0636 0.0454 0.0389 0.0349 0.0326 0.0309 0.0296 0.0287 0.0279 0.0273 0.0269 0.0266 0.0263 0.0261 0.0259 

[TRAIN] Epoch[4](182/375); Loss: 0.027699; Backpropagation: 0.2884 sec; Batch: 2.0780 sec
0.0563 0.0436 0.0340 0.0301 0.0275 0.0261 0.0251 0.0241 0.0234 0.0227 0.0223 0.0220 0.0217 0.0215 0.0214 0.0213 

[TRAIN] Epoch[4](183/375); Loss: 0.050121; Backpropagation: 0.2888 sec; Batch: 2.0737 sec
0.1094 0.0734 0.0609 0.0536 0.0500 0.0474 0.0454 0.0436 0.0421 0.0411 0.0403 0.0397 0.0392 0.0388 0.0386 0.0383 

[TRAIN] Epoch[4](184/375); Loss: 0.036675; Backpropagation: 0.2883 sec; Batch: 2.0823 sec
0.0752 0.0553 0.0450 0.0399 0.0363 0.0343 0.0329 0.0319 0.0310 0.0303 0.0298 0.0294 0.0291 0.0289 0.0288 0.0287 

[TRAIN] Epoch[4](185/375); Loss: 0.043855; Backpropagation: 0.2883 sec; Batch: 2.0768 sec
0.0956 0.0675 0.0551 0.0478 0.0442 0.0411 0.0391 0.0375 0.0363 0.0354 0.0346 0.0342 0.0337 0.0334 0.0332 0.0331 

[TRAIN] Epoch[4](186/375); Loss: 0.033592; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0801 0.0521 0.0400 0.0356 0.0328 0.0305 0.0290 0.0281 0.0275 0.0269 0.0264 0.0261 0.0259 0.0257 0.0255 0.0254 

[TRAIN] Epoch[4](187/375); Loss: 0.051782; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1088 0.0787 0.0658 0.0578 0.0531 0.0491 0.0466 0.0446 0.0431 0.0420 0.0411 0.0404 0.0399 0.0395 0.0392 0.0390 

[TRAIN] Epoch[4](188/375); Loss: 0.027380; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0832 0.0509 0.0338 0.0269 0.0243 0.0230 0.0217 0.0208 0.0202 0.0197 0.0194 0.0191 0.0189 0.0188 0.0187 0.0186 

[TRAIN] Epoch[4](189/375); Loss: 0.053626; Backpropagation: 0.2883 sec; Batch: 2.0875 sec
0.0994 0.0729 0.0626 0.0576 0.0544 0.0521 0.0500 0.0484 0.0472 0.0462 0.0455 0.0450 0.0446 0.0443 0.0440 0.0438 

[TRAIN] Epoch[4](190/375); Loss: 0.045178; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1016 0.0722 0.0591 0.0504 0.0455 0.0424 0.0400 0.0379 0.0368 0.0357 0.0348 0.0341 0.0335 0.0332 0.0329 0.0327 

[TRAIN] Epoch[4](191/375); Loss: 0.051161; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1197 0.0818 0.0676 0.0559 0.0503 0.0469 0.0445 0.0427 0.0411 0.0399 0.0392 0.0385 0.0380 0.0377 0.0374 0.0371 

[TRAIN] Epoch[4](192/375); Loss: 0.059482; Backpropagation: 0.2883 sec; Batch: 2.0867 sec
0.1241 0.0879 0.0725 0.0648 0.0598 0.0561 0.0536 0.0517 0.0503 0.0491 0.0481 0.0475 0.0470 0.0467 0.0464 0.0461 

[TRAIN] Epoch[4](193/375); Loss: 0.030308; Backpropagation: 0.2881 sec; Batch: 2.0730 sec
0.0771 0.0533 0.0414 0.0341 0.0301 0.0272 0.0254 0.0242 0.0232 0.0224 0.0219 0.0215 0.0211 0.0209 0.0207 0.0206 

[TRAIN] Epoch[4](194/375); Loss: 0.046602; Backpropagation: 0.2884 sec; Batch: 2.0765 sec
0.0941 0.0697 0.0573 0.0505 0.0467 0.0440 0.0420 0.0408 0.0395 0.0386 0.0380 0.0374 0.0371 0.0368 0.0366 0.0364 

[TRAIN] Epoch[4](195/375); Loss: 0.033300; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0661 0.0484 0.0397 0.0355 0.0333 0.0318 0.0305 0.0295 0.0288 0.0281 0.0276 0.0272 0.0268 0.0266 0.0264 0.0263 

[TRAIN] Epoch[4](196/375); Loss: 0.059608; Backpropagation: 0.2886 sec; Batch: 2.1097 sec
0.1236 0.0993 0.0774 0.0673 0.0605 0.0552 0.0523 0.0503 0.0488 0.0475 0.0465 0.0458 0.0453 0.0449 0.0446 0.0444 

[TRAIN] Epoch[4](197/375); Loss: 0.040023; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0802 0.0615 0.0506 0.0445 0.0407 0.0379 0.0359 0.0345 0.0336 0.0328 0.0322 0.0317 0.0314 0.0311 0.0309 0.0307 

[TRAIN] Epoch[4](198/375); Loss: 0.061539; Backpropagation: 0.2882 sec; Batch: 2.1121 sec
0.1328 0.1033 0.0804 0.0678 0.0599 0.0563 0.0537 0.0517 0.0501 0.0489 0.0479 0.0472 0.0466 0.0463 0.0460 0.0458 

[TRAIN] Epoch[4](199/375); Loss: 0.052270; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.1113 0.0795 0.0654 0.0573 0.0525 0.0491 0.0465 0.0448 0.0436 0.0425 0.0418 0.0412 0.0407 0.0403 0.0400 0.0398 

[TRAIN] Epoch[4](200/375); Loss: 0.042920; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.0882 0.0652 0.0541 0.0488 0.0448 0.0418 0.0392 0.0370 0.0354 0.0345 0.0338 0.0334 0.0330 0.0327 0.0325 0.0323 

[TRAIN] Epoch[4](201/375); Loss: 0.052126; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1040 0.0795 0.0649 0.0567 0.0525 0.0494 0.0472 0.0455 0.0442 0.0431 0.0423 0.0417 0.0412 0.0408 0.0405 0.0403 

[TRAIN] Epoch[4](202/375); Loss: 0.040836; Backpropagation: 0.2881 sec; Batch: 2.0932 sec
0.0950 0.0600 0.0494 0.0435 0.0398 0.0377 0.0359 0.0347 0.0338 0.0331 0.0325 0.0321 0.0318 0.0315 0.0314 0.0313 

[TRAIN] Epoch[4](203/375); Loss: 0.057477; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1079 0.0758 0.0670 0.0617 0.0580 0.0555 0.0535 0.0518 0.0506 0.0497 0.0489 0.0484 0.0480 0.0477 0.0475 0.0474 

[TRAIN] Epoch[4](204/375); Loss: 0.044752; Backpropagation: 0.2882 sec; Batch: 2.0777 sec
0.1040 0.0763 0.0577 0.0472 0.0436 0.0403 0.0383 0.0368 0.0357 0.0350 0.0344 0.0339 0.0336 0.0333 0.0331 0.0330 

[TRAIN] Epoch[4](205/375); Loss: 0.043498; Backpropagation: 0.2884 sec; Batch: 2.0856 sec
0.0946 0.0713 0.0551 0.0469 0.0432 0.0406 0.0385 0.0368 0.0357 0.0348 0.0341 0.0336 0.0331 0.0328 0.0326 0.0324 

[TRAIN] Epoch[4](206/375); Loss: 0.037141; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.0728 0.0558 0.0461 0.0395 0.0367 0.0353 0.0339 0.0328 0.0318 0.0311 0.0304 0.0300 0.0297 0.0295 0.0294 0.0293 

[TRAIN] Epoch[4](207/375); Loss: 0.053003; Backpropagation: 0.2885 sec; Batch: 2.0845 sec
0.1225 0.0832 0.0659 0.0583 0.0530 0.0494 0.0468 0.0446 0.0432 0.0420 0.0411 0.0404 0.0399 0.0395 0.0392 0.0389 

[TRAIN] Epoch[4](208/375); Loss: 0.050120; Backpropagation: 0.2882 sec; Batch: 2.0793 sec
0.1215 0.1012 0.0770 0.0593 0.0492 0.0433 0.0400 0.0378 0.0365 0.0353 0.0345 0.0339 0.0335 0.0332 0.0329 0.0327 

[TRAIN] Epoch[4](209/375); Loss: 0.068684; Backpropagation: 0.2884 sec; Batch: 2.0764 sec
0.1316 0.1000 0.0833 0.0748 0.0699 0.0660 0.0633 0.0610 0.0592 0.0579 0.0569 0.0560 0.0554 0.0549 0.0545 0.0543 

[TRAIN] Epoch[4](210/375); Loss: 0.046166; Backpropagation: 0.2881 sec; Batch: 2.0822 sec
0.0899 0.0667 0.0548 0.0490 0.0460 0.0439 0.0422 0.0410 0.0401 0.0394 0.0386 0.0381 0.0377 0.0373 0.0371 0.0369 

[TRAIN] Epoch[4](211/375); Loss: 0.053740; Backpropagation: 0.2884 sec; Batch: 2.0784 sec
0.1183 0.0900 0.0717 0.0599 0.0538 0.0497 0.0467 0.0445 0.0432 0.0421 0.0412 0.0405 0.0401 0.0398 0.0395 0.0392 

[TRAIN] Epoch[4](212/375); Loss: 0.038734; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0746 0.0544 0.0457 0.0413 0.0387 0.0369 0.0355 0.0345 0.0338 0.0331 0.0326 0.0321 0.0319 0.0317 0.0315 0.0315 

[TRAIN] Epoch[4](213/375); Loss: 0.056204; Backpropagation: 0.2883 sec; Batch: 2.0785 sec
0.1254 0.0996 0.0786 0.0657 0.0559 0.0506 0.0476 0.0457 0.0441 0.0427 0.0418 0.0411 0.0406 0.0403 0.0399 0.0396 

[TRAIN] Epoch[4](214/375); Loss: 0.048706; Backpropagation: 0.2885 sec; Batch: 2.0814 sec
0.1098 0.0809 0.0617 0.0522 0.0474 0.0444 0.0424 0.0408 0.0393 0.0385 0.0379 0.0373 0.0370 0.0367 0.0365 0.0364 

[TRAIN] Epoch[4](215/375); Loss: 0.030865; Backpropagation: 0.2883 sec; Batch: 2.0785 sec
0.0863 0.0550 0.0405 0.0333 0.0294 0.0269 0.0253 0.0240 0.0231 0.0225 0.0219 0.0216 0.0213 0.0211 0.0209 0.0208 

[TRAIN] Epoch[4](216/375); Loss: 0.042652; Backpropagation: 0.2883 sec; Batch: 2.1102 sec
0.1044 0.0682 0.0538 0.0455 0.0415 0.0388 0.0369 0.0353 0.0342 0.0334 0.0327 0.0321 0.0317 0.0315 0.0312 0.0310 

[TRAIN] Epoch[4](217/375); Loss: 0.039273; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0887 0.0638 0.0493 0.0432 0.0391 0.0364 0.0345 0.0331 0.0319 0.0310 0.0304 0.0300 0.0296 0.0293 0.0290 0.0288 

[TRAIN] Epoch[4](218/375); Loss: 0.062678; Backpropagation: 0.2885 sec; Batch: 2.0763 sec
0.1338 0.1042 0.0829 0.0706 0.0636 0.0587 0.0551 0.0524 0.0506 0.0492 0.0483 0.0476 0.0470 0.0466 0.0462 0.0459 

[TRAIN] Epoch[4](219/375); Loss: 0.049665; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1023 0.0752 0.0612 0.0543 0.0501 0.0471 0.0448 0.0429 0.0417 0.0407 0.0399 0.0395 0.0391 0.0388 0.0386 0.0384 

[TRAIN] Epoch[4](220/375); Loss: 0.056386; Backpropagation: 0.2884 sec; Batch: 2.0803 sec
0.1131 0.0834 0.0675 0.0611 0.0567 0.0532 0.0513 0.0496 0.0483 0.0472 0.0462 0.0456 0.0451 0.0448 0.0446 0.0445 

[TRAIN] Epoch[4](221/375); Loss: 0.079227; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1227 0.1072 0.0951 0.0881 0.0834 0.0798 0.0763 0.0735 0.0713 0.0696 0.0685 0.0676 0.0668 0.0663 0.0658 0.0655 

[TRAIN] Epoch[4](222/375); Loss: 0.056350; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.1139 0.0844 0.0709 0.0625 0.0576 0.0540 0.0513 0.0492 0.0477 0.0464 0.0454 0.0446 0.0441 0.0436 0.0432 0.0429 

[TRAIN] Epoch[4](223/375); Loss: 0.045836; Backpropagation: 0.2887 sec; Batch: 2.0729 sec
0.0893 0.0703 0.0565 0.0496 0.0464 0.0438 0.0419 0.0402 0.0391 0.0382 0.0374 0.0369 0.0364 0.0360 0.0358 0.0356 

[TRAIN] Epoch[4](224/375); Loss: 0.045212; Backpropagation: 0.2887 sec; Batch: 2.0792 sec
0.0910 0.0684 0.0563 0.0496 0.0457 0.0430 0.0409 0.0393 0.0381 0.0373 0.0366 0.0360 0.0356 0.0354 0.0351 0.0350 

[TRAIN] Epoch[4](225/375); Loss: 0.057232; Backpropagation: 0.2889 sec; Batch: 2.1139 sec
0.0946 0.0787 0.0684 0.0626 0.0588 0.0561 0.0538 0.0521 0.0509 0.0500 0.0493 0.0487 0.0483 0.0480 0.0477 0.0475 

[TRAIN] Epoch[4](226/375); Loss: 0.028345; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0661 0.0459 0.0372 0.0308 0.0277 0.0258 0.0245 0.0235 0.0227 0.0221 0.0217 0.0214 0.0212 0.0211 0.0209 0.0209 

[TRAIN] Epoch[4](227/375); Loss: 0.058569; Backpropagation: 0.2886 sec; Batch: 2.0767 sec
0.1124 0.0864 0.0712 0.0620 0.0589 0.0563 0.0538 0.0518 0.0503 0.0492 0.0485 0.0479 0.0475 0.0471 0.0469 0.0467 

[TRAIN] Epoch[4](228/375); Loss: 0.043436; Backpropagation: 0.2890 sec; Batch: 2.1100 sec
0.0923 0.0704 0.0576 0.0497 0.0444 0.0409 0.0380 0.0360 0.0350 0.0343 0.0336 0.0331 0.0327 0.0325 0.0323 0.0321 

[TRAIN] Epoch[4](229/375); Loss: 0.073096; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1339 0.1048 0.0890 0.0807 0.0754 0.0715 0.0682 0.0653 0.0633 0.0619 0.0608 0.0599 0.0594 0.0588 0.0585 0.0582 

[TRAIN] Epoch[4](230/375); Loss: 0.053326; Backpropagation: 0.2889 sec; Batch: 2.1145 sec
0.1033 0.0775 0.0660 0.0595 0.0552 0.0517 0.0491 0.0471 0.0454 0.0444 0.0435 0.0428 0.0424 0.0420 0.0417 0.0415 

[TRAIN] Epoch[4](231/375); Loss: 0.051510; Backpropagation: 0.2887 sec; Batch: 2.0729 sec
0.1304 0.0889 0.0623 0.0522 0.0484 0.0458 0.0438 0.0422 0.0410 0.0400 0.0392 0.0387 0.0382 0.0379 0.0377 0.0375 

[TRAIN] Epoch[4](232/375); Loss: 0.051498; Backpropagation: 0.2883 sec; Batch: 2.0767 sec
0.1001 0.0743 0.0626 0.0562 0.0524 0.0494 0.0469 0.0454 0.0441 0.0433 0.0426 0.0420 0.0416 0.0413 0.0411 0.0409 

[TRAIN] Epoch[4](233/375); Loss: 0.046782; Backpropagation: 0.2884 sec; Batch: 2.1107 sec
0.0899 0.0711 0.0592 0.0518 0.0481 0.0452 0.0430 0.0412 0.0398 0.0386 0.0378 0.0373 0.0367 0.0364 0.0362 0.0360 

[TRAIN] Epoch[4](234/375); Loss: 0.052507; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1220 0.0904 0.0683 0.0571 0.0515 0.0477 0.0452 0.0432 0.0418 0.0407 0.0398 0.0392 0.0387 0.0383 0.0381 0.0378 

[TRAIN] Epoch[4](235/375); Loss: 0.037430; Backpropagation: 0.2882 sec; Batch: 2.0806 sec
0.0787 0.0560 0.0454 0.0401 0.0373 0.0350 0.0334 0.0324 0.0315 0.0309 0.0304 0.0300 0.0297 0.0295 0.0293 0.0292 

[TRAIN] Epoch[4](236/375); Loss: 0.041675; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0888 0.0616 0.0500 0.0439 0.0406 0.0388 0.0374 0.0362 0.0352 0.0345 0.0340 0.0336 0.0333 0.0331 0.0330 0.0329 

[TRAIN] Epoch[4](237/375); Loss: 0.043442; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.0993 0.0699 0.0548 0.0470 0.0430 0.0402 0.0382 0.0366 0.0356 0.0345 0.0338 0.0332 0.0327 0.0324 0.0321 0.0318 

[TRAIN] Epoch[4](238/375); Loss: 0.041546; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0835 0.0617 0.0521 0.0460 0.0421 0.0394 0.0375 0.0360 0.0350 0.0342 0.0336 0.0332 0.0329 0.0326 0.0324 0.0323 

[TRAIN] Epoch[4](239/375); Loss: 0.040763; Backpropagation: 0.2883 sec; Batch: 2.1128 sec
0.0949 0.0630 0.0480 0.0422 0.0394 0.0374 0.0359 0.0348 0.0338 0.0330 0.0324 0.0320 0.0317 0.0314 0.0312 0.0311 

[TRAIN] Epoch[4](240/375); Loss: 0.057324; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1170 0.0856 0.0724 0.0638 0.0581 0.0547 0.0517 0.0497 0.0482 0.0471 0.0460 0.0453 0.0449 0.0445 0.0442 0.0440 

[TRAIN] Epoch[4](241/375); Loss: 0.038311; Backpropagation: 0.2881 sec; Batch: 2.0848 sec
0.0804 0.0571 0.0473 0.0409 0.0380 0.0361 0.0346 0.0333 0.0323 0.0316 0.0311 0.0306 0.0302 0.0300 0.0298 0.0297 

[TRAIN] Epoch[4](242/375); Loss: 0.054462; Backpropagation: 0.2882 sec; Batch: 2.0756 sec
0.0975 0.0767 0.0656 0.0585 0.0554 0.0527 0.0504 0.0490 0.0478 0.0468 0.0461 0.0456 0.0452 0.0449 0.0447 0.0445 

[TRAIN] Epoch[4](243/375); Loss: 0.050226; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.1076 0.0763 0.0611 0.0543 0.0504 0.0477 0.0452 0.0431 0.0418 0.0408 0.0402 0.0397 0.0393 0.0389 0.0387 0.0386 

[TRAIN] Epoch[4](244/375); Loss: 0.037869; Backpropagation: 0.2887 sec; Batch: 2.0878 sec
0.0786 0.0564 0.0474 0.0419 0.0378 0.0350 0.0334 0.0323 0.0315 0.0309 0.0306 0.0303 0.0301 0.0300 0.0299 0.0299 

[TRAIN] Epoch[4](245/375); Loss: 0.030524; Backpropagation: 0.2882 sec; Batch: 2.0764 sec
0.0775 0.0492 0.0371 0.0323 0.0295 0.0275 0.0262 0.0253 0.0244 0.0238 0.0232 0.0229 0.0226 0.0224 0.0223 0.0222 

[TRAIN] Epoch[4](246/375); Loss: 0.023787; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0503 0.0363 0.0302 0.0258 0.0238 0.0219 0.0208 0.0200 0.0196 0.0193 0.0191 0.0189 0.0188 0.0187 0.0186 0.0186 

[TRAIN] Epoch[4](247/375); Loss: 0.064542; Backpropagation: 0.2883 sec; Batch: 2.0772 sec
0.1435 0.1145 0.0900 0.0746 0.0654 0.0592 0.0554 0.0530 0.0507 0.0492 0.0479 0.0470 0.0462 0.0457 0.0453 0.0450 

[TRAIN] Epoch[4](248/375); Loss: 0.047535; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.1138 0.0828 0.0633 0.0521 0.0472 0.0437 0.0412 0.0392 0.0375 0.0363 0.0352 0.0345 0.0340 0.0335 0.0332 0.0330 

[TRAIN] Epoch[4](249/375); Loss: 0.051059; Backpropagation: 0.2887 sec; Batch: 2.0765 sec
0.1041 0.0770 0.0615 0.0544 0.0502 0.0477 0.0458 0.0445 0.0434 0.0425 0.0419 0.0415 0.0410 0.0407 0.0405 0.0403 

[TRAIN] Epoch[4](250/375); Loss: 0.034827; Backpropagation: 0.2884 sec; Batch: 2.0761 sec
0.0765 0.0533 0.0443 0.0395 0.0362 0.0334 0.0311 0.0297 0.0285 0.0276 0.0270 0.0266 0.0263 0.0260 0.0258 0.0257 

[TRAIN] Epoch[4](251/375); Loss: 0.048507; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1099 0.0841 0.0631 0.0523 0.0469 0.0436 0.0416 0.0401 0.0389 0.0381 0.0373 0.0367 0.0363 0.0360 0.0357 0.0355 

[TRAIN] Epoch[4](252/375); Loss: 0.057813; Backpropagation: 0.2884 sec; Batch: 2.0859 sec
0.1053 0.0829 0.0686 0.0623 0.0584 0.0555 0.0533 0.0518 0.0506 0.0495 0.0488 0.0483 0.0479 0.0475 0.0473 0.0471 

[TRAIN] Epoch[4](253/375); Loss: 0.060485; Backpropagation: 0.2886 sec; Batch: 2.0761 sec
0.1067 0.0880 0.0741 0.0661 0.0614 0.0582 0.0559 0.0541 0.0528 0.0518 0.0510 0.0503 0.0498 0.0495 0.0492 0.0490 

[TRAIN] Epoch[4](254/375); Loss: 0.038745; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.0808 0.0584 0.0478 0.0416 0.0384 0.0364 0.0348 0.0335 0.0325 0.0319 0.0313 0.0310 0.0307 0.0305 0.0303 0.0302 

[TRAIN] Epoch[4](255/375); Loss: 0.038058; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0783 0.0559 0.0466 0.0410 0.0379 0.0357 0.0341 0.0330 0.0322 0.0316 0.0311 0.0307 0.0304 0.0302 0.0301 0.0300 

[TRAIN] Epoch[4](256/375); Loss: 0.066259; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1123 0.0921 0.0782 0.0716 0.0679 0.0651 0.0627 0.0605 0.0590 0.0578 0.0568 0.0561 0.0556 0.0552 0.0548 0.0546 

[TRAIN] Epoch[4](257/375); Loss: 0.047738; Backpropagation: 0.2887 sec; Batch: 2.0768 sec
0.0809 0.0644 0.0559 0.0508 0.0481 0.0464 0.0449 0.0435 0.0426 0.0420 0.0415 0.0411 0.0408 0.0405 0.0403 0.0402 

[TRAIN] Epoch[4](258/375); Loss: 0.047495; Backpropagation: 0.2885 sec; Batch: 2.0775 sec
0.0920 0.0656 0.0552 0.0501 0.0467 0.0447 0.0432 0.0421 0.0413 0.0408 0.0403 0.0400 0.0397 0.0395 0.0394 0.0393 

[TRAIN] Epoch[4](259/375); Loss: 0.045933; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.0918 0.0703 0.0588 0.0518 0.0475 0.0445 0.0419 0.0399 0.0384 0.0373 0.0366 0.0360 0.0355 0.0351 0.0349 0.0347 

[TRAIN] Epoch[4](260/375); Loss: 0.049892; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.1041 0.0758 0.0617 0.0561 0.0512 0.0481 0.0456 0.0436 0.0421 0.0407 0.0398 0.0389 0.0382 0.0377 0.0375 0.0372 

[TRAIN] Epoch[4](261/375); Loss: 0.070782; Backpropagation: 0.2887 sec; Batch: 2.0790 sec
0.1160 0.0982 0.0839 0.0766 0.0726 0.0696 0.0670 0.0649 0.0634 0.0622 0.0611 0.0603 0.0597 0.0593 0.0590 0.0587 

[TRAIN] Epoch[4](262/375); Loss: 0.046940; Backpropagation: 0.2887 sec; Batch: 2.0767 sec
0.0910 0.0707 0.0582 0.0513 0.0473 0.0447 0.0429 0.0412 0.0401 0.0392 0.0385 0.0379 0.0374 0.0371 0.0369 0.0367 

[TRAIN] Epoch[4](263/375); Loss: 0.051799; Backpropagation: 0.2884 sec; Batch: 2.0784 sec
0.0940 0.0756 0.0625 0.0567 0.0531 0.0503 0.0481 0.0464 0.0451 0.0441 0.0433 0.0427 0.0422 0.0418 0.0415 0.0413 

[TRAIN] Epoch[4](264/375); Loss: 0.049804; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.0964 0.0740 0.0604 0.0538 0.0503 0.0479 0.0457 0.0441 0.0428 0.0419 0.0411 0.0406 0.0401 0.0396 0.0392 0.0389 

[TRAIN] Epoch[4](265/375); Loss: 0.056144; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1165 0.0824 0.0691 0.0619 0.0572 0.0539 0.0512 0.0491 0.0475 0.0462 0.0452 0.0445 0.0440 0.0436 0.0432 0.0430 

[TRAIN] Epoch[4](266/375); Loss: 0.052954; Backpropagation: 0.2884 sec; Batch: 2.0772 sec
0.1106 0.0823 0.0665 0.0585 0.0537 0.0505 0.0477 0.0455 0.0440 0.0429 0.0419 0.0413 0.0409 0.0406 0.0403 0.0401 

[TRAIN] Epoch[4](267/375); Loss: 0.044675; Backpropagation: 0.2882 sec; Batch: 2.0777 sec
0.0820 0.0623 0.0537 0.0481 0.0452 0.0431 0.0414 0.0402 0.0393 0.0384 0.0378 0.0373 0.0369 0.0366 0.0363 0.0362 

[TRAIN] Epoch[4](268/375); Loss: 0.034272; Backpropagation: 0.2884 sec; Batch: 2.0767 sec
0.0813 0.0561 0.0451 0.0374 0.0339 0.0313 0.0296 0.0283 0.0273 0.0265 0.0260 0.0256 0.0253 0.0250 0.0249 0.0247 

[TRAIN] Epoch[4](269/375); Loss: 0.042413; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0910 0.0654 0.0552 0.0459 0.0417 0.0394 0.0375 0.0362 0.0351 0.0343 0.0337 0.0332 0.0328 0.0325 0.0323 0.0322 

[TRAIN] Epoch[4](270/375); Loss: 0.047806; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1040 0.0789 0.0625 0.0530 0.0478 0.0444 0.0420 0.0403 0.0390 0.0379 0.0370 0.0363 0.0359 0.0356 0.0353 0.0351 

[TRAIN] Epoch[4](271/375); Loss: 0.052650; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0948 0.0743 0.0629 0.0576 0.0541 0.0511 0.0490 0.0474 0.0462 0.0452 0.0444 0.0438 0.0434 0.0430 0.0427 0.0425 

[TRAIN] Epoch[4](272/375); Loss: 0.052428; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0959 0.0766 0.0643 0.0575 0.0540 0.0511 0.0487 0.0470 0.0455 0.0443 0.0435 0.0428 0.0423 0.0420 0.0417 0.0415 

[TRAIN] Epoch[4](273/375); Loss: 0.057901; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1228 0.0905 0.0712 0.0627 0.0576 0.0538 0.0513 0.0494 0.0480 0.0470 0.0463 0.0458 0.0454 0.0451 0.0448 0.0447 

[TRAIN] Epoch[4](274/375); Loss: 0.044343; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.0961 0.0685 0.0543 0.0473 0.0438 0.0411 0.0392 0.0379 0.0367 0.0360 0.0354 0.0351 0.0348 0.0345 0.0344 0.0343 

[TRAIN] Epoch[4](275/375); Loss: 0.057539; Backpropagation: 0.2886 sec; Batch: 2.0774 sec
0.1172 0.0915 0.0732 0.0618 0.0570 0.0537 0.0513 0.0495 0.0481 0.0471 0.0462 0.0456 0.0451 0.0447 0.0445 0.0442 

[TRAIN] Epoch[4](276/375); Loss: 0.044208; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0852 0.0678 0.0561 0.0488 0.0448 0.0422 0.0401 0.0385 0.0373 0.0365 0.0359 0.0354 0.0350 0.0347 0.0345 0.0343 

[TRAIN] Epoch[4](277/375); Loss: 0.062291; Backpropagation: 0.2888 sec; Batch: 2.0741 sec
0.1366 0.1007 0.0815 0.0701 0.0644 0.0601 0.0563 0.0530 0.0507 0.0490 0.0476 0.0466 0.0457 0.0452 0.0448 0.0445 

[TRAIN] Epoch[4](278/375); Loss: 0.053336; Backpropagation: 0.2885 sec; Batch: 2.0764 sec
0.1127 0.0830 0.0672 0.0581 0.0531 0.0497 0.0474 0.0456 0.0443 0.0433 0.0426 0.0420 0.0416 0.0412 0.0410 0.0408 

[TRAIN] Epoch[4](279/375); Loss: 0.050561; Backpropagation: 0.2896 sec; Batch: 2.0739 sec
0.1168 0.0843 0.0667 0.0561 0.0510 0.0470 0.0443 0.0422 0.0406 0.0391 0.0381 0.0375 0.0369 0.0364 0.0361 0.0358 

[TRAIN] Epoch[4](280/375); Loss: 0.043428; Backpropagation: 0.2883 sec; Batch: 2.0786 sec
0.0927 0.0686 0.0551 0.0473 0.0436 0.0408 0.0389 0.0375 0.0362 0.0352 0.0344 0.0337 0.0332 0.0328 0.0325 0.0324 

[TRAIN] Epoch[4](281/375); Loss: 0.044930; Backpropagation: 0.2886 sec; Batch: 2.0764 sec
0.0941 0.0711 0.0568 0.0488 0.0449 0.0421 0.0399 0.0384 0.0373 0.0364 0.0358 0.0353 0.0349 0.0346 0.0343 0.0342 

[TRAIN] Epoch[4](282/375); Loss: 0.036294; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0776 0.0547 0.0454 0.0399 0.0369 0.0346 0.0327 0.0313 0.0302 0.0294 0.0288 0.0284 0.0281 0.0278 0.0276 0.0274 

[TRAIN] Epoch[4](283/375); Loss: 0.049535; Backpropagation: 0.2881 sec; Batch: 2.0732 sec
0.0848 0.0710 0.0599 0.0546 0.0513 0.0487 0.0466 0.0449 0.0435 0.0424 0.0417 0.0412 0.0408 0.0406 0.0403 0.0401 

[TRAIN] Epoch[4](284/375); Loss: 0.042820; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.0821 0.0579 0.0495 0.0450 0.0427 0.0411 0.0396 0.0385 0.0376 0.0369 0.0364 0.0361 0.0358 0.0355 0.0353 0.0352 

[TRAIN] Epoch[4](285/375); Loss: 0.036357; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0866 0.0599 0.0460 0.0390 0.0352 0.0331 0.0313 0.0299 0.0290 0.0283 0.0279 0.0276 0.0272 0.0270 0.0268 0.0266 

[TRAIN] Epoch[4](286/375); Loss: 0.033875; Backpropagation: 0.2883 sec; Batch: 2.0895 sec
0.0814 0.0555 0.0431 0.0359 0.0326 0.0303 0.0290 0.0279 0.0271 0.0265 0.0260 0.0257 0.0255 0.0253 0.0251 0.0250 

[TRAIN] Epoch[4](287/375); Loss: 0.053537; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1025 0.0791 0.0633 0.0572 0.0537 0.0511 0.0489 0.0472 0.0461 0.0452 0.0446 0.0442 0.0438 0.0435 0.0432 0.0430 

[TRAIN] Epoch[4](288/375); Loss: 0.036292; Backpropagation: 0.2887 sec; Batch: 2.1131 sec
0.0746 0.0566 0.0440 0.0391 0.0363 0.0343 0.0329 0.0316 0.0307 0.0299 0.0293 0.0288 0.0285 0.0282 0.0280 0.0279 

[TRAIN] Epoch[4](289/375); Loss: 0.050466; Backpropagation: 0.2887 sec; Batch: 2.0738 sec
0.1085 0.0783 0.0632 0.0568 0.0518 0.0481 0.0454 0.0434 0.0418 0.0405 0.0394 0.0388 0.0383 0.0380 0.0377 0.0374 

[TRAIN] Epoch[4](290/375); Loss: 0.031671; Backpropagation: 0.2886 sec; Batch: 2.1130 sec
0.0783 0.0503 0.0391 0.0336 0.0309 0.0291 0.0276 0.0264 0.0255 0.0248 0.0243 0.0239 0.0236 0.0233 0.0232 0.0230 

[TRAIN] Epoch[4](291/375); Loss: 0.053139; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.1072 0.0816 0.0652 0.0578 0.0545 0.0509 0.0483 0.0465 0.0451 0.0438 0.0429 0.0421 0.0416 0.0413 0.0410 0.0407 

[TRAIN] Epoch[4](292/375); Loss: 0.059664; Backpropagation: 0.2886 sec; Batch: 2.0751 sec
0.0970 0.0819 0.0726 0.0657 0.0613 0.0581 0.0558 0.0542 0.0532 0.0522 0.0514 0.0509 0.0504 0.0502 0.0500 0.0498 

[TRAIN] Epoch[4](293/375); Loss: 0.058595; Backpropagation: 0.2885 sec; Batch: 2.0731 sec
0.1161 0.0869 0.0728 0.0652 0.0604 0.0568 0.0540 0.0518 0.0499 0.0484 0.0473 0.0465 0.0459 0.0455 0.0452 0.0449 

[TRAIN] Epoch[4](294/375); Loss: 0.031535; Backpropagation: 0.2885 sec; Batch: 2.0772 sec
0.0825 0.0532 0.0411 0.0348 0.0313 0.0287 0.0267 0.0253 0.0243 0.0236 0.0230 0.0225 0.0222 0.0219 0.0218 0.0216 

[TRAIN] Epoch[4](295/375); Loss: 0.054594; Backpropagation: 0.2884 sec; Batch: 2.0781 sec
0.0909 0.0715 0.0637 0.0588 0.0558 0.0536 0.0517 0.0503 0.0492 0.0484 0.0476 0.0471 0.0467 0.0463 0.0460 0.0458 

[TRAIN] Epoch[4](296/375); Loss: 0.047407; Backpropagation: 0.2883 sec; Batch: 2.0812 sec
0.0919 0.0709 0.0589 0.0518 0.0477 0.0451 0.0430 0.0414 0.0403 0.0395 0.0389 0.0384 0.0381 0.0377 0.0375 0.0374 

[TRAIN] Epoch[4](297/375); Loss: 0.055276; Backpropagation: 0.2886 sec; Batch: 2.0795 sec
0.1047 0.0831 0.0681 0.0610 0.0566 0.0529 0.0504 0.0485 0.0473 0.0464 0.0454 0.0448 0.0443 0.0439 0.0437 0.0435 

[TRAIN] Epoch[4](298/375); Loss: 0.052834; Backpropagation: 0.2889 sec; Batch: 2.0776 sec
0.1087 0.0805 0.0658 0.0572 0.0527 0.0497 0.0474 0.0456 0.0444 0.0434 0.0427 0.0422 0.0417 0.0414 0.0411 0.0410 

[TRAIN] Epoch[4](299/375); Loss: 0.040839; Backpropagation: 0.2883 sec; Batch: 2.1158 sec
0.0895 0.0642 0.0498 0.0433 0.0403 0.0380 0.0362 0.0349 0.0338 0.0331 0.0326 0.0321 0.0318 0.0315 0.0313 0.0312 

[TRAIN] Epoch[4](300/375); Loss: 0.047260; Backpropagation: 0.2887 sec; Batch: 2.0731 sec
0.0972 0.0681 0.0563 0.0502 0.0470 0.0445 0.0427 0.0415 0.0404 0.0396 0.0390 0.0385 0.0382 0.0379 0.0377 0.0375 

[TRAIN] Epoch[4](301/375); Loss: 0.051724; Backpropagation: 0.2885 sec; Batch: 2.0768 sec
0.0970 0.0747 0.0608 0.0550 0.0521 0.0497 0.0477 0.0463 0.0452 0.0442 0.0434 0.0429 0.0425 0.0422 0.0420 0.0418 

[TRAIN] Epoch[4](302/375); Loss: 0.031781; Backpropagation: 0.2884 sec; Batch: 2.1080 sec
0.0799 0.0539 0.0406 0.0346 0.0312 0.0285 0.0269 0.0257 0.0249 0.0243 0.0237 0.0234 0.0230 0.0228 0.0226 0.0225 

[TRAIN] Epoch[4](303/375); Loss: 0.058621; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.1227 0.0893 0.0733 0.0637 0.0591 0.0558 0.0529 0.0508 0.0492 0.0480 0.0471 0.0462 0.0455 0.0451 0.0448 0.0445 

[TRAIN] Epoch[4](304/375); Loss: 0.059471; Backpropagation: 0.2889 sec; Batch: 2.0772 sec
0.1066 0.0862 0.0734 0.0660 0.0607 0.0572 0.0546 0.0527 0.0514 0.0505 0.0496 0.0491 0.0487 0.0485 0.0482 0.0480 

[TRAIN] Epoch[4](305/375); Loss: 0.049213; Backpropagation: 0.2890 sec; Batch: 2.1150 sec
0.1061 0.0754 0.0624 0.0538 0.0492 0.0462 0.0440 0.0425 0.0411 0.0400 0.0391 0.0384 0.0379 0.0374 0.0371 0.0368 

[TRAIN] Epoch[4](306/375); Loss: 0.036282; Backpropagation: 0.2885 sec; Batch: 2.0765 sec
0.0670 0.0543 0.0434 0.0395 0.0368 0.0349 0.0335 0.0323 0.0313 0.0306 0.0301 0.0298 0.0295 0.0293 0.0291 0.0290 

[TRAIN] Epoch[4](307/375); Loss: 0.045978; Backpropagation: 0.2882 sec; Batch: 2.0775 sec
0.0911 0.0693 0.0572 0.0512 0.0472 0.0442 0.0420 0.0400 0.0387 0.0378 0.0371 0.0365 0.0362 0.0359 0.0357 0.0355 

[TRAIN] Epoch[4](308/375); Loss: 0.060919; Backpropagation: 0.2884 sec; Batch: 2.0812 sec
0.1217 0.0917 0.0748 0.0656 0.0613 0.0578 0.0553 0.0534 0.0518 0.0507 0.0498 0.0491 0.0485 0.0481 0.0477 0.0474 

[TRAIN] Epoch[4](309/375); Loss: 0.040639; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0915 0.0657 0.0539 0.0458 0.0415 0.0384 0.0361 0.0343 0.0329 0.0318 0.0309 0.0302 0.0298 0.0294 0.0291 0.0288 

[TRAIN] Epoch[4](310/375); Loss: 0.047592; Backpropagation: 0.2884 sec; Batch: 2.0848 sec
0.0986 0.0719 0.0577 0.0515 0.0480 0.0449 0.0428 0.0412 0.0400 0.0391 0.0384 0.0380 0.0376 0.0374 0.0372 0.0370 

[TRAIN] Epoch[4](311/375); Loss: 0.065644; Backpropagation: 0.2881 sec; Batch: 2.0751 sec
0.1331 0.1068 0.0826 0.0710 0.0650 0.0617 0.0589 0.0566 0.0548 0.0535 0.0524 0.0517 0.0512 0.0507 0.0503 0.0500 

[TRAIN] Epoch[4](312/375); Loss: 0.062283; Backpropagation: 0.2887 sec; Batch: 2.0780 sec
0.1163 0.0957 0.0757 0.0660 0.0621 0.0591 0.0570 0.0552 0.0537 0.0527 0.0518 0.0511 0.0505 0.0501 0.0498 0.0496 

[TRAIN] Epoch[4](313/375); Loss: 0.037360; Backpropagation: 0.2885 sec; Batch: 2.0764 sec
0.0838 0.0577 0.0454 0.0404 0.0373 0.0349 0.0332 0.0320 0.0309 0.0302 0.0295 0.0291 0.0287 0.0284 0.0282 0.0281 

[TRAIN] Epoch[4](314/375); Loss: 0.030952; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0934 0.0701 0.0493 0.0360 0.0290 0.0244 0.0222 0.0210 0.0201 0.0194 0.0190 0.0187 0.0184 0.0182 0.0180 0.0180 

[TRAIN] Epoch[4](315/375); Loss: 0.036009; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0889 0.0612 0.0457 0.0387 0.0349 0.0323 0.0306 0.0294 0.0284 0.0277 0.0271 0.0266 0.0264 0.0262 0.0260 0.0259 

[TRAIN] Epoch[4](316/375); Loss: 0.041498; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0944 0.0670 0.0523 0.0454 0.0413 0.0386 0.0366 0.0350 0.0338 0.0329 0.0322 0.0316 0.0312 0.0308 0.0305 0.0303 

[TRAIN] Epoch[4](317/375); Loss: 0.058025; Backpropagation: 0.2882 sec; Batch: 2.0758 sec
0.1214 0.1012 0.0808 0.0675 0.0592 0.0538 0.0507 0.0482 0.0464 0.0448 0.0438 0.0430 0.0425 0.0420 0.0417 0.0415 

[TRAIN] Epoch[4](318/375); Loss: 0.055090; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.1011 0.0793 0.0656 0.0593 0.0558 0.0532 0.0512 0.0495 0.0482 0.0472 0.0464 0.0456 0.0452 0.0449 0.0446 0.0444 

[TRAIN] Epoch[4](319/375); Loss: 0.041594; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0845 0.0656 0.0522 0.0463 0.0423 0.0399 0.0380 0.0364 0.0351 0.0340 0.0331 0.0325 0.0320 0.0315 0.0312 0.0309 

[TRAIN] Epoch[4](320/375); Loss: 0.052897; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1174 0.0787 0.0627 0.0558 0.0521 0.0496 0.0476 0.0457 0.0444 0.0433 0.0425 0.0420 0.0416 0.0412 0.0410 0.0408 

[TRAIN] Epoch[4](321/375); Loss: 0.036981; Backpropagation: 0.2884 sec; Batch: 2.1071 sec
0.0737 0.0555 0.0454 0.0405 0.0378 0.0356 0.0337 0.0324 0.0314 0.0306 0.0300 0.0296 0.0292 0.0289 0.0288 0.0286 

[TRAIN] Epoch[4](322/375); Loss: 0.039027; Backpropagation: 0.2883 sec; Batch: 2.0763 sec
0.0890 0.0639 0.0498 0.0428 0.0390 0.0364 0.0344 0.0329 0.0316 0.0306 0.0299 0.0294 0.0290 0.0287 0.0285 0.0284 

[TRAIN] Epoch[4](323/375); Loss: 0.064053; Backpropagation: 0.2888 sec; Batch: 2.0749 sec
0.1224 0.0949 0.0756 0.0676 0.0637 0.0608 0.0585 0.0569 0.0554 0.0545 0.0536 0.0529 0.0525 0.0520 0.0518 0.0516 

[TRAIN] Epoch[4](324/375); Loss: 0.035957; Backpropagation: 0.2885 sec; Batch: 2.0855 sec
0.0824 0.0550 0.0434 0.0379 0.0354 0.0332 0.0316 0.0305 0.0296 0.0290 0.0285 0.0281 0.0279 0.0278 0.0276 0.0276 

[TRAIN] Epoch[4](325/375); Loss: 0.029926; Backpropagation: 0.2883 sec; Batch: 2.1138 sec
0.0810 0.0522 0.0389 0.0316 0.0286 0.0267 0.0251 0.0239 0.0228 0.0222 0.0218 0.0213 0.0210 0.0208 0.0206 0.0205 

[TRAIN] Epoch[4](326/375); Loss: 0.045935; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0881 0.0684 0.0558 0.0501 0.0466 0.0438 0.0419 0.0404 0.0394 0.0386 0.0380 0.0374 0.0370 0.0367 0.0364 0.0362 

[TRAIN] Epoch[4](327/375); Loss: 0.032776; Backpropagation: 0.2884 sec; Batch: 2.0767 sec
0.0731 0.0548 0.0425 0.0355 0.0321 0.0299 0.0285 0.0274 0.0266 0.0259 0.0254 0.0250 0.0247 0.0245 0.0243 0.0242 

[TRAIN] Epoch[4](328/375); Loss: 0.047458; Backpropagation: 0.2888 sec; Batch: 2.0747 sec
0.1035 0.0781 0.0605 0.0518 0.0467 0.0435 0.0416 0.0399 0.0389 0.0380 0.0373 0.0366 0.0362 0.0358 0.0356 0.0354 

[TRAIN] Epoch[4](329/375); Loss: 0.047747; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.1004 0.0729 0.0579 0.0513 0.0481 0.0449 0.0430 0.0413 0.0401 0.0390 0.0384 0.0379 0.0376 0.0373 0.0371 0.0370 

[TRAIN] Epoch[4](330/375); Loss: 0.044508; Backpropagation: 0.2884 sec; Batch: 2.0767 sec
0.0933 0.0698 0.0570 0.0494 0.0453 0.0423 0.0400 0.0383 0.0369 0.0358 0.0351 0.0345 0.0340 0.0337 0.0335 0.0333 

[TRAIN] Epoch[4](331/375); Loss: 0.047251; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.0839 0.0666 0.0570 0.0513 0.0479 0.0457 0.0438 0.0424 0.0414 0.0407 0.0402 0.0397 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[4](332/375); Loss: 0.041809; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0891 0.0628 0.0509 0.0453 0.0421 0.0397 0.0378 0.0362 0.0351 0.0342 0.0335 0.0330 0.0326 0.0324 0.0322 0.0321 

[TRAIN] Epoch[4](333/375); Loss: 0.038142; Backpropagation: 0.2886 sec; Batch: 2.0838 sec
0.0834 0.0591 0.0467 0.0417 0.0381 0.0355 0.0339 0.0326 0.0316 0.0309 0.0303 0.0298 0.0295 0.0292 0.0290 0.0289 

[TRAIN] Epoch[4](334/375); Loss: 0.041290; Backpropagation: 0.2883 sec; Batch: 2.0777 sec
0.0798 0.0628 0.0532 0.0450 0.0415 0.0392 0.0375 0.0361 0.0350 0.0342 0.0336 0.0331 0.0328 0.0325 0.0323 0.0322 

[TRAIN] Epoch[4](335/375); Loss: 0.057905; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1285 0.1001 0.0776 0.0658 0.0580 0.0534 0.0502 0.0479 0.0463 0.0449 0.0438 0.0429 0.0423 0.0418 0.0415 0.0412 

[TRAIN] Epoch[4](336/375); Loss: 0.047664; Backpropagation: 0.2881 sec; Batch: 2.0772 sec
0.1093 0.0864 0.0628 0.0510 0.0457 0.0424 0.0404 0.0389 0.0378 0.0369 0.0362 0.0357 0.0352 0.0349 0.0346 0.0344 

[TRAIN] Epoch[4](337/375); Loss: 0.042736; Backpropagation: 0.2882 sec; Batch: 2.0749 sec
0.0820 0.0656 0.0550 0.0472 0.0428 0.0403 0.0386 0.0372 0.0362 0.0355 0.0349 0.0344 0.0340 0.0337 0.0335 0.0333 

[TRAIN] Epoch[4](338/375); Loss: 0.047957; Backpropagation: 0.2886 sec; Batch: 2.0766 sec
0.1126 0.0753 0.0607 0.0523 0.0474 0.0440 0.0415 0.0398 0.0386 0.0377 0.0370 0.0366 0.0362 0.0360 0.0359 0.0358 

[TRAIN] Epoch[4](339/375); Loss: 0.040170; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0836 0.0642 0.0498 0.0430 0.0397 0.0375 0.0359 0.0346 0.0336 0.0328 0.0322 0.0317 0.0314 0.0311 0.0309 0.0307 

[TRAIN] Epoch[4](340/375); Loss: 0.039101; Backpropagation: 0.2890 sec; Batch: 2.0779 sec
0.0811 0.0633 0.0494 0.0430 0.0391 0.0363 0.0344 0.0331 0.0323 0.0316 0.0311 0.0307 0.0303 0.0301 0.0300 0.0299 

[TRAIN] Epoch[4](341/375); Loss: 0.042934; Backpropagation: 0.2882 sec; Batch: 2.0763 sec
0.1041 0.0711 0.0553 0.0463 0.0415 0.0386 0.0366 0.0352 0.0342 0.0333 0.0327 0.0322 0.0318 0.0315 0.0313 0.0312 

[TRAIN] Epoch[4](342/375); Loss: 0.045253; Backpropagation: 0.2884 sec; Batch: 2.0751 sec
0.0831 0.0656 0.0538 0.0482 0.0452 0.0430 0.0415 0.0404 0.0395 0.0387 0.0382 0.0378 0.0375 0.0373 0.0371 0.0369 

[TRAIN] Epoch[4](343/375); Loss: 0.063576; Backpropagation: 0.2883 sec; Batch: 2.0769 sec
0.1129 0.0866 0.0751 0.0692 0.0649 0.0619 0.0596 0.0577 0.0562 0.0550 0.0543 0.0535 0.0530 0.0527 0.0524 0.0522 

[TRAIN] Epoch[4](344/375); Loss: 0.029273; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0582 0.0434 0.0366 0.0321 0.0294 0.0276 0.0264 0.0255 0.0248 0.0243 0.0239 0.0236 0.0234 0.0232 0.0231 0.0229 

[TRAIN] Epoch[4](345/375); Loss: 0.041849; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0856 0.0640 0.0510 0.0449 0.0416 0.0391 0.0377 0.0363 0.0354 0.0346 0.0340 0.0336 0.0332 0.0330 0.0328 0.0326 

[TRAIN] Epoch[4](346/375); Loss: 0.041104; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.0773 0.0664 0.0518 0.0450 0.0414 0.0388 0.0371 0.0358 0.0348 0.0341 0.0335 0.0330 0.0325 0.0322 0.0320 0.0318 

[TRAIN] Epoch[4](347/375); Loss: 0.038514; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.1039 0.0753 0.0512 0.0416 0.0363 0.0333 0.0314 0.0298 0.0286 0.0278 0.0272 0.0266 0.0262 0.0259 0.0257 0.0255 

[TRAIN] Epoch[4](348/375); Loss: 0.050438; Backpropagation: 0.2887 sec; Batch: 2.0791 sec
0.1049 0.0848 0.0668 0.0565 0.0507 0.0474 0.0447 0.0428 0.0413 0.0401 0.0393 0.0385 0.0378 0.0374 0.0371 0.0368 

[TRAIN] Epoch[4](349/375); Loss: 0.030909; Backpropagation: 0.2884 sec; Batch: 2.0770 sec
0.0842 0.0607 0.0417 0.0334 0.0293 0.0266 0.0248 0.0236 0.0228 0.0222 0.0216 0.0212 0.0209 0.0207 0.0205 0.0203 

[TRAIN] Epoch[4](350/375); Loss: 0.055816; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.1037 0.0828 0.0696 0.0612 0.0556 0.0526 0.0506 0.0492 0.0481 0.0471 0.0465 0.0459 0.0455 0.0452 0.0449 0.0447 

[TRAIN] Epoch[4](351/375); Loss: 0.048260; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.0863 0.0691 0.0587 0.0526 0.0485 0.0458 0.0441 0.0430 0.0422 0.0415 0.0410 0.0405 0.0401 0.0398 0.0396 0.0394 

[TRAIN] Epoch[4](352/375); Loss: 0.060768; Backpropagation: 0.2886 sec; Batch: 2.0770 sec
0.1017 0.0857 0.0738 0.0660 0.0626 0.0596 0.0572 0.0552 0.0538 0.0526 0.0519 0.0512 0.0507 0.0504 0.0500 0.0498 

[TRAIN] Epoch[4](353/375); Loss: 0.047616; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0954 0.0782 0.0634 0.0546 0.0488 0.0451 0.0422 0.0403 0.0389 0.0379 0.0372 0.0366 0.0363 0.0359 0.0356 0.0355 

[TRAIN] Epoch[4](354/375); Loss: 0.040782; Backpropagation: 0.2887 sec; Batch: 2.0785 sec
0.0866 0.0695 0.0514 0.0440 0.0401 0.0377 0.0357 0.0344 0.0335 0.0327 0.0320 0.0315 0.0312 0.0309 0.0307 0.0305 

[TRAIN] Epoch[4](355/375); Loss: 0.030031; Backpropagation: 0.2887 sec; Batch: 2.0790 sec
0.0670 0.0515 0.0390 0.0335 0.0301 0.0280 0.0262 0.0250 0.0240 0.0233 0.0228 0.0225 0.0222 0.0219 0.0218 0.0216 

[TRAIN] Epoch[4](356/375); Loss: 0.047477; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0839 0.0686 0.0587 0.0524 0.0491 0.0466 0.0445 0.0426 0.0414 0.0404 0.0396 0.0391 0.0386 0.0383 0.0380 0.0379 

[TRAIN] Epoch[4](357/375); Loss: 0.060727; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.1278 0.1023 0.0772 0.0659 0.0600 0.0563 0.0536 0.0515 0.0500 0.0488 0.0478 0.0470 0.0464 0.0460 0.0456 0.0455 

[TRAIN] Epoch[4](358/375); Loss: 0.035130; Backpropagation: 0.2882 sec; Batch: 2.0775 sec
0.0902 0.0621 0.0454 0.0378 0.0338 0.0312 0.0296 0.0283 0.0272 0.0265 0.0259 0.0254 0.0250 0.0248 0.0246 0.0244 

[TRAIN] Epoch[4](359/375); Loss: 0.044873; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0983 0.0705 0.0572 0.0504 0.0461 0.0427 0.0402 0.0383 0.0367 0.0356 0.0348 0.0342 0.0337 0.0334 0.0331 0.0329 

[TRAIN] Epoch[4](360/375); Loss: 0.050286; Backpropagation: 0.2881 sec; Batch: 2.1122 sec
0.0927 0.0709 0.0605 0.0546 0.0510 0.0485 0.0465 0.0450 0.0439 0.0429 0.0422 0.0418 0.0415 0.0411 0.0408 0.0406 

[TRAIN] Epoch[4](361/375); Loss: 0.062274; Backpropagation: 0.2886 sec; Batch: 2.0739 sec
0.1144 0.0948 0.0794 0.0703 0.0644 0.0604 0.0574 0.0550 0.0532 0.0518 0.0509 0.0500 0.0493 0.0488 0.0484 0.0480 

[TRAIN] Epoch[4](362/375); Loss: 0.061203; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.1003 0.0858 0.0739 0.0677 0.0634 0.0601 0.0576 0.0558 0.0544 0.0534 0.0525 0.0518 0.0513 0.0508 0.0504 0.0502 

[TRAIN] Epoch[4](363/375); Loss: 0.047579; Backpropagation: 0.2885 sec; Batch: 2.0760 sec
0.0986 0.0805 0.0617 0.0527 0.0474 0.0440 0.0414 0.0400 0.0388 0.0380 0.0373 0.0368 0.0364 0.0361 0.0359 0.0357 

[TRAIN] Epoch[4](364/375); Loss: 0.050180; Backpropagation: 0.2890 sec; Batch: 2.0743 sec
0.0998 0.0766 0.0631 0.0553 0.0509 0.0478 0.0455 0.0436 0.0423 0.0413 0.0405 0.0399 0.0394 0.0391 0.0389 0.0387 

[TRAIN] Epoch[4](365/375); Loss: 0.038262; Backpropagation: 0.2884 sec; Batch: 2.0763 sec
0.0870 0.0635 0.0498 0.0422 0.0379 0.0351 0.0331 0.0317 0.0306 0.0299 0.0293 0.0289 0.0286 0.0284 0.0282 0.0281 

[TRAIN] Epoch[4](366/375); Loss: 0.048821; Backpropagation: 0.2881 sec; Batch: 2.0746 sec
0.0985 0.0762 0.0626 0.0538 0.0488 0.0457 0.0435 0.0419 0.0408 0.0398 0.0391 0.0387 0.0383 0.0380 0.0378 0.0376 

[TRAIN] Epoch[4](367/375); Loss: 0.046874; Backpropagation: 0.2883 sec; Batch: 2.0768 sec
0.1003 0.0702 0.0576 0.0513 0.0476 0.0445 0.0421 0.0404 0.0392 0.0381 0.0374 0.0369 0.0365 0.0362 0.0359 0.0358 

[TRAIN] Epoch[4](368/375); Loss: 0.057435; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0933 0.0787 0.0700 0.0632 0.0591 0.0562 0.0540 0.0522 0.0511 0.0502 0.0496 0.0490 0.0486 0.0483 0.0480 0.0478 

[TRAIN] Epoch[4](369/375); Loss: 0.056895; Backpropagation: 0.2884 sec; Batch: 2.0834 sec
0.1027 0.0879 0.0708 0.0640 0.0586 0.0550 0.0522 0.0503 0.0488 0.0477 0.0469 0.0461 0.0454 0.0449 0.0446 0.0444 

[TRAIN] Epoch[4](370/375); Loss: 0.046377; Backpropagation: 0.2885 sec; Batch: 2.0778 sec
0.1081 0.0774 0.0589 0.0529 0.0470 0.0428 0.0402 0.0382 0.0369 0.0360 0.0351 0.0344 0.0340 0.0336 0.0334 0.0332 

[TRAIN] Epoch[4](371/375); Loss: 0.037739; Backpropagation: 0.2880 sec; Batch: 2.0757 sec
0.0830 0.0613 0.0496 0.0427 0.0379 0.0346 0.0328 0.0314 0.0304 0.0296 0.0291 0.0287 0.0284 0.0282 0.0281 0.0280 

[TRAIN] Epoch[4](372/375); Loss: 0.049909; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0843 0.0709 0.0610 0.0544 0.0512 0.0484 0.0466 0.0450 0.0441 0.0432 0.0425 0.0419 0.0415 0.0413 0.0411 0.0410 

[TRAIN] Epoch[4](373/375); Loss: 0.043986; Backpropagation: 0.2888 sec; Batch: 2.0775 sec
0.0908 0.0685 0.0535 0.0470 0.0433 0.0411 0.0396 0.0382 0.0370 0.0363 0.0357 0.0352 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[4](374/375); Loss: 0.045587; Backpropagation: 0.2880 sec; Batch: 2.0735 sec
0.0906 0.0679 0.0567 0.0495 0.0455 0.0431 0.0410 0.0398 0.0387 0.0379 0.0372 0.0368 0.0365 0.0362 0.0360 0.0359 

[TRAIN] Epoch[4](375/375); Loss: 0.033807; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.0707 0.0486 0.0405 0.0364 0.0338 0.0319 0.0304 0.0294 0.0286 0.0281 0.0276 0.0273 0.0271 0.0269 0.0268 0.0267 

[TRAIN] Epoch[5](1/375); Loss: 0.041160; Backpropagation: 0.2997 sec; Batch: 2.1395 sec
0.0846 0.0600 0.0497 0.0439 0.0408 0.0387 0.0372 0.0358 0.0350 0.0344 0.0339 0.0335 0.0331 0.0328 0.0327 0.0325 

[TRAIN] Epoch[5](2/375); Loss: 0.047747; Backpropagation: 0.2886 sec; Batch: 2.0932 sec
0.1019 0.0811 0.0631 0.0525 0.0479 0.0442 0.0417 0.0400 0.0387 0.0378 0.0369 0.0364 0.0359 0.0355 0.0352 0.0351 

[TRAIN] Epoch[5](3/375); Loss: 0.031381; Backpropagation: 0.2884 sec; Batch: 2.0873 sec
0.0627 0.0510 0.0396 0.0343 0.0316 0.0295 0.0279 0.0269 0.0262 0.0256 0.0252 0.0247 0.0244 0.0243 0.0241 0.0240 

[TRAIN] Epoch[5](4/375); Loss: 0.033930; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0927 0.0640 0.0451 0.0359 0.0320 0.0295 0.0276 0.0263 0.0253 0.0246 0.0241 0.0237 0.0233 0.0231 0.0229 0.0228 

[TRAIN] Epoch[5](5/375); Loss: 0.032301; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0834 0.0603 0.0420 0.0344 0.0303 0.0281 0.0266 0.0254 0.0246 0.0240 0.0236 0.0233 0.0230 0.0227 0.0226 0.0225 

[TRAIN] Epoch[5](6/375); Loss: 0.043188; Backpropagation: 0.2883 sec; Batch: 2.0727 sec
0.0861 0.0652 0.0563 0.0484 0.0444 0.0415 0.0393 0.0375 0.0362 0.0352 0.0345 0.0339 0.0335 0.0332 0.0330 0.0328 

[TRAIN] Epoch[5](7/375); Loss: 0.045144; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.0918 0.0735 0.0558 0.0495 0.0457 0.0429 0.0404 0.0387 0.0376 0.0366 0.0360 0.0354 0.0350 0.0347 0.0344 0.0342 

[TRAIN] Epoch[5](8/375); Loss: 0.046045; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0822 0.0662 0.0572 0.0502 0.0468 0.0446 0.0428 0.0414 0.0402 0.0392 0.0385 0.0380 0.0377 0.0374 0.0372 0.0371 

[TRAIN] Epoch[5](9/375); Loss: 0.028694; Backpropagation: 0.2888 sec; Batch: 2.0760 sec
0.0839 0.0529 0.0359 0.0296 0.0267 0.0249 0.0235 0.0223 0.0214 0.0208 0.0203 0.0199 0.0196 0.0193 0.0191 0.0190 

[TRAIN] Epoch[5](10/375); Loss: 0.064617; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1128 0.0918 0.0776 0.0707 0.0661 0.0628 0.0602 0.0584 0.0568 0.0557 0.0548 0.0541 0.0535 0.0531 0.0528 0.0527 

[TRAIN] Epoch[5](11/375); Loss: 0.035039; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0713 0.0529 0.0437 0.0391 0.0354 0.0331 0.0314 0.0303 0.0293 0.0287 0.0281 0.0278 0.0276 0.0274 0.0273 0.0273 

[TRAIN] Epoch[5](12/375); Loss: 0.073511; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.1286 0.1069 0.0915 0.0820 0.0764 0.0722 0.0687 0.0660 0.0641 0.0626 0.0613 0.0604 0.0597 0.0591 0.0586 0.0582 

[TRAIN] Epoch[5](13/375); Loss: 0.033437; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.0619 0.0538 0.0441 0.0373 0.0335 0.0311 0.0298 0.0289 0.0281 0.0276 0.0271 0.0268 0.0265 0.0263 0.0262 0.0260 

[TRAIN] Epoch[5](14/375); Loss: 0.045616; Backpropagation: 0.2889 sec; Batch: 2.0738 sec
0.1090 0.0792 0.0595 0.0499 0.0446 0.0415 0.0392 0.0374 0.0361 0.0350 0.0342 0.0335 0.0331 0.0327 0.0325 0.0323 

[TRAIN] Epoch[5](15/375); Loss: 0.048961; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0903 0.0737 0.0601 0.0546 0.0507 0.0475 0.0452 0.0434 0.0421 0.0411 0.0402 0.0396 0.0392 0.0388 0.0386 0.0384 

[TRAIN] Epoch[5](16/375); Loss: 0.038095; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0838 0.0612 0.0485 0.0415 0.0374 0.0353 0.0336 0.0324 0.0315 0.0305 0.0299 0.0294 0.0291 0.0287 0.0285 0.0283 

[TRAIN] Epoch[5](17/375); Loss: 0.040397; Backpropagation: 0.2888 sec; Batch: 2.0737 sec
0.0875 0.0665 0.0491 0.0450 0.0400 0.0372 0.0355 0.0341 0.0331 0.0324 0.0318 0.0313 0.0310 0.0308 0.0306 0.0305 

[TRAIN] Epoch[5](18/375); Loss: 0.041300; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0860 0.0650 0.0518 0.0448 0.0411 0.0386 0.0367 0.0355 0.0345 0.0336 0.0330 0.0326 0.0322 0.0319 0.0318 0.0316 

[TRAIN] Epoch[5](19/375); Loss: 0.063010; Backpropagation: 0.2890 sec; Batch: 2.0747 sec
0.1120 0.0939 0.0764 0.0686 0.0643 0.0609 0.0585 0.0566 0.0550 0.0538 0.0529 0.0521 0.0514 0.0510 0.0506 0.0503 

[TRAIN] Epoch[5](20/375); Loss: 0.046572; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.0991 0.0782 0.0602 0.0511 0.0468 0.0436 0.0413 0.0396 0.0382 0.0370 0.0361 0.0355 0.0351 0.0347 0.0345 0.0343 

[TRAIN] Epoch[5](21/375); Loss: 0.064240; Backpropagation: 0.2888 sec; Batch: 2.0736 sec
0.1099 0.0917 0.0792 0.0712 0.0664 0.0629 0.0601 0.0579 0.0563 0.0551 0.0542 0.0535 0.0530 0.0526 0.0522 0.0518 

[TRAIN] Epoch[5](22/375); Loss: 0.061659; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1515 0.1180 0.0916 0.0735 0.0622 0.0541 0.0504 0.0476 0.0459 0.0441 0.0429 0.0421 0.0414 0.0408 0.0404 0.0401 

[TRAIN] Epoch[5](23/375); Loss: 0.036838; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0918 0.0618 0.0457 0.0395 0.0358 0.0333 0.0315 0.0301 0.0290 0.0283 0.0278 0.0274 0.0271 0.0269 0.0267 0.0266 

[TRAIN] Epoch[5](24/375); Loss: 0.043139; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0849 0.0713 0.0560 0.0486 0.0440 0.0407 0.0386 0.0370 0.0358 0.0349 0.0341 0.0335 0.0331 0.0328 0.0325 0.0323 

[TRAIN] Epoch[5](25/375); Loss: 0.042094; Backpropagation: 0.2889 sec; Batch: 2.0746 sec
0.0787 0.0627 0.0524 0.0457 0.0425 0.0399 0.0380 0.0368 0.0360 0.0353 0.0348 0.0344 0.0342 0.0341 0.0340 0.0340 

[TRAIN] Epoch[5](26/375); Loss: 0.044341; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.0909 0.0675 0.0564 0.0496 0.0459 0.0429 0.0405 0.0386 0.0370 0.0359 0.0351 0.0345 0.0341 0.0337 0.0335 0.0333 

[TRAIN] Epoch[5](27/375); Loss: 0.057622; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1195 0.0853 0.0699 0.0620 0.0573 0.0542 0.0519 0.0501 0.0487 0.0477 0.0469 0.0463 0.0459 0.0456 0.0453 0.0451 

[TRAIN] Epoch[5](28/375); Loss: 0.046791; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.0994 0.0686 0.0561 0.0498 0.0464 0.0439 0.0419 0.0405 0.0394 0.0386 0.0381 0.0377 0.0374 0.0371 0.0369 0.0367 

[TRAIN] Epoch[5](29/375); Loss: 0.065189; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1258 0.0978 0.0802 0.0712 0.0661 0.0625 0.0598 0.0576 0.0561 0.0546 0.0534 0.0527 0.0520 0.0514 0.0511 0.0507 

[TRAIN] Epoch[5](30/375); Loss: 0.044663; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0821 0.0643 0.0553 0.0492 0.0452 0.0429 0.0412 0.0399 0.0387 0.0378 0.0372 0.0367 0.0364 0.0361 0.0358 0.0357 

[TRAIN] Epoch[5](31/375); Loss: 0.041387; Backpropagation: 0.2890 sec; Batch: 2.0738 sec
0.0929 0.0706 0.0526 0.0439 0.0398 0.0374 0.0357 0.0345 0.0335 0.0327 0.0322 0.0317 0.0314 0.0312 0.0310 0.0309 

[TRAIN] Epoch[5](32/375); Loss: 0.042618; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0857 0.0692 0.0570 0.0484 0.0442 0.0411 0.0383 0.0365 0.0352 0.0340 0.0332 0.0325 0.0320 0.0317 0.0315 0.0313 

[TRAIN] Epoch[5](33/375); Loss: 0.048302; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0938 0.0716 0.0599 0.0534 0.0491 0.0465 0.0443 0.0425 0.0413 0.0403 0.0394 0.0389 0.0385 0.0381 0.0377 0.0374 

[TRAIN] Epoch[5](34/375); Loss: 0.044685; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0830 0.0669 0.0547 0.0483 0.0452 0.0428 0.0411 0.0396 0.0386 0.0377 0.0371 0.0366 0.0362 0.0360 0.0358 0.0356 

[TRAIN] Epoch[5](35/375); Loss: 0.043875; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0963 0.0661 0.0522 0.0457 0.0424 0.0402 0.0388 0.0378 0.0368 0.0362 0.0356 0.0353 0.0349 0.0347 0.0346 0.0344 

[TRAIN] Epoch[5](36/375); Loss: 0.044003; Backpropagation: 0.2884 sec; Batch: 2.0734 sec
0.0876 0.0682 0.0556 0.0484 0.0441 0.0414 0.0393 0.0377 0.0366 0.0360 0.0355 0.0351 0.0349 0.0347 0.0345 0.0344 

[TRAIN] Epoch[5](37/375); Loss: 0.048491; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0968 0.0714 0.0604 0.0523 0.0487 0.0461 0.0441 0.0425 0.0413 0.0403 0.0396 0.0391 0.0387 0.0384 0.0381 0.0380 

[TRAIN] Epoch[5](38/375); Loss: 0.043971; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0978 0.0680 0.0550 0.0484 0.0444 0.0416 0.0393 0.0374 0.0361 0.0352 0.0344 0.0338 0.0335 0.0331 0.0329 0.0327 

[TRAIN] Epoch[5](39/375); Loss: 0.066993; Backpropagation: 0.2889 sec; Batch: 2.0742 sec
0.1410 0.1103 0.0860 0.0730 0.0662 0.0619 0.0589 0.0567 0.0551 0.0538 0.0529 0.0522 0.0516 0.0511 0.0507 0.0505 

[TRAIN] Epoch[5](40/375); Loss: 0.034761; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0914 0.0532 0.0405 0.0356 0.0328 0.0309 0.0295 0.0286 0.0279 0.0273 0.0270 0.0267 0.0265 0.0262 0.0261 0.0260 

[TRAIN] Epoch[5](41/375); Loss: 0.039668; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0916 0.0640 0.0527 0.0453 0.0410 0.0375 0.0348 0.0331 0.0317 0.0306 0.0299 0.0292 0.0288 0.0284 0.0281 0.0280 

[TRAIN] Epoch[5](42/375); Loss: 0.049914; Backpropagation: 0.2889 sec; Batch: 2.0747 sec
0.0857 0.0735 0.0619 0.0559 0.0517 0.0489 0.0468 0.0450 0.0436 0.0426 0.0417 0.0410 0.0405 0.0402 0.0399 0.0396 

[TRAIN] Epoch[5](43/375); Loss: 0.050124; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1052 0.0763 0.0627 0.0551 0.0500 0.0469 0.0446 0.0430 0.0418 0.0409 0.0402 0.0396 0.0393 0.0390 0.0388 0.0386 

[TRAIN] Epoch[5](44/375); Loss: 0.041279; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1025 0.0736 0.0530 0.0439 0.0393 0.0367 0.0349 0.0334 0.0323 0.0314 0.0308 0.0303 0.0300 0.0297 0.0294 0.0292 

[TRAIN] Epoch[5](45/375); Loss: 0.026597; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0600 0.0415 0.0321 0.0282 0.0256 0.0241 0.0233 0.0225 0.0220 0.0216 0.0212 0.0210 0.0208 0.0206 0.0205 0.0205 

[TRAIN] Epoch[5](46/375); Loss: 0.056180; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.1050 0.0802 0.0679 0.0613 0.0571 0.0542 0.0518 0.0501 0.0488 0.0479 0.0469 0.0462 0.0458 0.0455 0.0452 0.0450 

[TRAIN] Epoch[5](47/375); Loss: 0.054974; Backpropagation: 0.2882 sec; Batch: 2.0728 sec
0.1144 0.0845 0.0694 0.0598 0.0546 0.0512 0.0486 0.0470 0.0458 0.0449 0.0442 0.0437 0.0433 0.0430 0.0427 0.0425 

[TRAIN] Epoch[5](48/375); Loss: 0.037929; Backpropagation: 0.2887 sec; Batch: 2.0743 sec
0.0836 0.0561 0.0464 0.0403 0.0369 0.0350 0.0336 0.0326 0.0318 0.0312 0.0306 0.0302 0.0299 0.0297 0.0295 0.0294 

[TRAIN] Epoch[5](49/375); Loss: 0.050344; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.0898 0.0719 0.0588 0.0539 0.0511 0.0488 0.0469 0.0454 0.0443 0.0434 0.0428 0.0423 0.0419 0.0417 0.0414 0.0412 

[TRAIN] Epoch[5](50/375); Loss: 0.064477; Backpropagation: 0.2887 sec; Batch: 2.0786 sec
0.1279 0.0934 0.0802 0.0721 0.0668 0.0624 0.0591 0.0565 0.0546 0.0534 0.0522 0.0515 0.0509 0.0505 0.0501 0.0499 

[TRAIN] Epoch[5](51/375); Loss: 0.036397; Backpropagation: 0.2893 sec; Batch: 2.0750 sec
0.0819 0.0508 0.0431 0.0383 0.0356 0.0337 0.0323 0.0313 0.0307 0.0302 0.0297 0.0293 0.0291 0.0289 0.0288 0.0287 

[TRAIN] Epoch[5](52/375); Loss: 0.049989; Backpropagation: 0.2944 sec; Batch: 2.0795 sec
0.1111 0.0824 0.0638 0.0553 0.0505 0.0469 0.0444 0.0423 0.0406 0.0395 0.0385 0.0378 0.0373 0.0368 0.0364 0.0362 

[TRAIN] Epoch[5](53/375); Loss: 0.043340; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0794 0.0607 0.0527 0.0471 0.0442 0.0418 0.0400 0.0389 0.0379 0.0371 0.0365 0.0360 0.0357 0.0354 0.0352 0.0350 

[TRAIN] Epoch[5](54/375); Loss: 0.055244; Backpropagation: 0.2886 sec; Batch: 2.0728 sec
0.1069 0.0840 0.0699 0.0627 0.0566 0.0527 0.0502 0.0481 0.0468 0.0455 0.0445 0.0439 0.0434 0.0431 0.0428 0.0427 

[TRAIN] Epoch[5](55/375); Loss: 0.047395; Backpropagation: 0.2887 sec; Batch: 2.0733 sec
0.0976 0.0731 0.0595 0.0522 0.0475 0.0443 0.0423 0.0408 0.0397 0.0387 0.0380 0.0376 0.0372 0.0369 0.0366 0.0363 

[TRAIN] Epoch[5](56/375); Loss: 0.045682; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.0935 0.0766 0.0608 0.0519 0.0464 0.0430 0.0405 0.0385 0.0373 0.0363 0.0355 0.0349 0.0344 0.0340 0.0338 0.0335 

[TRAIN] Epoch[5](57/375); Loss: 0.073092; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1282 0.1075 0.0905 0.0801 0.0749 0.0708 0.0679 0.0653 0.0634 0.0621 0.0612 0.0604 0.0599 0.0593 0.0591 0.0588 

[TRAIN] Epoch[5](58/375); Loss: 0.049446; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1090 0.0817 0.0631 0.0530 0.0484 0.0454 0.0432 0.0416 0.0404 0.0395 0.0387 0.0381 0.0377 0.0374 0.0372 0.0370 

[TRAIN] Epoch[5](59/375); Loss: 0.042048; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.0966 0.0726 0.0536 0.0455 0.0417 0.0386 0.0364 0.0349 0.0337 0.0328 0.0321 0.0315 0.0311 0.0308 0.0306 0.0304 

[TRAIN] Epoch[5](60/375); Loss: 0.057070; Backpropagation: 0.2883 sec; Batch: 2.0724 sec
0.1110 0.0830 0.0705 0.0625 0.0580 0.0548 0.0521 0.0503 0.0489 0.0477 0.0469 0.0463 0.0458 0.0454 0.0451 0.0448 

[TRAIN] Epoch[5](61/375); Loss: 0.056990; Backpropagation: 0.2884 sec; Batch: 2.0730 sec
0.1091 0.0849 0.0723 0.0641 0.0587 0.0553 0.0525 0.0503 0.0487 0.0472 0.0462 0.0454 0.0448 0.0444 0.0441 0.0439 

[TRAIN] Epoch[5](62/375); Loss: 0.045554; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.0963 0.0740 0.0561 0.0482 0.0446 0.0419 0.0400 0.0387 0.0379 0.0372 0.0365 0.0360 0.0357 0.0354 0.0352 0.0351 

[TRAIN] Epoch[5](63/375); Loss: 0.073672; Backpropagation: 0.2887 sec; Batch: 2.0738 sec
0.1459 0.1180 0.0923 0.0789 0.0726 0.0690 0.0661 0.0639 0.0622 0.0608 0.0596 0.0588 0.0582 0.0578 0.0574 0.0572 

[TRAIN] Epoch[5](64/375); Loss: 0.033737; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0744 0.0593 0.0439 0.0362 0.0329 0.0306 0.0290 0.0278 0.0270 0.0264 0.0259 0.0256 0.0254 0.0252 0.0251 0.0251 

[TRAIN] Epoch[5](65/375); Loss: 0.053218; Backpropagation: 0.2887 sec; Batch: 2.0739 sec
0.1048 0.0778 0.0652 0.0582 0.0540 0.0510 0.0486 0.0469 0.0456 0.0445 0.0436 0.0430 0.0425 0.0422 0.0419 0.0417 

[TRAIN] Epoch[5](66/375); Loss: 0.030920; Backpropagation: 0.2882 sec; Batch: 2.0723 sec
0.0733 0.0558 0.0414 0.0343 0.0307 0.0280 0.0261 0.0249 0.0240 0.0234 0.0229 0.0225 0.0221 0.0219 0.0218 0.0217 

[TRAIN] Epoch[5](67/375); Loss: 0.057917; Backpropagation: 0.2887 sec; Batch: 2.0735 sec
0.1222 0.0999 0.0758 0.0664 0.0593 0.0535 0.0502 0.0480 0.0464 0.0453 0.0446 0.0439 0.0433 0.0429 0.0425 0.0424 

[TRAIN] Epoch[5](68/375); Loss: 0.028008; Backpropagation: 0.2889 sec; Batch: 2.0728 sec
0.0726 0.0421 0.0330 0.0285 0.0264 0.0251 0.0240 0.0232 0.0226 0.0222 0.0219 0.0216 0.0214 0.0213 0.0211 0.0211 

[TRAIN] Epoch[5](69/375); Loss: 0.070776; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.1286 0.1037 0.0867 0.0783 0.0727 0.0686 0.0656 0.0633 0.0616 0.0601 0.0590 0.0580 0.0573 0.0567 0.0564 0.0561 

[TRAIN] Epoch[5](70/375); Loss: 0.043268; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0944 0.0732 0.0563 0.0483 0.0437 0.0404 0.0382 0.0364 0.0349 0.0338 0.0331 0.0325 0.0322 0.0318 0.0316 0.0314 

[TRAIN] Epoch[5](71/375); Loss: 0.044868; Backpropagation: 0.2882 sec; Batch: 2.0720 sec
0.0865 0.0676 0.0558 0.0487 0.0450 0.0425 0.0407 0.0394 0.0383 0.0375 0.0369 0.0364 0.0360 0.0358 0.0355 0.0353 

[TRAIN] Epoch[5](72/375); Loss: 0.048897; Backpropagation: 0.2887 sec; Batch: 2.0738 sec
0.0975 0.0722 0.0609 0.0542 0.0502 0.0472 0.0449 0.0430 0.0415 0.0403 0.0396 0.0389 0.0385 0.0382 0.0379 0.0376 

[TRAIN] Epoch[5](73/375); Loss: 0.025188; Backpropagation: 0.2882 sec; Batch: 2.0728 sec
0.0759 0.0429 0.0317 0.0262 0.0236 0.0218 0.0204 0.0195 0.0188 0.0182 0.0179 0.0175 0.0174 0.0172 0.0170 0.0170 

[TRAIN] Epoch[5](74/375); Loss: 0.040997; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.0985 0.0760 0.0588 0.0462 0.0400 0.0367 0.0344 0.0327 0.0315 0.0304 0.0296 0.0289 0.0285 0.0281 0.0279 0.0277 

[TRAIN] Epoch[5](75/375); Loss: 0.056061; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.1154 0.0893 0.0710 0.0609 0.0562 0.0529 0.0502 0.0483 0.0467 0.0456 0.0448 0.0440 0.0434 0.0431 0.0427 0.0426 

[TRAIN] Epoch[5](76/375); Loss: 0.046542; Backpropagation: 0.2885 sec; Batch: 2.0725 sec
0.1102 0.0833 0.0625 0.0499 0.0449 0.0418 0.0397 0.0379 0.0365 0.0355 0.0347 0.0342 0.0338 0.0335 0.0332 0.0330 

[TRAIN] Epoch[5](77/375); Loss: 0.035668; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.0969 0.0583 0.0452 0.0385 0.0344 0.0317 0.0299 0.0285 0.0275 0.0267 0.0262 0.0257 0.0255 0.0254 0.0252 0.0251 

[TRAIN] Epoch[5](78/375); Loss: 0.041542; Backpropagation: 0.2885 sec; Batch: 2.0727 sec
0.0873 0.0654 0.0532 0.0456 0.0416 0.0390 0.0370 0.0355 0.0344 0.0335 0.0330 0.0325 0.0321 0.0318 0.0315 0.0313 

[TRAIN] Epoch[5](79/375); Loss: 0.047507; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.0897 0.0688 0.0575 0.0518 0.0484 0.0458 0.0438 0.0424 0.0409 0.0400 0.0393 0.0389 0.0386 0.0383 0.0380 0.0379 

[TRAIN] Epoch[5](80/375); Loss: 0.053102; Backpropagation: 0.2885 sec; Batch: 2.0722 sec
0.0971 0.0744 0.0644 0.0577 0.0538 0.0512 0.0492 0.0477 0.0463 0.0454 0.0447 0.0442 0.0438 0.0435 0.0432 0.0429 

[TRAIN] Epoch[5](81/375); Loss: 0.040875; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.0851 0.0628 0.0492 0.0438 0.0407 0.0386 0.0367 0.0354 0.0344 0.0337 0.0330 0.0326 0.0323 0.0321 0.0319 0.0318 

[TRAIN] Epoch[5](82/375); Loss: 0.042061; Backpropagation: 0.2881 sec; Batch: 2.0731 sec
0.0863 0.0667 0.0541 0.0466 0.0418 0.0389 0.0369 0.0356 0.0348 0.0342 0.0336 0.0332 0.0328 0.0326 0.0324 0.0323 

[TRAIN] Epoch[5](83/375); Loss: 0.049540; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.0934 0.0773 0.0638 0.0559 0.0507 0.0470 0.0448 0.0430 0.0419 0.0409 0.0401 0.0395 0.0391 0.0387 0.0384 0.0382 

[TRAIN] Epoch[5](84/375); Loss: 0.040581; Backpropagation: 0.2882 sec; Batch: 2.0725 sec
0.0774 0.0612 0.0518 0.0449 0.0416 0.0388 0.0369 0.0355 0.0345 0.0336 0.0331 0.0326 0.0322 0.0319 0.0318 0.0316 

[TRAIN] Epoch[5](85/375); Loss: 0.037174; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.0899 0.0636 0.0488 0.0396 0.0360 0.0334 0.0317 0.0304 0.0294 0.0286 0.0281 0.0277 0.0273 0.0270 0.0267 0.0265 

[TRAIN] Epoch[5](86/375); Loss: 0.046978; Backpropagation: 0.2884 sec; Batch: 2.0730 sec
0.0921 0.0726 0.0582 0.0519 0.0484 0.0451 0.0427 0.0410 0.0396 0.0387 0.0380 0.0374 0.0369 0.0366 0.0363 0.0361 

[TRAIN] Epoch[5](87/375); Loss: 0.038147; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.0915 0.0652 0.0485 0.0402 0.0368 0.0344 0.0326 0.0313 0.0304 0.0296 0.0291 0.0287 0.0283 0.0281 0.0279 0.0278 

[TRAIN] Epoch[5](88/375); Loss: 0.042532; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.0962 0.0716 0.0547 0.0464 0.0421 0.0395 0.0372 0.0356 0.0344 0.0334 0.0327 0.0321 0.0316 0.0312 0.0310 0.0308 

[TRAIN] Epoch[5](89/375); Loss: 0.047730; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.0933 0.0726 0.0588 0.0513 0.0471 0.0448 0.0432 0.0419 0.0409 0.0399 0.0391 0.0387 0.0383 0.0380 0.0378 0.0378 

[TRAIN] Epoch[5](90/375); Loss: 0.057925; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.1058 0.0823 0.0707 0.0638 0.0594 0.0560 0.0537 0.0518 0.0504 0.0493 0.0484 0.0478 0.0473 0.0469 0.0467 0.0465 

[TRAIN] Epoch[5](91/375); Loss: 0.032216; Backpropagation: 0.2887 sec; Batch: 2.0732 sec
0.0843 0.0562 0.0412 0.0340 0.0307 0.0284 0.0269 0.0258 0.0249 0.0242 0.0238 0.0234 0.0232 0.0230 0.0228 0.0227 

[TRAIN] Epoch[5](92/375); Loss: 0.040237; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0871 0.0620 0.0509 0.0447 0.0410 0.0382 0.0359 0.0342 0.0330 0.0323 0.0317 0.0312 0.0308 0.0305 0.0303 0.0301 

[TRAIN] Epoch[5](93/375); Loss: 0.056944; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.1114 0.0830 0.0702 0.0624 0.0577 0.0541 0.0520 0.0502 0.0487 0.0478 0.0469 0.0463 0.0457 0.0453 0.0449 0.0447 

[TRAIN] Epoch[5](94/375); Loss: 0.029844; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.0637 0.0449 0.0376 0.0326 0.0297 0.0279 0.0266 0.0256 0.0249 0.0243 0.0239 0.0235 0.0233 0.0231 0.0230 0.0229 

[TRAIN] Epoch[5](95/375); Loss: 0.032611; Backpropagation: 0.2884 sec; Batch: 2.0724 sec
0.0798 0.0558 0.0443 0.0354 0.0315 0.0292 0.0276 0.0265 0.0255 0.0248 0.0242 0.0239 0.0236 0.0234 0.0232 0.0231 

[TRAIN] Epoch[5](96/375); Loss: 0.059377; Backpropagation: 0.2885 sec; Batch: 2.0731 sec
0.1020 0.0832 0.0727 0.0663 0.0615 0.0582 0.0555 0.0537 0.0521 0.0510 0.0500 0.0495 0.0490 0.0487 0.0484 0.0482 

[TRAIN] Epoch[5](97/375); Loss: 0.049999; Backpropagation: 0.2882 sec; Batch: 2.0729 sec
0.1011 0.0741 0.0616 0.0531 0.0486 0.0462 0.0449 0.0437 0.0428 0.0419 0.0412 0.0408 0.0404 0.0401 0.0399 0.0396 

[TRAIN] Epoch[5](98/375); Loss: 0.043604; Backpropagation: 0.2888 sec; Batch: 2.0730 sec
0.0882 0.0687 0.0545 0.0478 0.0441 0.0413 0.0393 0.0377 0.0366 0.0357 0.0350 0.0345 0.0340 0.0337 0.0334 0.0332 

[TRAIN] Epoch[5](99/375); Loss: 0.044719; Backpropagation: 0.2883 sec; Batch: 2.0727 sec
0.0878 0.0736 0.0574 0.0502 0.0456 0.0425 0.0404 0.0385 0.0371 0.0361 0.0354 0.0348 0.0344 0.0342 0.0339 0.0338 

[TRAIN] Epoch[5](100/375); Loss: 0.048586; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.1172 0.0927 0.0735 0.0579 0.0485 0.0426 0.0401 0.0379 0.0363 0.0351 0.0340 0.0332 0.0326 0.0322 0.0319 0.0317 

[TRAIN] Epoch[5](101/375); Loss: 0.044157; Backpropagation: 0.2887 sec; Batch: 2.0728 sec
0.0928 0.0753 0.0583 0.0486 0.0436 0.0405 0.0386 0.0371 0.0361 0.0351 0.0344 0.0339 0.0335 0.0331 0.0329 0.0328 

[TRAIN] Epoch[5](102/375); Loss: 0.047604; Backpropagation: 0.2886 sec; Batch: 2.0730 sec
0.0948 0.0709 0.0602 0.0528 0.0491 0.0460 0.0436 0.0417 0.0403 0.0392 0.0385 0.0377 0.0372 0.0368 0.0366 0.0364 

[TRAIN] Epoch[5](103/375); Loss: 0.048700; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.1002 0.0723 0.0589 0.0517 0.0483 0.0458 0.0439 0.0425 0.0414 0.0405 0.0398 0.0393 0.0390 0.0387 0.0385 0.0384 

[TRAIN] Epoch[5](104/375); Loss: 0.044668; Backpropagation: 0.2883 sec; Batch: 2.0723 sec
0.1086 0.0756 0.0559 0.0468 0.0427 0.0402 0.0381 0.0368 0.0357 0.0347 0.0341 0.0336 0.0333 0.0330 0.0328 0.0327 

[TRAIN] Epoch[5](105/375); Loss: 0.040199; Backpropagation: 0.2886 sec; Batch: 2.0725 sec
0.0838 0.0568 0.0483 0.0423 0.0396 0.0378 0.0363 0.0351 0.0343 0.0337 0.0332 0.0328 0.0325 0.0324 0.0322 0.0321 

[TRAIN] Epoch[5](106/375); Loss: 0.042799; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1125 0.0869 0.0610 0.0490 0.0418 0.0368 0.0342 0.0324 0.0311 0.0300 0.0292 0.0286 0.0281 0.0278 0.0276 0.0275 

[TRAIN] Epoch[5](107/375); Loss: 0.052039; Backpropagation: 0.2888 sec; Batch: 2.0724 sec
0.0991 0.0734 0.0654 0.0577 0.0538 0.0505 0.0483 0.0463 0.0448 0.0436 0.0428 0.0422 0.0416 0.0413 0.0410 0.0408 

[TRAIN] Epoch[5](108/375); Loss: 0.056611; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0994 0.0797 0.0674 0.0611 0.0576 0.0549 0.0527 0.0511 0.0499 0.0490 0.0483 0.0477 0.0472 0.0468 0.0466 0.0464 

[TRAIN] Epoch[5](109/375); Loss: 0.052334; Backpropagation: 0.2886 sec; Batch: 2.0726 sec
0.1040 0.0785 0.0652 0.0574 0.0534 0.0499 0.0473 0.0455 0.0442 0.0433 0.0426 0.0420 0.0415 0.0411 0.0409 0.0406 

[TRAIN] Epoch[5](110/375); Loss: 0.042655; Backpropagation: 0.2884 sec; Batch: 2.0719 sec
0.0895 0.0606 0.0499 0.0450 0.0422 0.0402 0.0389 0.0375 0.0366 0.0357 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 

[TRAIN] Epoch[5](111/375); Loss: 0.037991; Backpropagation: 0.2884 sec; Batch: 2.0725 sec
0.0693 0.0505 0.0446 0.0406 0.0384 0.0365 0.0352 0.0342 0.0335 0.0330 0.0326 0.0322 0.0320 0.0319 0.0318 0.0317 

[TRAIN] Epoch[5](112/375); Loss: 0.035809; Backpropagation: 0.2883 sec; Batch: 2.0765 sec
0.0676 0.0483 0.0421 0.0386 0.0361 0.0344 0.0330 0.0320 0.0313 0.0308 0.0304 0.0301 0.0298 0.0296 0.0295 0.0293 

[TRAIN] Epoch[5](113/375); Loss: 0.048025; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1028 0.0801 0.0630 0.0541 0.0490 0.0456 0.0428 0.0406 0.0391 0.0378 0.0368 0.0362 0.0356 0.0353 0.0350 0.0347 

[TRAIN] Epoch[5](114/375); Loss: 0.050743; Backpropagation: 0.2887 sec; Batch: 2.0730 sec
0.1083 0.0768 0.0624 0.0550 0.0508 0.0481 0.0458 0.0440 0.0427 0.0415 0.0407 0.0400 0.0395 0.0390 0.0388 0.0385 

[TRAIN] Epoch[5](115/375); Loss: 0.036524; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0928 0.0678 0.0480 0.0385 0.0351 0.0325 0.0307 0.0293 0.0281 0.0272 0.0266 0.0261 0.0257 0.0255 0.0252 0.0251 

[TRAIN] Epoch[5](116/375); Loss: 0.042323; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.0977 0.0720 0.0541 0.0460 0.0418 0.0387 0.0368 0.0352 0.0340 0.0330 0.0322 0.0317 0.0314 0.0310 0.0308 0.0307 

[TRAIN] Epoch[5](117/375); Loss: 0.059217; Backpropagation: 0.2888 sec; Batch: 2.0726 sec
0.1023 0.0806 0.0694 0.0638 0.0600 0.0574 0.0556 0.0540 0.0527 0.0516 0.0509 0.0504 0.0501 0.0497 0.0495 0.0493 

[TRAIN] Epoch[5](118/375); Loss: 0.057215; Backpropagation: 0.2886 sec; Batch: 2.0716 sec
0.1260 0.0934 0.0710 0.0602 0.0557 0.0528 0.0507 0.0488 0.0473 0.0462 0.0453 0.0445 0.0439 0.0435 0.0432 0.0429 

[TRAIN] Epoch[5](119/375); Loss: 0.049304; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.1035 0.0788 0.0636 0.0553 0.0503 0.0466 0.0440 0.0420 0.0406 0.0395 0.0387 0.0379 0.0374 0.0371 0.0368 0.0367 

[TRAIN] Epoch[5](120/375); Loss: 0.053791; Backpropagation: 0.2886 sec; Batch: 2.0730 sec
0.0965 0.0781 0.0659 0.0586 0.0546 0.0518 0.0497 0.0481 0.0469 0.0459 0.0452 0.0446 0.0441 0.0438 0.0435 0.0433 

[TRAIN] Epoch[5](121/375); Loss: 0.037587; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0894 0.0626 0.0482 0.0408 0.0371 0.0346 0.0325 0.0310 0.0300 0.0291 0.0285 0.0281 0.0278 0.0275 0.0273 0.0271 

[TRAIN] Epoch[5](122/375); Loss: 0.069608; Backpropagation: 0.2887 sec; Batch: 2.0724 sec
0.1214 0.1030 0.0868 0.0761 0.0713 0.0673 0.0644 0.0622 0.0607 0.0594 0.0584 0.0576 0.0570 0.0564 0.0561 0.0558 

[TRAIN] Epoch[5](123/375); Loss: 0.044713; Backpropagation: 0.2882 sec; Batch: 2.0728 sec
0.0934 0.0674 0.0547 0.0477 0.0445 0.0420 0.0402 0.0387 0.0377 0.0369 0.0362 0.0358 0.0354 0.0352 0.0350 0.0348 

[TRAIN] Epoch[5](124/375); Loss: 0.041497; Backpropagation: 0.2884 sec; Batch: 2.0725 sec
0.0929 0.0693 0.0540 0.0452 0.0409 0.0382 0.0359 0.0346 0.0335 0.0327 0.0321 0.0316 0.0312 0.0309 0.0306 0.0304 

[TRAIN] Epoch[5](125/375); Loss: 0.054158; Backpropagation: 0.2887 sec; Batch: 2.0729 sec
0.1319 0.0973 0.0716 0.0590 0.0531 0.0488 0.0460 0.0438 0.0421 0.0408 0.0400 0.0393 0.0387 0.0383 0.0381 0.0378 

[TRAIN] Epoch[5](126/375); Loss: 0.049090; Backpropagation: 0.2884 sec; Batch: 2.0717 sec
0.0983 0.0747 0.0617 0.0538 0.0494 0.0465 0.0443 0.0426 0.0413 0.0404 0.0397 0.0392 0.0387 0.0384 0.0382 0.0381 

[TRAIN] Epoch[5](127/375); Loss: 0.056473; Backpropagation: 0.2886 sec; Batch: 2.0726 sec
0.0961 0.0767 0.0657 0.0605 0.0574 0.0552 0.0532 0.0517 0.0505 0.0496 0.0488 0.0483 0.0479 0.0476 0.0473 0.0470 

[TRAIN] Epoch[5](128/375); Loss: 0.034593; Backpropagation: 0.2886 sec; Batch: 2.0727 sec
0.0707 0.0529 0.0430 0.0387 0.0353 0.0327 0.0310 0.0298 0.0288 0.0282 0.0277 0.0273 0.0271 0.0269 0.0268 0.0267 

[TRAIN] Epoch[5](129/375); Loss: 0.060004; Backpropagation: 0.2880 sec; Batch: 2.0719 sec
0.1268 0.0955 0.0762 0.0659 0.0605 0.0567 0.0538 0.0516 0.0499 0.0484 0.0473 0.0464 0.0459 0.0454 0.0451 0.0448 

[TRAIN] Epoch[5](130/375); Loss: 0.047790; Backpropagation: 0.2887 sec; Batch: 2.0725 sec
0.0951 0.0726 0.0589 0.0520 0.0483 0.0455 0.0435 0.0420 0.0407 0.0396 0.0389 0.0382 0.0377 0.0374 0.0372 0.0370 

[TRAIN] Epoch[5](131/375); Loss: 0.051157; Backpropagation: 0.2882 sec; Batch: 2.0729 sec
0.1030 0.0745 0.0628 0.0565 0.0526 0.0495 0.0471 0.0451 0.0437 0.0423 0.0414 0.0408 0.0404 0.0399 0.0397 0.0394 

[TRAIN] Epoch[5](132/375); Loss: 0.056925; Backpropagation: 0.2883 sec; Batch: 2.0726 sec
0.1227 0.0873 0.0701 0.0609 0.0563 0.0531 0.0508 0.0489 0.0475 0.0463 0.0456 0.0450 0.0445 0.0442 0.0439 0.0436 

[TRAIN] Epoch[5](133/375); Loss: 0.069175; Backpropagation: 0.2886 sec; Batch: 2.0725 sec
0.1227 0.0959 0.0827 0.0747 0.0709 0.0675 0.0649 0.0627 0.0610 0.0597 0.0587 0.0580 0.0574 0.0570 0.0566 0.0564 

[TRAIN] Epoch[5](134/375); Loss: 0.036934; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0786 0.0566 0.0451 0.0399 0.0370 0.0348 0.0331 0.0317 0.0307 0.0301 0.0296 0.0292 0.0289 0.0287 0.0286 0.0285 

[TRAIN] Epoch[5](135/375); Loss: 0.029479; Backpropagation: 0.2889 sec; Batch: 2.0729 sec
0.0796 0.0496 0.0360 0.0313 0.0282 0.0260 0.0246 0.0236 0.0228 0.0223 0.0218 0.0215 0.0213 0.0211 0.0210 0.0209 

[TRAIN] Epoch[5](136/375); Loss: 0.035457; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.0736 0.0590 0.0464 0.0389 0.0362 0.0338 0.0317 0.0303 0.0291 0.0283 0.0277 0.0272 0.0267 0.0264 0.0262 0.0260 

[TRAIN] Epoch[5](137/375); Loss: 0.033795; Backpropagation: 0.2885 sec; Batch: 2.0725 sec
0.0889 0.0619 0.0451 0.0351 0.0316 0.0293 0.0277 0.0265 0.0256 0.0250 0.0245 0.0242 0.0240 0.0238 0.0237 0.0237 

[TRAIN] Epoch[5](138/375); Loss: 0.033554; Backpropagation: 0.2887 sec; Batch: 2.0724 sec
0.0703 0.0529 0.0425 0.0369 0.0341 0.0317 0.0299 0.0286 0.0276 0.0269 0.0265 0.0262 0.0260 0.0257 0.0256 0.0255 

[TRAIN] Epoch[5](139/375); Loss: 0.055604; Backpropagation: 0.2885 sec; Batch: 2.0724 sec
0.1208 0.0912 0.0686 0.0606 0.0556 0.0521 0.0493 0.0473 0.0456 0.0444 0.0436 0.0429 0.0424 0.0420 0.0417 0.0415 

[TRAIN] Epoch[5](140/375); Loss: 0.066712; Backpropagation: 0.2886 sec; Batch: 2.0725 sec
0.1237 0.0952 0.0807 0.0723 0.0679 0.0643 0.0617 0.0596 0.0579 0.0566 0.0558 0.0552 0.0547 0.0543 0.0539 0.0537 

[TRAIN] Epoch[5](141/375); Loss: 0.030464; Backpropagation: 0.2883 sec; Batch: 2.0727 sec
0.0885 0.0539 0.0389 0.0320 0.0288 0.0266 0.0250 0.0237 0.0228 0.0221 0.0216 0.0212 0.0209 0.0206 0.0205 0.0204 

[TRAIN] Epoch[5](142/375); Loss: 0.041947; Backpropagation: 0.2884 sec; Batch: 2.0721 sec
0.0927 0.0704 0.0539 0.0452 0.0414 0.0387 0.0369 0.0354 0.0342 0.0332 0.0324 0.0320 0.0316 0.0313 0.0311 0.0309 

[TRAIN] Epoch[5](143/375); Loss: 0.052196; Backpropagation: 0.2887 sec; Batch: 2.0731 sec
0.1082 0.0805 0.0644 0.0565 0.0522 0.0494 0.0471 0.0453 0.0439 0.0429 0.0420 0.0413 0.0408 0.0404 0.0402 0.0399 

[TRAIN] Epoch[5](144/375); Loss: 0.050391; Backpropagation: 0.2888 sec; Batch: 2.0727 sec
0.1121 0.0779 0.0621 0.0548 0.0503 0.0469 0.0448 0.0429 0.0415 0.0406 0.0398 0.0392 0.0388 0.0384 0.0381 0.0380 

[TRAIN] Epoch[5](145/375); Loss: 0.042475; Backpropagation: 0.2886 sec; Batch: 2.0723 sec
0.0911 0.0632 0.0513 0.0457 0.0424 0.0401 0.0382 0.0368 0.0357 0.0350 0.0343 0.0338 0.0334 0.0331 0.0329 0.0327 

[TRAIN] Epoch[5](146/375); Loss: 0.043245; Backpropagation: 0.2887 sec; Batch: 2.0726 sec
0.1082 0.0792 0.0603 0.0492 0.0420 0.0376 0.0354 0.0338 0.0327 0.0319 0.0313 0.0307 0.0303 0.0300 0.0297 0.0295 

[TRAIN] Epoch[5](147/375); Loss: 0.059355; Backpropagation: 0.2887 sec; Batch: 2.0728 sec
0.1019 0.0835 0.0710 0.0646 0.0610 0.0582 0.0559 0.0539 0.0525 0.0513 0.0506 0.0499 0.0494 0.0490 0.0487 0.0485 

[TRAIN] Epoch[5](148/375); Loss: 0.029112; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0703 0.0489 0.0380 0.0322 0.0285 0.0264 0.0249 0.0237 0.0229 0.0223 0.0219 0.0216 0.0213 0.0211 0.0210 0.0209 

[TRAIN] Epoch[5](149/375); Loss: 0.047277; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0860 0.0692 0.0589 0.0524 0.0484 0.0455 0.0436 0.0419 0.0407 0.0399 0.0393 0.0388 0.0383 0.0381 0.0378 0.0377 

[TRAIN] Epoch[5](150/375); Loss: 0.040516; Backpropagation: 0.2887 sec; Batch: 2.0731 sec
0.0969 0.0645 0.0514 0.0453 0.0408 0.0376 0.0354 0.0339 0.0326 0.0315 0.0307 0.0301 0.0297 0.0294 0.0292 0.0291 

[TRAIN] Epoch[5](151/375); Loss: 0.040632; Backpropagation: 0.2886 sec; Batch: 2.0728 sec
0.0826 0.0603 0.0494 0.0436 0.0408 0.0383 0.0367 0.0354 0.0345 0.0337 0.0333 0.0328 0.0325 0.0323 0.0321 0.0320 

[TRAIN] Epoch[5](152/375); Loss: 0.050995; Backpropagation: 0.2886 sec; Batch: 2.0804 sec
0.0952 0.0785 0.0646 0.0568 0.0529 0.0496 0.0470 0.0451 0.0436 0.0424 0.0414 0.0407 0.0402 0.0397 0.0393 0.0391 

[TRAIN] Epoch[5](153/375); Loss: 0.035594; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0731 0.0562 0.0448 0.0397 0.0364 0.0337 0.0317 0.0303 0.0295 0.0288 0.0283 0.0279 0.0276 0.0273 0.0272 0.0270 

[TRAIN] Epoch[5](154/375); Loss: 0.068058; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1232 0.0995 0.0836 0.0738 0.0690 0.0654 0.0627 0.0606 0.0591 0.0577 0.0568 0.0563 0.0558 0.0555 0.0551 0.0549 

[TRAIN] Epoch[5](155/375); Loss: 0.049955; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.0979 0.0703 0.0604 0.0538 0.0503 0.0478 0.0458 0.0444 0.0431 0.0423 0.0415 0.0410 0.0406 0.0402 0.0400 0.0398 

[TRAIN] Epoch[5](156/375); Loss: 0.044986; Backpropagation: 0.2885 sec; Batch: 2.0729 sec
0.0837 0.0637 0.0544 0.0493 0.0458 0.0435 0.0415 0.0401 0.0390 0.0381 0.0375 0.0371 0.0368 0.0366 0.0364 0.0361 

[TRAIN] Epoch[5](157/375); Loss: 0.052414; Backpropagation: 0.2888 sec; Batch: 2.0724 sec
0.0965 0.0765 0.0642 0.0580 0.0538 0.0503 0.0479 0.0462 0.0451 0.0442 0.0436 0.0430 0.0427 0.0423 0.0422 0.0420 

[TRAIN] Epoch[5](158/375); Loss: 0.036030; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0898 0.0567 0.0440 0.0378 0.0346 0.0324 0.0309 0.0298 0.0289 0.0283 0.0278 0.0274 0.0272 0.0270 0.0270 0.0269 

[TRAIN] Epoch[5](159/375); Loss: 0.042013; Backpropagation: 0.2889 sec; Batch: 2.0732 sec
0.0906 0.0705 0.0550 0.0474 0.0429 0.0400 0.0377 0.0356 0.0341 0.0331 0.0322 0.0315 0.0309 0.0305 0.0302 0.0300 

[TRAIN] Epoch[5](160/375); Loss: 0.052025; Backpropagation: 0.2886 sec; Batch: 2.0742 sec
0.0962 0.0760 0.0626 0.0558 0.0523 0.0497 0.0477 0.0463 0.0452 0.0444 0.0436 0.0432 0.0427 0.0425 0.0423 0.0421 

[TRAIN] Epoch[5](161/375); Loss: 0.040734; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0743 0.0582 0.0479 0.0427 0.0403 0.0385 0.0372 0.0363 0.0357 0.0352 0.0348 0.0345 0.0342 0.0341 0.0340 0.0339 

[TRAIN] Epoch[5](162/375); Loss: 0.045058; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0819 0.0679 0.0553 0.0493 0.0460 0.0437 0.0418 0.0402 0.0390 0.0380 0.0373 0.0368 0.0363 0.0360 0.0358 0.0356 

[TRAIN] Epoch[5](163/375); Loss: 0.038338; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0853 0.0605 0.0489 0.0419 0.0380 0.0355 0.0337 0.0323 0.0312 0.0306 0.0300 0.0296 0.0293 0.0291 0.0289 0.0288 

[TRAIN] Epoch[5](164/375); Loss: 0.048863; Backpropagation: 0.2884 sec; Batch: 2.0729 sec
0.0921 0.0679 0.0594 0.0533 0.0493 0.0464 0.0445 0.0434 0.0424 0.0417 0.0411 0.0406 0.0402 0.0400 0.0398 0.0397 

[TRAIN] Epoch[5](165/375); Loss: 0.028904; Backpropagation: 0.2887 sec; Batch: 2.0727 sec
0.0657 0.0422 0.0336 0.0301 0.0279 0.0267 0.0257 0.0248 0.0243 0.0238 0.0234 0.0231 0.0229 0.0228 0.0227 0.0227 

[TRAIN] Epoch[5](166/375); Loss: 0.044964; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0998 0.0715 0.0581 0.0514 0.0467 0.0426 0.0399 0.0377 0.0363 0.0352 0.0344 0.0339 0.0334 0.0330 0.0328 0.0326 

[TRAIN] Epoch[5](167/375); Loss: 0.046855; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0954 0.0709 0.0577 0.0515 0.0477 0.0450 0.0430 0.0411 0.0397 0.0386 0.0378 0.0371 0.0366 0.0362 0.0359 0.0356 

[TRAIN] Epoch[5](168/375); Loss: 0.031255; Backpropagation: 0.2887 sec; Batch: 2.0729 sec
0.0666 0.0472 0.0368 0.0326 0.0304 0.0289 0.0278 0.0269 0.0263 0.0259 0.0256 0.0253 0.0251 0.0249 0.0248 0.0247 

[TRAIN] Epoch[5](169/375); Loss: 0.066905; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1371 0.1040 0.0834 0.0722 0.0671 0.0633 0.0603 0.0579 0.0561 0.0548 0.0539 0.0531 0.0525 0.0519 0.0516 0.0514 

[TRAIN] Epoch[5](170/375); Loss: 0.060875; Backpropagation: 0.2887 sec; Batch: 2.0818 sec
0.1283 0.0921 0.0748 0.0666 0.0619 0.0577 0.0548 0.0527 0.0509 0.0497 0.0488 0.0481 0.0474 0.0470 0.0467 0.0464 

[TRAIN] Epoch[5](171/375); Loss: 0.054604; Backpropagation: 0.2884 sec; Batch: 2.0724 sec
0.0940 0.0761 0.0623 0.0570 0.0545 0.0525 0.0512 0.0499 0.0488 0.0480 0.0473 0.0469 0.0466 0.0464 0.0461 0.0460 

[TRAIN] Epoch[5](172/375); Loss: 0.060389; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.1177 0.0911 0.0777 0.0686 0.0631 0.0585 0.0554 0.0529 0.0510 0.0494 0.0483 0.0475 0.0469 0.0463 0.0460 0.0457 

[TRAIN] Epoch[5](173/375); Loss: 0.037418; Backpropagation: 0.2888 sec; Batch: 2.0744 sec
0.0723 0.0546 0.0439 0.0401 0.0377 0.0358 0.0341 0.0331 0.0323 0.0317 0.0313 0.0309 0.0305 0.0303 0.0301 0.0300 

[TRAIN] Epoch[5](174/375); Loss: 0.032720; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0817 0.0558 0.0441 0.0360 0.0322 0.0296 0.0277 0.0264 0.0255 0.0248 0.0241 0.0237 0.0233 0.0230 0.0229 0.0227 

[TRAIN] Epoch[5](175/375); Loss: 0.048402; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.1083 0.0795 0.0623 0.0537 0.0489 0.0454 0.0427 0.0405 0.0391 0.0380 0.0372 0.0366 0.0360 0.0357 0.0354 0.0352 

[TRAIN] Epoch[5](176/375); Loss: 0.039358; Backpropagation: 0.2886 sec; Batch: 2.0723 sec
0.0809 0.0581 0.0486 0.0431 0.0400 0.0377 0.0359 0.0344 0.0333 0.0324 0.0317 0.0312 0.0309 0.0307 0.0305 0.0303 

[TRAIN] Epoch[5](177/375); Loss: 0.047419; Backpropagation: 0.2887 sec; Batch: 2.0726 sec
0.0940 0.0691 0.0589 0.0532 0.0487 0.0453 0.0431 0.0416 0.0403 0.0395 0.0386 0.0381 0.0376 0.0372 0.0369 0.0367 

[TRAIN] Epoch[5](178/375); Loss: 0.049847; Backpropagation: 0.2896 sec; Batch: 2.0728 sec
0.1030 0.0753 0.0625 0.0539 0.0497 0.0469 0.0448 0.0431 0.0420 0.0410 0.0402 0.0397 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[5](179/375); Loss: 0.064712; Backpropagation: 0.2884 sec; Batch: 2.0723 sec
0.1156 0.0984 0.0798 0.0718 0.0666 0.0630 0.0601 0.0577 0.0559 0.0546 0.0535 0.0527 0.0520 0.0515 0.0512 0.0510 

[TRAIN] Epoch[5](180/375); Loss: 0.048764; Backpropagation: 0.2885 sec; Batch: 2.0725 sec
0.0993 0.0760 0.0603 0.0531 0.0491 0.0461 0.0437 0.0419 0.0406 0.0398 0.0391 0.0388 0.0384 0.0382 0.0380 0.0379 

[TRAIN] Epoch[5](181/375); Loss: 0.050709; Backpropagation: 0.2885 sec; Batch: 2.0727 sec
0.0848 0.0667 0.0605 0.0555 0.0527 0.0500 0.0480 0.0465 0.0454 0.0445 0.0438 0.0433 0.0429 0.0425 0.0423 0.0421 

[TRAIN] Epoch[5](182/375); Loss: 0.037397; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0924 0.0599 0.0454 0.0402 0.0368 0.0345 0.0326 0.0310 0.0299 0.0291 0.0285 0.0281 0.0278 0.0275 0.0274 0.0272 

[TRAIN] Epoch[5](183/375); Loss: 0.045299; Backpropagation: 0.2889 sec; Batch: 2.0730 sec
0.0980 0.0688 0.0565 0.0493 0.0458 0.0427 0.0405 0.0388 0.0376 0.0366 0.0360 0.0355 0.0351 0.0348 0.0345 0.0343 

[TRAIN] Epoch[5](184/375); Loss: 0.023726; Backpropagation: 0.2888 sec; Batch: 2.0730 sec
0.0564 0.0429 0.0317 0.0261 0.0229 0.0210 0.0199 0.0191 0.0184 0.0180 0.0176 0.0174 0.0172 0.0171 0.0170 0.0169 

[TRAIN] Epoch[5](185/375); Loss: 0.041273; Backpropagation: 0.2889 sec; Batch: 2.0726 sec
0.0904 0.0650 0.0505 0.0444 0.0413 0.0388 0.0368 0.0353 0.0342 0.0333 0.0327 0.0322 0.0317 0.0314 0.0312 0.0311 

[TRAIN] Epoch[5](186/375); Loss: 0.049591; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.1122 0.0846 0.0637 0.0518 0.0477 0.0449 0.0430 0.0415 0.0401 0.0393 0.0385 0.0380 0.0375 0.0371 0.0369 0.0366 

[TRAIN] Epoch[5](187/375); Loss: 0.039962; Backpropagation: 0.2886 sec; Batch: 2.0720 sec
0.0899 0.0646 0.0507 0.0436 0.0398 0.0369 0.0352 0.0337 0.0327 0.0318 0.0311 0.0305 0.0301 0.0298 0.0296 0.0294 

[TRAIN] Epoch[5](188/375); Loss: 0.066210; Backpropagation: 0.2884 sec; Batch: 2.0719 sec
0.1335 0.1059 0.0867 0.0738 0.0662 0.0620 0.0589 0.0567 0.0549 0.0536 0.0526 0.0519 0.0513 0.0508 0.0504 0.0501 

[TRAIN] Epoch[5](189/375); Loss: 0.056979; Backpropagation: 0.2886 sec; Batch: 2.0720 sec
0.1116 0.0853 0.0694 0.0618 0.0573 0.0539 0.0516 0.0500 0.0487 0.0476 0.0468 0.0462 0.0458 0.0454 0.0451 0.0450 

[TRAIN] Epoch[5](190/375); Loss: 0.052604; Backpropagation: 0.2884 sec; Batch: 2.0721 sec
0.0928 0.0750 0.0640 0.0585 0.0548 0.0519 0.0494 0.0475 0.0459 0.0448 0.0440 0.0434 0.0429 0.0425 0.0423 0.0420 

[TRAIN] Epoch[5](191/375); Loss: 0.042926; Backpropagation: 0.2882 sec; Batch: 2.0715 sec
0.0996 0.0702 0.0538 0.0470 0.0426 0.0396 0.0376 0.0360 0.0348 0.0338 0.0330 0.0324 0.0320 0.0317 0.0315 0.0313 

[TRAIN] Epoch[5](192/375); Loss: 0.043226; Backpropagation: 0.2890 sec; Batch: 2.0742 sec
0.0816 0.0617 0.0514 0.0465 0.0437 0.0414 0.0397 0.0384 0.0373 0.0367 0.0363 0.0359 0.0356 0.0354 0.0352 0.0350 

[TRAIN] Epoch[5](193/375); Loss: 0.051819; Backpropagation: 0.2886 sec; Batch: 2.1131 sec
0.1011 0.0748 0.0628 0.0566 0.0530 0.0501 0.0479 0.0462 0.0447 0.0434 0.0425 0.0419 0.0414 0.0411 0.0408 0.0406 

[TRAIN] Epoch[5](194/375); Loss: 0.034432; Backpropagation: 0.2883 sec; Batch: 2.0722 sec
0.0772 0.0524 0.0411 0.0362 0.0337 0.0317 0.0304 0.0293 0.0287 0.0281 0.0276 0.0273 0.0270 0.0269 0.0267 0.0266 

[TRAIN] Epoch[5](195/375); Loss: 0.039096; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0878 0.0675 0.0480 0.0411 0.0380 0.0356 0.0339 0.0326 0.0317 0.0310 0.0304 0.0300 0.0297 0.0295 0.0293 0.0292 

[TRAIN] Epoch[5](196/375); Loss: 0.041709; Backpropagation: 0.2886 sec; Batch: 2.1150 sec
0.0883 0.0730 0.0578 0.0483 0.0429 0.0390 0.0366 0.0350 0.0335 0.0322 0.0313 0.0306 0.0301 0.0298 0.0296 0.0294 

[TRAIN] Epoch[5](197/375); Loss: 0.044665; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.0865 0.0651 0.0546 0.0485 0.0454 0.0428 0.0411 0.0396 0.0384 0.0374 0.0367 0.0363 0.0359 0.0357 0.0354 0.0352 

[TRAIN] Epoch[5](198/375); Loss: 0.045412; Backpropagation: 0.2883 sec; Batch: 2.0784 sec
0.1063 0.0745 0.0601 0.0510 0.0458 0.0417 0.0391 0.0375 0.0361 0.0351 0.0343 0.0337 0.0333 0.0329 0.0327 0.0325 

[TRAIN] Epoch[5](199/375); Loss: 0.048637; Backpropagation: 0.2885 sec; Batch: 2.0725 sec
0.0923 0.0706 0.0581 0.0524 0.0490 0.0464 0.0445 0.0431 0.0420 0.0413 0.0406 0.0402 0.0398 0.0395 0.0393 0.0391 

[TRAIN] Epoch[5](200/375); Loss: 0.049486; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.0940 0.0708 0.0599 0.0530 0.0497 0.0471 0.0453 0.0438 0.0427 0.0419 0.0413 0.0409 0.0406 0.0404 0.0403 0.0401 

[TRAIN] Epoch[5](201/375); Loss: 0.055452; Backpropagation: 0.2885 sec; Batch: 2.0728 sec
0.1119 0.0823 0.0685 0.0604 0.0561 0.0532 0.0507 0.0489 0.0473 0.0460 0.0450 0.0442 0.0436 0.0433 0.0430 0.0427 

[TRAIN] Epoch[5](202/375); Loss: 0.048692; Backpropagation: 0.2889 sec; Batch: 2.0801 sec
0.1056 0.0764 0.0636 0.0550 0.0496 0.0456 0.0432 0.0413 0.0399 0.0388 0.0379 0.0372 0.0367 0.0363 0.0360 0.0358 

[TRAIN] Epoch[5](203/375); Loss: 0.043537; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0898 0.0646 0.0524 0.0469 0.0436 0.0411 0.0392 0.0380 0.0368 0.0360 0.0354 0.0350 0.0347 0.0345 0.0343 0.0341 

[TRAIN] Epoch[5](204/375); Loss: 0.051839; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.1162 0.0894 0.0679 0.0563 0.0518 0.0476 0.0451 0.0432 0.0415 0.0403 0.0395 0.0389 0.0384 0.0381 0.0377 0.0375 

[TRAIN] Epoch[5](205/375); Loss: 0.044332; Backpropagation: 0.2887 sec; Batch: 2.0754 sec
0.0876 0.0652 0.0529 0.0482 0.0443 0.0420 0.0403 0.0390 0.0380 0.0372 0.0366 0.0362 0.0358 0.0356 0.0353 0.0352 

[TRAIN] Epoch[5](206/375); Loss: 0.050011; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.1118 0.0827 0.0638 0.0544 0.0496 0.0462 0.0438 0.0421 0.0407 0.0396 0.0388 0.0382 0.0376 0.0372 0.0369 0.0367 

[TRAIN] Epoch[5](207/375); Loss: 0.057753; Backpropagation: 0.2884 sec; Batch: 2.0827 sec
0.1476 0.1275 0.0953 0.0715 0.0569 0.0471 0.0438 0.0413 0.0397 0.0384 0.0374 0.0365 0.0359 0.0354 0.0350 0.0348 

[TRAIN] Epoch[5](208/375); Loss: 0.037542; Backpropagation: 0.2888 sec; Batch: 2.0777 sec
0.0755 0.0546 0.0447 0.0401 0.0374 0.0354 0.0341 0.0330 0.0322 0.0315 0.0310 0.0307 0.0304 0.0302 0.0300 0.0300 

[TRAIN] Epoch[5](209/375); Loss: 0.042255; Backpropagation: 0.2880 sec; Batch: 2.0866 sec
0.0942 0.0664 0.0526 0.0460 0.0423 0.0394 0.0373 0.0358 0.0347 0.0338 0.0331 0.0326 0.0323 0.0320 0.0318 0.0317 

[TRAIN] Epoch[5](210/375); Loss: 0.068552; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1215 0.1068 0.0844 0.0739 0.0689 0.0658 0.0631 0.0611 0.0594 0.0581 0.0572 0.0565 0.0558 0.0552 0.0549 0.0546 

[TRAIN] Epoch[5](211/375); Loss: 0.049138; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.0922 0.0743 0.0597 0.0536 0.0495 0.0469 0.0449 0.0434 0.0420 0.0412 0.0406 0.0401 0.0398 0.0395 0.0393 0.0391 

[TRAIN] Epoch[5](212/375); Loss: 0.038882; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0851 0.0635 0.0488 0.0427 0.0388 0.0362 0.0343 0.0329 0.0319 0.0310 0.0303 0.0299 0.0295 0.0292 0.0290 0.0289 

[TRAIN] Epoch[5](213/375); Loss: 0.038889; Backpropagation: 0.2888 sec; Batch: 2.0740 sec
0.0856 0.0625 0.0484 0.0420 0.0380 0.0356 0.0340 0.0328 0.0320 0.0313 0.0307 0.0303 0.0300 0.0297 0.0296 0.0295 

[TRAIN] Epoch[5](214/375); Loss: 0.039160; Backpropagation: 0.2883 sec; Batch: 2.1049 sec
0.0805 0.0575 0.0478 0.0426 0.0395 0.0370 0.0356 0.0343 0.0333 0.0325 0.0319 0.0314 0.0310 0.0307 0.0305 0.0304 

[TRAIN] Epoch[5](215/375); Loss: 0.043117; Backpropagation: 0.2886 sec; Batch: 2.0784 sec
0.0886 0.0640 0.0526 0.0468 0.0433 0.0411 0.0393 0.0378 0.0365 0.0356 0.0349 0.0345 0.0341 0.0338 0.0336 0.0334 

[TRAIN] Epoch[5](216/375); Loss: 0.042931; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0864 0.0609 0.0509 0.0465 0.0436 0.0411 0.0392 0.0379 0.0368 0.0360 0.0354 0.0350 0.0347 0.0344 0.0342 0.0341 

[TRAIN] Epoch[5](217/375); Loss: 0.031681; Backpropagation: 0.2882 sec; Batch: 2.1024 sec
0.0689 0.0487 0.0394 0.0345 0.0317 0.0298 0.0283 0.0272 0.0263 0.0256 0.0251 0.0247 0.0245 0.0243 0.0241 0.0240 

[TRAIN] Epoch[5](218/375); Loss: 0.045453; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0854 0.0652 0.0545 0.0493 0.0464 0.0444 0.0424 0.0408 0.0396 0.0387 0.0379 0.0373 0.0368 0.0365 0.0362 0.0359 

[TRAIN] Epoch[5](219/375); Loss: 0.056724; Backpropagation: 0.2884 sec; Batch: 2.1126 sec
0.1030 0.0822 0.0687 0.0623 0.0586 0.0554 0.0531 0.0511 0.0494 0.0483 0.0473 0.0465 0.0460 0.0455 0.0452 0.0450 

[TRAIN] Epoch[5](220/375); Loss: 0.034715; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0652 0.0493 0.0398 0.0363 0.0340 0.0326 0.0317 0.0309 0.0304 0.0299 0.0296 0.0294 0.0292 0.0291 0.0290 0.0289 

[TRAIN] Epoch[5](221/375); Loss: 0.043867; Backpropagation: 0.2886 sec; Batch: 2.1056 sec
0.1005 0.0729 0.0536 0.0474 0.0425 0.0393 0.0376 0.0364 0.0355 0.0348 0.0342 0.0338 0.0335 0.0333 0.0333 0.0332 

[TRAIN] Epoch[5](222/375); Loss: 0.052462; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.1176 0.0875 0.0670 0.0571 0.0518 0.0484 0.0461 0.0444 0.0428 0.0416 0.0405 0.0398 0.0392 0.0389 0.0385 0.0382 

[TRAIN] Epoch[5](223/375); Loss: 0.052004; Backpropagation: 0.2888 sec; Batch: 2.0731 sec
0.0915 0.0709 0.0625 0.0569 0.0533 0.0507 0.0486 0.0471 0.0458 0.0449 0.0442 0.0437 0.0433 0.0431 0.0428 0.0427 

[TRAIN] Epoch[5](224/375); Loss: 0.051595; Backpropagation: 0.2885 sec; Batch: 2.0763 sec
0.0960 0.0796 0.0654 0.0579 0.0530 0.0495 0.0466 0.0449 0.0437 0.0427 0.0421 0.0416 0.0410 0.0407 0.0405 0.0403 

[TRAIN] Epoch[5](225/375); Loss: 0.037512; Backpropagation: 0.2881 sec; Batch: 2.0723 sec
0.0936 0.0652 0.0482 0.0402 0.0359 0.0333 0.0318 0.0302 0.0293 0.0286 0.0281 0.0276 0.0273 0.0271 0.0270 0.0268 

[TRAIN] Epoch[5](226/375); Loss: 0.028843; Backpropagation: 0.2887 sec; Batch: 2.0742 sec
0.0766 0.0481 0.0366 0.0305 0.0278 0.0257 0.0243 0.0232 0.0223 0.0218 0.0213 0.0210 0.0208 0.0206 0.0205 0.0204 

[TRAIN] Epoch[5](227/375); Loss: 0.038551; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1002 0.0770 0.0568 0.0447 0.0378 0.0325 0.0306 0.0292 0.0280 0.0270 0.0264 0.0260 0.0255 0.0252 0.0250 0.0249 

[TRAIN] Epoch[5](228/375); Loss: 0.057181; Backpropagation: 0.2890 sec; Batch: 2.0937 sec
0.1176 0.0900 0.0737 0.0632 0.0570 0.0539 0.0509 0.0490 0.0474 0.0462 0.0455 0.0449 0.0443 0.0440 0.0437 0.0435 

[TRAIN] Epoch[5](229/375); Loss: 0.040375; Backpropagation: 0.2884 sec; Batch: 2.0804 sec
0.0870 0.0661 0.0517 0.0450 0.0411 0.0382 0.0360 0.0343 0.0328 0.0319 0.0312 0.0308 0.0304 0.0301 0.0298 0.0296 

[TRAIN] Epoch[5](230/375); Loss: 0.040952; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0920 0.0664 0.0518 0.0450 0.0412 0.0384 0.0362 0.0346 0.0334 0.0324 0.0316 0.0311 0.0307 0.0304 0.0302 0.0300 

[TRAIN] Epoch[5](231/375); Loss: 0.028992; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0686 0.0480 0.0393 0.0324 0.0286 0.0263 0.0248 0.0237 0.0228 0.0222 0.0218 0.0214 0.0212 0.0210 0.0209 0.0209 

[TRAIN] Epoch[5](232/375); Loss: 0.041370; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0906 0.0687 0.0540 0.0459 0.0417 0.0386 0.0365 0.0348 0.0335 0.0326 0.0319 0.0314 0.0309 0.0306 0.0303 0.0301 

[TRAIN] Epoch[5](233/375); Loss: 0.044929; Backpropagation: 0.2886 sec; Batch: 2.0900 sec
0.0918 0.0722 0.0563 0.0486 0.0449 0.0421 0.0402 0.0386 0.0375 0.0365 0.0359 0.0354 0.0351 0.0348 0.0346 0.0344 

[TRAIN] Epoch[5](234/375); Loss: 0.049893; Backpropagation: 0.2886 sec; Batch: 2.0732 sec
0.1007 0.0755 0.0615 0.0548 0.0504 0.0474 0.0452 0.0435 0.0421 0.0412 0.0404 0.0398 0.0394 0.0391 0.0388 0.0386 

[TRAIN] Epoch[5](235/375); Loss: 0.031390; Backpropagation: 0.2885 sec; Batch: 2.0760 sec
0.0677 0.0460 0.0377 0.0335 0.0311 0.0293 0.0280 0.0271 0.0264 0.0259 0.0255 0.0252 0.0249 0.0248 0.0247 0.0246 

[TRAIN] Epoch[5](236/375); Loss: 0.035873; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0750 0.0523 0.0439 0.0385 0.0355 0.0336 0.0322 0.0311 0.0303 0.0296 0.0292 0.0288 0.0287 0.0286 0.0284 0.0283 

[TRAIN] Epoch[5](237/375); Loss: 0.052983; Backpropagation: 0.2889 sec; Batch: 2.0776 sec
0.1165 0.0822 0.0674 0.0592 0.0537 0.0496 0.0470 0.0448 0.0432 0.0422 0.0413 0.0408 0.0404 0.0400 0.0398 0.0396 

[TRAIN] Epoch[5](238/375); Loss: 0.070259; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.1195 0.0981 0.0847 0.0778 0.0725 0.0687 0.0658 0.0636 0.0620 0.0606 0.0597 0.0591 0.0586 0.0581 0.0577 0.0574 

[TRAIN] Epoch[5](239/375); Loss: 0.044677; Backpropagation: 0.2885 sec; Batch: 2.0727 sec
0.0860 0.0640 0.0537 0.0489 0.0458 0.0432 0.0413 0.0398 0.0387 0.0377 0.0370 0.0364 0.0360 0.0356 0.0354 0.0352 

[TRAIN] Epoch[5](240/375); Loss: 0.036573; Backpropagation: 0.2883 sec; Batch: 2.0939 sec
0.0949 0.0759 0.0543 0.0437 0.0374 0.0321 0.0289 0.0270 0.0258 0.0248 0.0242 0.0237 0.0234 0.0231 0.0230 0.0229 

[TRAIN] Epoch[5](241/375); Loss: 0.054704; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.1065 0.0833 0.0677 0.0599 0.0553 0.0519 0.0496 0.0477 0.0464 0.0455 0.0447 0.0441 0.0436 0.0433 0.0431 0.0428 

[TRAIN] Epoch[5](242/375); Loss: 0.042800; Backpropagation: 0.2884 sec; Batch: 2.0726 sec
0.1003 0.0713 0.0550 0.0471 0.0425 0.0396 0.0373 0.0356 0.0342 0.0332 0.0324 0.0319 0.0315 0.0312 0.0310 0.0307 

[TRAIN] Epoch[5](243/375); Loss: 0.039690; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0846 0.0574 0.0488 0.0434 0.0402 0.0376 0.0358 0.0345 0.0334 0.0326 0.0319 0.0315 0.0312 0.0310 0.0307 0.0306 

[TRAIN] Epoch[5](244/375); Loss: 0.027009; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.0560 0.0427 0.0334 0.0294 0.0270 0.0251 0.0240 0.0231 0.0224 0.0220 0.0217 0.0214 0.0212 0.0210 0.0209 0.0208 

[TRAIN] Epoch[5](245/375); Loss: 0.034913; Backpropagation: 0.2883 sec; Batch: 2.0728 sec
0.0770 0.0545 0.0422 0.0376 0.0346 0.0324 0.0309 0.0298 0.0289 0.0283 0.0278 0.0273 0.0271 0.0269 0.0267 0.0266 

[TRAIN] Epoch[5](246/375); Loss: 0.051746; Backpropagation: 0.2887 sec; Batch: 2.0725 sec
0.1127 0.0835 0.0653 0.0571 0.0524 0.0488 0.0459 0.0438 0.0425 0.0413 0.0404 0.0397 0.0392 0.0388 0.0384 0.0383 

[TRAIN] Epoch[5](247/375); Loss: 0.062242; Backpropagation: 0.2887 sec; Batch: 2.0755 sec
0.1111 0.0880 0.0738 0.0675 0.0637 0.0607 0.0582 0.0563 0.0547 0.0535 0.0526 0.0520 0.0514 0.0510 0.0507 0.0505 

[TRAIN] Epoch[5](248/375); Loss: 0.040280; Backpropagation: 0.2889 sec; Batch: 2.0934 sec
0.0799 0.0603 0.0482 0.0431 0.0397 0.0376 0.0361 0.0350 0.0343 0.0338 0.0333 0.0329 0.0327 0.0326 0.0326 0.0325 

[TRAIN] Epoch[5](249/375); Loss: 0.050655; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1197 0.0999 0.0785 0.0617 0.0515 0.0443 0.0409 0.0387 0.0370 0.0358 0.0350 0.0343 0.0338 0.0334 0.0331 0.0329 

[TRAIN] Epoch[5](250/375); Loss: 0.070169; Backpropagation: 0.2883 sec; Batch: 2.0720 sec
0.1184 0.0971 0.0823 0.0753 0.0715 0.0681 0.0656 0.0638 0.0624 0.0614 0.0606 0.0600 0.0596 0.0592 0.0588 0.0586 

[TRAIN] Epoch[5](251/375); Loss: 0.049712; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.1029 0.0790 0.0622 0.0546 0.0505 0.0475 0.0449 0.0429 0.0415 0.0403 0.0394 0.0387 0.0382 0.0379 0.0376 0.0373 

[TRAIN] Epoch[5](252/375); Loss: 0.048839; Backpropagation: 0.2887 sec; Batch: 2.0782 sec
0.1158 0.0970 0.0760 0.0600 0.0504 0.0428 0.0396 0.0372 0.0357 0.0343 0.0334 0.0326 0.0322 0.0318 0.0315 0.0312 

[TRAIN] Epoch[5](253/375); Loss: 0.038998; Backpropagation: 0.2885 sec; Batch: 2.0727 sec
0.0730 0.0586 0.0479 0.0423 0.0394 0.0374 0.0358 0.0346 0.0336 0.0328 0.0322 0.0318 0.0315 0.0312 0.0311 0.0309 

[TRAIN] Epoch[5](254/375); Loss: 0.058582; Backpropagation: 0.2887 sec; Batch: 2.0763 sec
0.0984 0.0798 0.0686 0.0634 0.0601 0.0574 0.0552 0.0535 0.0521 0.0512 0.0506 0.0500 0.0496 0.0494 0.0492 0.0490 

[TRAIN] Epoch[5](255/375); Loss: 0.048778; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.1089 0.0707 0.0585 0.0520 0.0485 0.0457 0.0436 0.0420 0.0409 0.0399 0.0392 0.0387 0.0383 0.0380 0.0378 0.0377 

[TRAIN] Epoch[5](256/375); Loss: 0.036701; Backpropagation: 0.2885 sec; Batch: 2.0722 sec
0.0902 0.0638 0.0479 0.0400 0.0360 0.0335 0.0315 0.0299 0.0286 0.0278 0.0272 0.0267 0.0264 0.0261 0.0259 0.0257 

[TRAIN] Epoch[5](257/375); Loss: 0.062613; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1110 0.0963 0.0771 0.0679 0.0634 0.0600 0.0574 0.0555 0.0541 0.0531 0.0522 0.0516 0.0511 0.0507 0.0503 0.0501 

[TRAIN] Epoch[5](258/375); Loss: 0.060224; Backpropagation: 0.2887 sec; Batch: 2.0789 sec
0.1335 0.1137 0.0904 0.0725 0.0617 0.0536 0.0501 0.0475 0.0457 0.0442 0.0432 0.0425 0.0419 0.0414 0.0410 0.0407 

[TRAIN] Epoch[5](259/375); Loss: 0.038780; Backpropagation: 0.2885 sec; Batch: 2.0767 sec
0.0774 0.0565 0.0469 0.0421 0.0395 0.0372 0.0356 0.0343 0.0332 0.0324 0.0317 0.0313 0.0309 0.0307 0.0304 0.0303 

[TRAIN] Epoch[5](260/375); Loss: 0.041111; Backpropagation: 0.2883 sec; Batch: 2.0715 sec
0.0937 0.0651 0.0512 0.0444 0.0408 0.0383 0.0363 0.0348 0.0336 0.0327 0.0320 0.0315 0.0312 0.0310 0.0307 0.0305 

[TRAIN] Epoch[5](261/375); Loss: 0.052652; Backpropagation: 0.2886 sec; Batch: 2.0759 sec
0.1162 0.0967 0.0737 0.0608 0.0528 0.0487 0.0443 0.0422 0.0408 0.0397 0.0389 0.0383 0.0378 0.0375 0.0372 0.0370 

[TRAIN] Epoch[5](262/375); Loss: 0.048792; Backpropagation: 0.2886 sec; Batch: 2.0765 sec
0.1139 0.0890 0.0699 0.0565 0.0476 0.0441 0.0408 0.0386 0.0374 0.0362 0.0354 0.0348 0.0345 0.0342 0.0339 0.0338 

[TRAIN] Epoch[5](263/375); Loss: 0.040142; Backpropagation: 0.2885 sec; Batch: 2.0728 sec
0.0944 0.0585 0.0462 0.0416 0.0390 0.0371 0.0354 0.0343 0.0335 0.0328 0.0324 0.0320 0.0316 0.0314 0.0312 0.0310 

[TRAIN] Epoch[5](264/375); Loss: 0.048808; Backpropagation: 0.2887 sec; Batch: 2.0828 sec
0.0920 0.0707 0.0606 0.0537 0.0497 0.0473 0.0452 0.0434 0.0421 0.0411 0.0404 0.0398 0.0393 0.0389 0.0386 0.0383 

[TRAIN] Epoch[5](265/375); Loss: 0.044784; Backpropagation: 0.2884 sec; Batch: 2.0787 sec
0.0806 0.0652 0.0543 0.0484 0.0456 0.0430 0.0412 0.0399 0.0389 0.0383 0.0376 0.0372 0.0369 0.0367 0.0365 0.0363 

[TRAIN] Epoch[5](266/375); Loss: 0.040416; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.0822 0.0625 0.0512 0.0456 0.0416 0.0386 0.0366 0.0348 0.0336 0.0328 0.0321 0.0316 0.0312 0.0309 0.0307 0.0305 

[TRAIN] Epoch[5](267/375); Loss: 0.033692; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0787 0.0550 0.0436 0.0370 0.0332 0.0309 0.0293 0.0281 0.0270 0.0262 0.0256 0.0253 0.0250 0.0248 0.0247 0.0246 

[TRAIN] Epoch[5](268/375); Loss: 0.049005; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.1045 0.0788 0.0635 0.0546 0.0485 0.0452 0.0429 0.0412 0.0400 0.0392 0.0385 0.0380 0.0376 0.0374 0.0372 0.0370 

[TRAIN] Epoch[5](269/375); Loss: 0.048393; Backpropagation: 0.2883 sec; Batch: 2.0722 sec
0.0797 0.0665 0.0581 0.0534 0.0501 0.0473 0.0456 0.0441 0.0430 0.0422 0.0416 0.0411 0.0408 0.0405 0.0403 0.0401 

[TRAIN] Epoch[5](270/375); Loss: 0.036285; Backpropagation: 0.2888 sec; Batch: 2.0735 sec
0.0747 0.0470 0.0422 0.0386 0.0364 0.0349 0.0334 0.0323 0.0315 0.0308 0.0304 0.0301 0.0298 0.0296 0.0295 0.0293 

[TRAIN] Epoch[5](271/375); Loss: 0.042904; Backpropagation: 0.2885 sec; Batch: 2.0750 sec
0.0810 0.0648 0.0521 0.0470 0.0437 0.0412 0.0394 0.0379 0.0367 0.0359 0.0353 0.0348 0.0345 0.0342 0.0340 0.0338 

[TRAIN] Epoch[5](272/375); Loss: 0.057180; Backpropagation: 0.2887 sec; Batch: 2.1064 sec
0.1094 0.0841 0.0683 0.0618 0.0580 0.0553 0.0527 0.0507 0.0493 0.0481 0.0473 0.0467 0.0462 0.0459 0.0457 0.0454 

[TRAIN] Epoch[5](273/375); Loss: 0.053474; Backpropagation: 0.2885 sec; Batch: 2.0786 sec
0.1010 0.0815 0.0678 0.0600 0.0551 0.0511 0.0485 0.0467 0.0454 0.0443 0.0435 0.0428 0.0424 0.0420 0.0418 0.0416 

[TRAIN] Epoch[5](274/375); Loss: 0.050668; Backpropagation: 0.2888 sec; Batch: 2.0776 sec
0.0949 0.0749 0.0630 0.0567 0.0523 0.0492 0.0467 0.0448 0.0434 0.0424 0.0415 0.0409 0.0404 0.0401 0.0398 0.0396 

[TRAIN] Epoch[5](275/375); Loss: 0.037550; Backpropagation: 0.2886 sec; Batch: 2.1081 sec
0.0906 0.0595 0.0480 0.0409 0.0369 0.0343 0.0325 0.0312 0.0302 0.0294 0.0288 0.0283 0.0279 0.0276 0.0274 0.0272 

[TRAIN] Epoch[5](276/375); Loss: 0.049065; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.1294 0.0852 0.0641 0.0539 0.0482 0.0443 0.0414 0.0393 0.0377 0.0365 0.0354 0.0347 0.0342 0.0338 0.0335 0.0333 

[TRAIN] Epoch[5](277/375); Loss: 0.044084; Backpropagation: 0.2886 sec; Batch: 2.0772 sec
0.0852 0.0671 0.0549 0.0481 0.0445 0.0420 0.0401 0.0388 0.0377 0.0368 0.0360 0.0355 0.0351 0.0347 0.0345 0.0343 

[TRAIN] Epoch[5](278/375); Loss: 0.061432; Backpropagation: 0.2882 sec; Batch: 2.1012 sec
0.1254 0.1004 0.0808 0.0683 0.0613 0.0574 0.0548 0.0527 0.0507 0.0494 0.0483 0.0476 0.0470 0.0465 0.0462 0.0460 

[TRAIN] Epoch[5](279/375); Loss: 0.056249; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.0985 0.0769 0.0650 0.0593 0.0561 0.0541 0.0525 0.0513 0.0502 0.0494 0.0486 0.0482 0.0478 0.0476 0.0473 0.0472 

[TRAIN] Epoch[5](280/375); Loss: 0.036968; Backpropagation: 0.2887 sec; Batch: 2.0777 sec
0.0834 0.0622 0.0484 0.0417 0.0376 0.0346 0.0326 0.0311 0.0297 0.0287 0.0279 0.0273 0.0269 0.0266 0.0264 0.0262 

[TRAIN] Epoch[5](281/375); Loss: 0.034050; Backpropagation: 0.2887 sec; Batch: 2.1371 sec
0.0747 0.0514 0.0432 0.0373 0.0343 0.0320 0.0303 0.0291 0.0282 0.0274 0.0269 0.0264 0.0262 0.0259 0.0258 0.0257 

[TRAIN] Epoch[5](282/375); Loss: 0.064858; Backpropagation: 0.2887 sec; Batch: 2.0776 sec
0.1401 0.1167 0.0909 0.0739 0.0643 0.0591 0.0559 0.0531 0.0512 0.0499 0.0487 0.0479 0.0472 0.0467 0.0463 0.0459 

[TRAIN] Epoch[5](283/375); Loss: 0.043094; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0814 0.0624 0.0528 0.0482 0.0446 0.0418 0.0397 0.0381 0.0369 0.0361 0.0355 0.0350 0.0346 0.0343 0.0341 0.0339 

[TRAIN] Epoch[5](284/375); Loss: 0.048372; Backpropagation: 0.2886 sec; Batch: 2.0818 sec
0.1034 0.0748 0.0604 0.0531 0.0486 0.0453 0.0430 0.0411 0.0400 0.0391 0.0384 0.0379 0.0376 0.0373 0.0371 0.0369 

[TRAIN] Epoch[5](285/375); Loss: 0.035290; Backpropagation: 0.2891 sec; Batch: 2.1499 sec
0.0915 0.0610 0.0453 0.0377 0.0335 0.0312 0.0295 0.0283 0.0274 0.0267 0.0262 0.0257 0.0254 0.0253 0.0251 0.0250 

[TRAIN] Epoch[5](286/375); Loss: 0.048901; Backpropagation: 0.2887 sec; Batch: 2.0762 sec
0.0904 0.0691 0.0606 0.0544 0.0507 0.0478 0.0457 0.0439 0.0425 0.0414 0.0404 0.0398 0.0394 0.0390 0.0388 0.0386 

[TRAIN] Epoch[5](287/375); Loss: 0.062707; Backpropagation: 0.2885 sec; Batch: 2.1135 sec
0.1156 0.0864 0.0731 0.0662 0.0624 0.0598 0.0579 0.0565 0.0553 0.0543 0.0536 0.0531 0.0527 0.0524 0.0521 0.0519 

[TRAIN] Epoch[5](288/375); Loss: 0.031212; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0817 0.0526 0.0406 0.0337 0.0302 0.0277 0.0261 0.0249 0.0240 0.0235 0.0231 0.0227 0.0224 0.0222 0.0221 0.0220 

[TRAIN] Epoch[5](289/375); Loss: 0.036294; Backpropagation: 0.2886 sec; Batch: 2.0804 sec
0.0791 0.0580 0.0459 0.0391 0.0354 0.0331 0.0317 0.0306 0.0298 0.0292 0.0287 0.0284 0.0281 0.0280 0.0278 0.0278 

[TRAIN] Epoch[5](290/375); Loss: 0.056219; Backpropagation: 0.2888 sec; Batch: 2.0775 sec
0.0957 0.0770 0.0663 0.0616 0.0583 0.0555 0.0532 0.0512 0.0499 0.0488 0.0481 0.0475 0.0471 0.0467 0.0464 0.0462 

[TRAIN] Epoch[5](291/375); Loss: 0.041315; Backpropagation: 0.2886 sec; Batch: 2.0776 sec
0.0795 0.0598 0.0494 0.0447 0.0417 0.0394 0.0378 0.0365 0.0355 0.0348 0.0343 0.0339 0.0337 0.0335 0.0334 0.0333 

[TRAIN] Epoch[5](292/375); Loss: 0.042008; Backpropagation: 0.2888 sec; Batch: 2.0776 sec
0.0939 0.0618 0.0505 0.0449 0.0414 0.0392 0.0374 0.0359 0.0351 0.0344 0.0338 0.0334 0.0331 0.0328 0.0325 0.0323 

[TRAIN] Epoch[5](293/375); Loss: 0.049036; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0773 0.0625 0.0565 0.0528 0.0502 0.0481 0.0467 0.0455 0.0447 0.0440 0.0434 0.0430 0.0428 0.0425 0.0423 0.0422 

[TRAIN] Epoch[5](294/375); Loss: 0.033503; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1020 0.0764 0.0492 0.0369 0.0297 0.0267 0.0249 0.0234 0.0223 0.0216 0.0211 0.0208 0.0205 0.0203 0.0201 0.0200 

[TRAIN] Epoch[5](295/375); Loss: 0.037203; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.0822 0.0633 0.0486 0.0412 0.0374 0.0346 0.0326 0.0309 0.0298 0.0290 0.0285 0.0280 0.0276 0.0274 0.0272 0.0270 

[TRAIN] Epoch[5](296/375); Loss: 0.051220; Backpropagation: 0.2887 sec; Batch: 2.0770 sec
0.1169 0.0856 0.0650 0.0552 0.0506 0.0471 0.0447 0.0428 0.0413 0.0403 0.0396 0.0389 0.0384 0.0380 0.0377 0.0375 

[TRAIN] Epoch[5](297/375); Loss: 0.054407; Backpropagation: 0.2886 sec; Batch: 2.0939 sec
0.1189 0.0884 0.0696 0.0598 0.0549 0.0513 0.0483 0.0461 0.0445 0.0430 0.0422 0.0415 0.0410 0.0406 0.0403 0.0402 

[TRAIN] Epoch[5](298/375); Loss: 0.047751; Backpropagation: 0.2886 sec; Batch: 2.0765 sec
0.0991 0.0739 0.0593 0.0524 0.0484 0.0455 0.0430 0.0412 0.0399 0.0389 0.0382 0.0376 0.0371 0.0368 0.0365 0.0362 

[TRAIN] Epoch[5](299/375); Loss: 0.046714; Backpropagation: 0.2887 sec; Batch: 2.0733 sec
0.0934 0.0739 0.0593 0.0516 0.0478 0.0449 0.0425 0.0406 0.0391 0.0381 0.0372 0.0365 0.0361 0.0357 0.0354 0.0352 

[TRAIN] Epoch[5](300/375); Loss: 0.044056; Backpropagation: 0.2886 sec; Batch: 2.1002 sec
0.0768 0.0629 0.0539 0.0480 0.0450 0.0428 0.0411 0.0399 0.0387 0.0379 0.0372 0.0367 0.0363 0.0361 0.0359 0.0357 

[TRAIN] Epoch[5](301/375); Loss: 0.056738; Backpropagation: 0.2889 sec; Batch: 2.0738 sec
0.0933 0.0768 0.0672 0.0613 0.0585 0.0560 0.0539 0.0523 0.0510 0.0499 0.0491 0.0485 0.0480 0.0476 0.0473 0.0472 

[TRAIN] Epoch[5](302/375); Loss: 0.029237; Backpropagation: 0.2886 sec; Batch: 2.0770 sec
0.0707 0.0519 0.0367 0.0316 0.0289 0.0266 0.0250 0.0238 0.0229 0.0223 0.0218 0.0215 0.0212 0.0211 0.0209 0.0208 

[TRAIN] Epoch[5](303/375); Loss: 0.055713; Backpropagation: 0.2884 sec; Batch: 2.0810 sec
0.1088 0.0863 0.0711 0.0624 0.0575 0.0536 0.0508 0.0488 0.0472 0.0458 0.0447 0.0439 0.0433 0.0427 0.0424 0.0421 

[TRAIN] Epoch[5](304/375); Loss: 0.043086; Backpropagation: 0.2950 sec; Batch: 2.1155 sec
0.1014 0.0818 0.0610 0.0479 0.0420 0.0381 0.0361 0.0343 0.0331 0.0321 0.0313 0.0307 0.0303 0.0300 0.0298 0.0296 

[TRAIN] Epoch[5](305/375); Loss: 0.048965; Backpropagation: 0.2889 sec; Batch: 2.0805 sec
0.1000 0.0747 0.0615 0.0548 0.0505 0.0471 0.0443 0.0423 0.0409 0.0398 0.0390 0.0384 0.0379 0.0376 0.0374 0.0372 

[TRAIN] Epoch[5](306/375); Loss: 0.059531; Backpropagation: 0.2886 sec; Batch: 2.0776 sec
0.1090 0.0860 0.0730 0.0648 0.0608 0.0577 0.0551 0.0531 0.0517 0.0506 0.0498 0.0491 0.0485 0.0481 0.0478 0.0475 

[TRAIN] Epoch[5](307/375); Loss: 0.050736; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.0963 0.0745 0.0624 0.0562 0.0523 0.0492 0.0467 0.0450 0.0437 0.0425 0.0416 0.0410 0.0406 0.0402 0.0399 0.0398 

[TRAIN] Epoch[5](308/375); Loss: 0.040424; Backpropagation: 0.2886 sec; Batch: 2.0775 sec
0.0908 0.0700 0.0529 0.0438 0.0402 0.0374 0.0354 0.0338 0.0325 0.0314 0.0307 0.0302 0.0298 0.0295 0.0293 0.0291 

[TRAIN] Epoch[5](309/375); Loss: 0.056642; Backpropagation: 0.2882 sec; Batch: 2.0778 sec
0.1018 0.0816 0.0686 0.0619 0.0581 0.0550 0.0528 0.0509 0.0495 0.0484 0.0476 0.0468 0.0463 0.0459 0.0456 0.0454 

[TRAIN] Epoch[5](310/375); Loss: 0.047727; Backpropagation: 0.2887 sec; Batch: 2.0781 sec
0.0957 0.0702 0.0594 0.0524 0.0484 0.0456 0.0433 0.0416 0.0406 0.0396 0.0389 0.0383 0.0379 0.0375 0.0372 0.0371 

[TRAIN] Epoch[5](311/375); Loss: 0.037969; Backpropagation: 0.2883 sec; Batch: 2.0772 sec
0.0864 0.0639 0.0479 0.0412 0.0380 0.0352 0.0332 0.0317 0.0306 0.0298 0.0292 0.0286 0.0283 0.0280 0.0278 0.0277 

[TRAIN] Epoch[5](312/375); Loss: 0.043520; Backpropagation: 0.2887 sec; Batch: 2.0761 sec
0.0998 0.0715 0.0543 0.0475 0.0432 0.0402 0.0381 0.0366 0.0353 0.0343 0.0335 0.0331 0.0326 0.0323 0.0321 0.0319 

[TRAIN] Epoch[5](313/375); Loss: 0.037178; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.0732 0.0565 0.0458 0.0407 0.0375 0.0356 0.0338 0.0325 0.0315 0.0308 0.0303 0.0299 0.0296 0.0293 0.0291 0.0290 

[TRAIN] Epoch[5](314/375); Loss: 0.057010; Backpropagation: 0.2887 sec; Batch: 2.0901 sec
0.1238 0.1051 0.0810 0.0628 0.0547 0.0512 0.0481 0.0464 0.0450 0.0437 0.0428 0.0422 0.0417 0.0414 0.0412 0.0410 

[TRAIN] Epoch[5](315/375); Loss: 0.044723; Backpropagation: 0.2884 sec; Batch: 2.0775 sec
0.0914 0.0675 0.0557 0.0490 0.0455 0.0426 0.0404 0.0389 0.0376 0.0367 0.0361 0.0355 0.0351 0.0348 0.0345 0.0343 

[TRAIN] Epoch[5](316/375); Loss: 0.046874; Backpropagation: 0.2889 sec; Batch: 2.0782 sec
0.0926 0.0619 0.0549 0.0491 0.0460 0.0443 0.0428 0.0417 0.0409 0.0404 0.0399 0.0395 0.0393 0.0390 0.0388 0.0387 

[TRAIN] Epoch[5](317/375); Loss: 0.044619; Backpropagation: 0.2887 sec; Batch: 2.1053 sec
0.0854 0.0641 0.0537 0.0486 0.0450 0.0427 0.0411 0.0397 0.0385 0.0377 0.0371 0.0367 0.0363 0.0360 0.0358 0.0356 

[TRAIN] Epoch[5](318/375); Loss: 0.039250; Backpropagation: 0.2881 sec; Batch: 2.0961 sec
0.0797 0.0559 0.0470 0.0428 0.0400 0.0377 0.0359 0.0346 0.0335 0.0328 0.0322 0.0317 0.0314 0.0312 0.0310 0.0308 

[TRAIN] Epoch[5](319/375); Loss: 0.044105; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.0956 0.0666 0.0518 0.0468 0.0435 0.0411 0.0394 0.0381 0.0371 0.0363 0.0357 0.0352 0.0350 0.0348 0.0345 0.0344 

[TRAIN] Epoch[5](320/375); Loss: 0.060211; Backpropagation: 0.2881 sec; Batch: 2.0767 sec
0.1111 0.0842 0.0724 0.0660 0.0616 0.0581 0.0557 0.0540 0.0526 0.0516 0.0507 0.0499 0.0494 0.0490 0.0487 0.0484 

[TRAIN] Epoch[5](321/375); Loss: 0.063676; Backpropagation: 0.2947 sec; Batch: 2.0978 sec
0.1176 0.0901 0.0770 0.0693 0.0650 0.0617 0.0592 0.0572 0.0555 0.0542 0.0533 0.0526 0.0521 0.0517 0.0513 0.0510 

[TRAIN] Epoch[5](322/375); Loss: 0.044104; Backpropagation: 0.2905 sec; Batch: 2.0806 sec
0.1107 0.0756 0.0573 0.0473 0.0422 0.0393 0.0371 0.0356 0.0345 0.0337 0.0330 0.0325 0.0321 0.0318 0.0316 0.0315 

[TRAIN] Epoch[5](323/375); Loss: 0.039388; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.0882 0.0609 0.0491 0.0427 0.0395 0.0369 0.0352 0.0337 0.0325 0.0316 0.0310 0.0304 0.0300 0.0297 0.0295 0.0294 

[TRAIN] Epoch[5](324/375); Loss: 0.034465; Backpropagation: 0.2882 sec; Batch: 2.0796 sec
0.0830 0.0551 0.0435 0.0373 0.0335 0.0312 0.0297 0.0288 0.0279 0.0271 0.0266 0.0261 0.0257 0.0255 0.0253 0.0252 

[TRAIN] Epoch[5](325/375); Loss: 0.042711; Backpropagation: 0.2888 sec; Batch: 2.0765 sec
0.0859 0.0655 0.0520 0.0465 0.0428 0.0401 0.0383 0.0370 0.0362 0.0354 0.0348 0.0343 0.0339 0.0337 0.0335 0.0334 

[TRAIN] Epoch[5](326/375); Loss: 0.048182; Backpropagation: 0.2887 sec; Batch: 2.0914 sec
0.0847 0.0649 0.0573 0.0525 0.0494 0.0469 0.0450 0.0436 0.0425 0.0418 0.0412 0.0407 0.0404 0.0402 0.0400 0.0399 

[TRAIN] Epoch[5](327/375); Loss: 0.061769; Backpropagation: 0.2882 sec; Batch: 2.0766 sec
0.1085 0.0861 0.0736 0.0670 0.0629 0.0598 0.0575 0.0557 0.0544 0.0534 0.0526 0.0520 0.0516 0.0513 0.0510 0.0508 

[TRAIN] Epoch[5](328/375); Loss: 0.045333; Backpropagation: 0.2887 sec; Batch: 2.0818 sec
0.1198 0.1038 0.0705 0.0489 0.0403 0.0376 0.0351 0.0332 0.0317 0.0307 0.0300 0.0295 0.0290 0.0287 0.0285 0.0283 

[TRAIN] Epoch[5](329/375); Loss: 0.026947; Backpropagation: 0.2882 sec; Batch: 2.0759 sec
0.0596 0.0399 0.0320 0.0279 0.0260 0.0247 0.0237 0.0231 0.0226 0.0222 0.0219 0.0217 0.0216 0.0214 0.0214 0.0213 

[TRAIN] Epoch[5](330/375); Loss: 0.054444; Backpropagation: 0.2886 sec; Batch: 2.0801 sec
0.1079 0.0795 0.0629 0.0565 0.0534 0.0514 0.0496 0.0482 0.0471 0.0462 0.0456 0.0451 0.0448 0.0445 0.0443 0.0441 

[TRAIN] Epoch[5](331/375); Loss: 0.051974; Backpropagation: 0.2882 sec; Batch: 2.0774 sec
0.0988 0.0770 0.0638 0.0568 0.0530 0.0499 0.0478 0.0461 0.0446 0.0436 0.0429 0.0423 0.0418 0.0413 0.0411 0.0408 

[TRAIN] Epoch[5](332/375); Loss: 0.067188; Backpropagation: 0.2881 sec; Batch: 2.0889 sec
0.1330 0.1102 0.0861 0.0729 0.0667 0.0630 0.0600 0.0579 0.0561 0.0548 0.0539 0.0531 0.0524 0.0519 0.0516 0.0514 

[TRAIN] Epoch[5](333/375); Loss: 0.041138; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.0929 0.0677 0.0517 0.0443 0.0407 0.0378 0.0357 0.0342 0.0332 0.0325 0.0321 0.0316 0.0313 0.0310 0.0308 0.0306 

[TRAIN] Epoch[5](334/375); Loss: 0.030673; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0704 0.0523 0.0392 0.0332 0.0303 0.0280 0.0265 0.0254 0.0245 0.0239 0.0235 0.0231 0.0228 0.0226 0.0225 0.0224 

[TRAIN] Epoch[5](335/375); Loss: 0.043141; Backpropagation: 0.2882 sec; Batch: 2.0766 sec
0.0798 0.0583 0.0504 0.0464 0.0438 0.0418 0.0401 0.0389 0.0379 0.0372 0.0366 0.0363 0.0359 0.0357 0.0355 0.0355 

[TRAIN] Epoch[5](336/375); Loss: 0.042548; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.0783 0.0610 0.0505 0.0465 0.0435 0.0411 0.0393 0.0379 0.0369 0.0362 0.0358 0.0353 0.0350 0.0347 0.0345 0.0343 

[TRAIN] Epoch[5](337/375); Loss: 0.028769; Backpropagation: 0.2883 sec; Batch: 2.0765 sec
0.0801 0.0520 0.0405 0.0309 0.0274 0.0252 0.0237 0.0224 0.0214 0.0207 0.0201 0.0197 0.0194 0.0191 0.0189 0.0188 

[TRAIN] Epoch[5](338/375); Loss: 0.044150; Backpropagation: 0.2886 sec; Batch: 2.0776 sec
0.1035 0.0704 0.0547 0.0482 0.0442 0.0411 0.0388 0.0370 0.0358 0.0348 0.0340 0.0334 0.0330 0.0327 0.0324 0.0322 

[TRAIN] Epoch[5](339/375); Loss: 0.051081; Backpropagation: 0.2883 sec; Batch: 2.1014 sec
0.1076 0.0823 0.0627 0.0557 0.0511 0.0478 0.0453 0.0437 0.0423 0.0413 0.0406 0.0400 0.0396 0.0393 0.0391 0.0389 

[TRAIN] Epoch[5](340/375); Loss: 0.040695; Backpropagation: 0.2896 sec; Batch: 2.0797 sec
0.0988 0.0749 0.0548 0.0444 0.0395 0.0358 0.0339 0.0325 0.0313 0.0306 0.0299 0.0295 0.0291 0.0289 0.0287 0.0285 

[TRAIN] Epoch[5](341/375); Loss: 0.056519; Backpropagation: 0.2885 sec; Batch: 2.0773 sec
0.1162 0.0839 0.0675 0.0611 0.0567 0.0535 0.0511 0.0492 0.0477 0.0468 0.0460 0.0456 0.0452 0.0448 0.0446 0.0445 

[TRAIN] Epoch[5](342/375); Loss: 0.042250; Backpropagation: 0.2881 sec; Batch: 2.0741 sec
0.0920 0.0671 0.0528 0.0465 0.0426 0.0395 0.0376 0.0360 0.0348 0.0338 0.0331 0.0326 0.0322 0.0319 0.0317 0.0316 

[TRAIN] Epoch[5](343/375); Loss: 0.063494; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.1052 0.0896 0.0766 0.0687 0.0649 0.0616 0.0594 0.0578 0.0565 0.0553 0.0546 0.0540 0.0534 0.0530 0.0527 0.0525 

[TRAIN] Epoch[5](344/375); Loss: 0.029634; Backpropagation: 0.2886 sec; Batch: 2.0820 sec
0.0837 0.0587 0.0390 0.0302 0.0265 0.0247 0.0233 0.0224 0.0217 0.0212 0.0209 0.0206 0.0204 0.0203 0.0203 0.0202 

[TRAIN] Epoch[5](345/375); Loss: 0.061904; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.1168 0.0916 0.0761 0.0666 0.0623 0.0592 0.0567 0.0548 0.0532 0.0522 0.0514 0.0507 0.0502 0.0498 0.0496 0.0494 

[TRAIN] Epoch[5](346/375); Loss: 0.051573; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.1087 0.0800 0.0626 0.0543 0.0507 0.0486 0.0463 0.0446 0.0434 0.0424 0.0416 0.0411 0.0406 0.0403 0.0401 0.0400 

[TRAIN] Epoch[5](347/375); Loss: 0.043807; Backpropagation: 0.2883 sec; Batch: 2.0874 sec
0.0897 0.0679 0.0551 0.0488 0.0450 0.0418 0.0395 0.0378 0.0366 0.0358 0.0350 0.0344 0.0339 0.0335 0.0333 0.0330 

[TRAIN] Epoch[5](348/375); Loss: 0.051604; Backpropagation: 0.2887 sec; Batch: 2.0808 sec
0.1107 0.0831 0.0650 0.0569 0.0518 0.0484 0.0459 0.0439 0.0425 0.0414 0.0405 0.0399 0.0394 0.0390 0.0387 0.0384 

[TRAIN] Epoch[5](349/375); Loss: 0.058200; Backpropagation: 0.2882 sec; Batch: 2.0770 sec
0.0916 0.0811 0.0693 0.0633 0.0600 0.0573 0.0551 0.0534 0.0522 0.0513 0.0505 0.0499 0.0495 0.0492 0.0489 0.0488 

[TRAIN] Epoch[5](350/375); Loss: 0.045671; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.0882 0.0672 0.0553 0.0499 0.0465 0.0440 0.0420 0.0404 0.0392 0.0382 0.0376 0.0371 0.0367 0.0365 0.0362 0.0360 

[TRAIN] Epoch[5](351/375); Loss: 0.047648; Backpropagation: 0.2885 sec; Batch: 2.0777 sec
0.0933 0.0663 0.0552 0.0500 0.0472 0.0451 0.0434 0.0422 0.0414 0.0408 0.0403 0.0400 0.0396 0.0393 0.0392 0.0390 

[TRAIN] Epoch[5](352/375); Loss: 0.040886; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0868 0.0655 0.0539 0.0454 0.0412 0.0384 0.0363 0.0347 0.0336 0.0328 0.0320 0.0314 0.0310 0.0306 0.0304 0.0303 

[TRAIN] Epoch[5](353/375); Loss: 0.049740; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0912 0.0695 0.0598 0.0545 0.0507 0.0479 0.0458 0.0443 0.0433 0.0426 0.0420 0.0415 0.0411 0.0408 0.0406 0.0404 

[TRAIN] Epoch[5](354/375); Loss: 0.045091; Backpropagation: 0.2883 sec; Batch: 2.0879 sec
0.0839 0.0665 0.0561 0.0495 0.0459 0.0434 0.0415 0.0400 0.0387 0.0379 0.0372 0.0367 0.0364 0.0361 0.0359 0.0357 

[TRAIN] Epoch[5](355/375); Loss: 0.038061; Backpropagation: 0.2883 sec; Batch: 2.0766 sec
0.0852 0.0556 0.0464 0.0414 0.0382 0.0358 0.0339 0.0326 0.0316 0.0308 0.0303 0.0299 0.0296 0.0294 0.0292 0.0291 

[TRAIN] Epoch[5](356/375); Loss: 0.044642; Backpropagation: 0.2887 sec; Batch: 2.0783 sec
0.0996 0.0670 0.0537 0.0474 0.0438 0.0417 0.0400 0.0386 0.0375 0.0366 0.0359 0.0352 0.0347 0.0344 0.0342 0.0340 

[TRAIN] Epoch[5](357/375); Loss: 0.044465; Backpropagation: 0.2885 sec; Batch: 2.0781 sec
0.0902 0.0654 0.0544 0.0486 0.0450 0.0425 0.0404 0.0389 0.0377 0.0368 0.0361 0.0356 0.0353 0.0350 0.0347 0.0346 

[TRAIN] Epoch[5](358/375); Loss: 0.056117; Backpropagation: 0.2880 sec; Batch: 2.0805 sec
0.1063 0.0854 0.0691 0.0603 0.0564 0.0536 0.0513 0.0496 0.0482 0.0471 0.0463 0.0456 0.0451 0.0447 0.0445 0.0443 

[TRAIN] Epoch[5](359/375); Loss: 0.061814; Backpropagation: 0.2886 sec; Batch: 2.0794 sec
0.1143 0.0905 0.0749 0.0673 0.0631 0.0597 0.0570 0.0551 0.0537 0.0525 0.0517 0.0509 0.0502 0.0497 0.0494 0.0492 

[TRAIN] Epoch[5](360/375); Loss: 0.041825; Backpropagation: 0.2883 sec; Batch: 2.0757 sec
0.0909 0.0632 0.0521 0.0454 0.0423 0.0396 0.0375 0.0360 0.0348 0.0339 0.0332 0.0327 0.0323 0.0320 0.0318 0.0316 

[TRAIN] Epoch[5](361/375); Loss: 0.042063; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.0918 0.0675 0.0525 0.0465 0.0426 0.0395 0.0373 0.0358 0.0346 0.0336 0.0329 0.0323 0.0319 0.0316 0.0314 0.0312 

[TRAIN] Epoch[5](362/375); Loss: 0.051626; Backpropagation: 0.2886 sec; Batch: 2.0771 sec
0.1219 0.0974 0.0734 0.0560 0.0475 0.0443 0.0422 0.0409 0.0398 0.0389 0.0382 0.0377 0.0373 0.0370 0.0368 0.0366 

[TRAIN] Epoch[5](363/375); Loss: 0.042203; Backpropagation: 0.2882 sec; Batch: 2.0765 sec
0.0773 0.0617 0.0520 0.0465 0.0435 0.0411 0.0392 0.0377 0.0366 0.0357 0.0350 0.0344 0.0340 0.0337 0.0335 0.0333 

[TRAIN] Epoch[5](364/375); Loss: 0.034331; Backpropagation: 0.2880 sec; Batch: 2.0780 sec
0.0731 0.0508 0.0414 0.0362 0.0336 0.0319 0.0305 0.0296 0.0290 0.0285 0.0281 0.0278 0.0275 0.0273 0.0271 0.0271 

[TRAIN] Epoch[5](365/375); Loss: 0.056545; Backpropagation: 0.2940 sec; Batch: 2.1072 sec
0.1036 0.0849 0.0719 0.0647 0.0596 0.0561 0.0530 0.0502 0.0483 0.0467 0.0456 0.0448 0.0443 0.0439 0.0436 0.0434 

[TRAIN] Epoch[5](366/375); Loss: 0.055209; Backpropagation: 0.2884 sec; Batch: 2.0767 sec
0.1058 0.0806 0.0667 0.0597 0.0559 0.0531 0.0509 0.0490 0.0477 0.0467 0.0458 0.0451 0.0446 0.0443 0.0439 0.0437 

[TRAIN] Epoch[5](367/375); Loss: 0.038978; Backpropagation: 0.2884 sec; Batch: 2.0740 sec
0.0841 0.0625 0.0489 0.0417 0.0383 0.0359 0.0344 0.0332 0.0322 0.0314 0.0309 0.0304 0.0301 0.0299 0.0298 0.0297 

[TRAIN] Epoch[5](368/375); Loss: 0.045677; Backpropagation: 0.2879 sec; Batch: 2.0764 sec
0.0964 0.0710 0.0593 0.0519 0.0468 0.0432 0.0407 0.0390 0.0375 0.0366 0.0358 0.0352 0.0348 0.0345 0.0342 0.0341 

[TRAIN] Epoch[5](369/375); Loss: 0.060567; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1089 0.0893 0.0744 0.0667 0.0619 0.0584 0.0559 0.0540 0.0525 0.0514 0.0505 0.0499 0.0493 0.0489 0.0486 0.0484 

[TRAIN] Epoch[5](370/375); Loss: 0.035141; Backpropagation: 0.2882 sec; Batch: 2.0773 sec
0.0856 0.0603 0.0460 0.0385 0.0345 0.0317 0.0298 0.0286 0.0276 0.0269 0.0263 0.0259 0.0255 0.0252 0.0250 0.0249 

[TRAIN] Epoch[5](371/375); Loss: 0.055497; Backpropagation: 0.2881 sec; Batch: 2.0780 sec
0.1002 0.0771 0.0660 0.0603 0.0567 0.0540 0.0518 0.0501 0.0488 0.0479 0.0471 0.0464 0.0459 0.0455 0.0452 0.0450 

[TRAIN] Epoch[5](372/375); Loss: 0.034314; Backpropagation: 0.2880 sec; Batch: 2.0737 sec
0.0749 0.0550 0.0437 0.0379 0.0344 0.0318 0.0301 0.0289 0.0280 0.0272 0.0267 0.0264 0.0262 0.0260 0.0258 0.0258 

[TRAIN] Epoch[5](373/375); Loss: 0.036350; Backpropagation: 0.2880 sec; Batch: 2.0763 sec
0.0707 0.0517 0.0427 0.0392 0.0367 0.0346 0.0332 0.0323 0.0316 0.0309 0.0304 0.0300 0.0297 0.0294 0.0293 0.0291 

[TRAIN] Epoch[5](374/375); Loss: 0.032183; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.0774 0.0569 0.0436 0.0364 0.0323 0.0293 0.0272 0.0259 0.0249 0.0241 0.0236 0.0232 0.0229 0.0226 0.0224 0.0222 

[TRAIN] Epoch[5](375/375); Loss: 0.051765; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1053 0.0801 0.0657 0.0560 0.0512 0.0480 0.0461 0.0445 0.0433 0.0425 0.0419 0.0413 0.0409 0.0407 0.0405 0.0403 

[TRAIN] Epoch[6](1/375); Loss: 0.030112; Backpropagation: 0.3023 sec; Batch: 2.1441 sec
0.0666 0.0479 0.0379 0.0330 0.0301 0.0281 0.0266 0.0255 0.0246 0.0241 0.0236 0.0232 0.0229 0.0227 0.0226 0.0224 

[TRAIN] Epoch[6](2/375); Loss: 0.069119; Backpropagation: 0.2886 sec; Batch: 2.0846 sec
0.1280 0.1021 0.0848 0.0753 0.0701 0.0665 0.0634 0.0614 0.0598 0.0586 0.0575 0.0567 0.0560 0.0556 0.0552 0.0550 

[TRAIN] Epoch[6](3/375); Loss: 0.046971; Backpropagation: 0.2883 sec; Batch: 2.0832 sec
0.0854 0.0668 0.0566 0.0509 0.0475 0.0451 0.0433 0.0420 0.0412 0.0404 0.0397 0.0391 0.0387 0.0385 0.0383 0.0381 

[TRAIN] Epoch[6](4/375); Loss: 0.033670; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.0829 0.0556 0.0423 0.0359 0.0325 0.0303 0.0288 0.0277 0.0267 0.0262 0.0256 0.0253 0.0250 0.0248 0.0246 0.0245 

[TRAIN] Epoch[6](5/375); Loss: 0.048077; Backpropagation: 0.2885 sec; Batch: 2.0832 sec
0.1005 0.0704 0.0579 0.0518 0.0483 0.0455 0.0435 0.0420 0.0407 0.0398 0.0391 0.0385 0.0382 0.0379 0.0377 0.0375 

[TRAIN] Epoch[6](6/375); Loss: 0.058271; Backpropagation: 0.2889 sec; Batch: 2.0735 sec
0.1035 0.0840 0.0714 0.0641 0.0598 0.0566 0.0541 0.0522 0.0507 0.0496 0.0488 0.0482 0.0478 0.0474 0.0471 0.0469 

[TRAIN] Epoch[6](7/375); Loss: 0.042024; Backpropagation: 0.2889 sec; Batch: 2.0750 sec
0.0857 0.0654 0.0517 0.0453 0.0418 0.0393 0.0377 0.0364 0.0354 0.0346 0.0339 0.0335 0.0332 0.0330 0.0328 0.0326 

[TRAIN] Epoch[6](8/375); Loss: 0.039330; Backpropagation: 0.2887 sec; Batch: 2.0739 sec
0.0739 0.0568 0.0474 0.0416 0.0390 0.0373 0.0359 0.0350 0.0342 0.0336 0.0331 0.0327 0.0325 0.0322 0.0321 0.0319 

[TRAIN] Epoch[6](9/375); Loss: 0.048885; Backpropagation: 0.2935 sec; Batch: 2.0800 sec
0.1024 0.0775 0.0619 0.0536 0.0490 0.0462 0.0438 0.0421 0.0407 0.0396 0.0388 0.0381 0.0376 0.0372 0.0369 0.0367 

[TRAIN] Epoch[6](10/375); Loss: 0.048784; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0949 0.0703 0.0596 0.0524 0.0489 0.0467 0.0447 0.0433 0.0420 0.0411 0.0404 0.0399 0.0395 0.0391 0.0389 0.0387 

[TRAIN] Epoch[6](11/375); Loss: 0.033138; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0863 0.0567 0.0418 0.0354 0.0322 0.0300 0.0284 0.0270 0.0260 0.0252 0.0244 0.0239 0.0236 0.0233 0.0231 0.0230 

[TRAIN] Epoch[6](12/375); Loss: 0.061724; Backpropagation: 0.2914 sec; Batch: 2.0871 sec
0.1115 0.0885 0.0764 0.0693 0.0646 0.0608 0.0578 0.0555 0.0535 0.0520 0.0509 0.0503 0.0498 0.0493 0.0489 0.0485 

[TRAIN] Epoch[6](13/375); Loss: 0.056147; Backpropagation: 0.2880 sec; Batch: 2.0731 sec
0.0942 0.0749 0.0660 0.0611 0.0577 0.0550 0.0531 0.0515 0.0503 0.0493 0.0486 0.0480 0.0476 0.0472 0.0470 0.0468 

[TRAIN] Epoch[6](14/375); Loss: 0.043107; Backpropagation: 0.2940 sec; Batch: 2.0790 sec
0.0883 0.0655 0.0548 0.0477 0.0436 0.0407 0.0388 0.0375 0.0363 0.0353 0.0345 0.0339 0.0336 0.0333 0.0331 0.0329 

[TRAIN] Epoch[6](15/375); Loss: 0.050872; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.0848 0.0711 0.0618 0.0562 0.0524 0.0498 0.0476 0.0460 0.0450 0.0441 0.0435 0.0430 0.0426 0.0423 0.0420 0.0418 

[TRAIN] Epoch[6](16/375); Loss: 0.049468; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.0854 0.0651 0.0578 0.0537 0.0508 0.0484 0.0466 0.0452 0.0441 0.0433 0.0427 0.0423 0.0419 0.0416 0.0414 0.0413 

[TRAIN] Epoch[6](17/375); Loss: 0.047933; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0891 0.0718 0.0592 0.0518 0.0478 0.0454 0.0436 0.0422 0.0413 0.0406 0.0399 0.0394 0.0390 0.0388 0.0385 0.0383 

[TRAIN] Epoch[6](18/375); Loss: 0.060649; Backpropagation: 0.2888 sec; Batch: 2.0747 sec
0.1118 0.0862 0.0739 0.0660 0.0616 0.0585 0.0559 0.0541 0.0527 0.0517 0.0509 0.0502 0.0497 0.0493 0.0490 0.0489 

[TRAIN] Epoch[6](19/375); Loss: 0.053912; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.1067 0.0825 0.0665 0.0593 0.0548 0.0515 0.0491 0.0472 0.0458 0.0446 0.0437 0.0430 0.0425 0.0421 0.0418 0.0416 

[TRAIN] Epoch[6](20/375); Loss: 0.038537; Backpropagation: 0.2888 sec; Batch: 2.0733 sec
0.0860 0.0594 0.0494 0.0431 0.0386 0.0352 0.0335 0.0322 0.0313 0.0306 0.0302 0.0299 0.0296 0.0294 0.0291 0.0290 

[TRAIN] Epoch[6](21/375); Loss: 0.046458; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.1055 0.0866 0.0638 0.0527 0.0462 0.0419 0.0390 0.0372 0.0359 0.0349 0.0342 0.0337 0.0333 0.0330 0.0328 0.0326 

[TRAIN] Epoch[6](22/375); Loss: 0.053783; Backpropagation: 0.2883 sec; Batch: 2.0809 sec
0.1068 0.0838 0.0676 0.0587 0.0540 0.0508 0.0484 0.0468 0.0455 0.0444 0.0436 0.0428 0.0423 0.0419 0.0416 0.0414 

[TRAIN] Epoch[6](23/375); Loss: 0.057747; Backpropagation: 0.2887 sec; Batch: 2.0749 sec
0.1066 0.0836 0.0703 0.0629 0.0590 0.0558 0.0534 0.0514 0.0500 0.0490 0.0482 0.0475 0.0470 0.0467 0.0464 0.0462 

[TRAIN] Epoch[6](24/375); Loss: 0.044446; Backpropagation: 0.2883 sec; Batch: 2.0768 sec
0.0892 0.0657 0.0582 0.0498 0.0449 0.0418 0.0400 0.0384 0.0373 0.0364 0.0357 0.0353 0.0350 0.0347 0.0345 0.0344 

[TRAIN] Epoch[6](25/375); Loss: 0.046200; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1052 0.0754 0.0614 0.0535 0.0480 0.0440 0.0410 0.0386 0.0368 0.0356 0.0347 0.0339 0.0333 0.0329 0.0325 0.0323 

[TRAIN] Epoch[6](26/375); Loss: 0.061192; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0928 0.0798 0.0726 0.0670 0.0636 0.0609 0.0589 0.0571 0.0558 0.0547 0.0538 0.0531 0.0527 0.0523 0.0521 0.0519 

[TRAIN] Epoch[6](27/375); Loss: 0.032728; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.0725 0.0490 0.0412 0.0364 0.0334 0.0311 0.0292 0.0277 0.0268 0.0262 0.0256 0.0253 0.0251 0.0248 0.0247 0.0246 

[TRAIN] Epoch[6](28/375); Loss: 0.051373; Backpropagation: 0.2888 sec; Batch: 2.0744 sec
0.0832 0.0677 0.0607 0.0555 0.0528 0.0504 0.0486 0.0473 0.0463 0.0455 0.0449 0.0444 0.0440 0.0438 0.0436 0.0434 

[TRAIN] Epoch[6](29/375); Loss: 0.039659; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0820 0.0631 0.0517 0.0448 0.0407 0.0378 0.0355 0.0339 0.0327 0.0317 0.0310 0.0305 0.0302 0.0299 0.0296 0.0294 

[TRAIN] Epoch[6](30/375); Loss: 0.053221; Backpropagation: 0.2881 sec; Batch: 2.0731 sec
0.1076 0.0848 0.0668 0.0581 0.0537 0.0506 0.0483 0.0463 0.0446 0.0434 0.0426 0.0418 0.0412 0.0409 0.0405 0.0403 

[TRAIN] Epoch[6](31/375); Loss: 0.051542; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.1160 0.0823 0.0653 0.0568 0.0519 0.0482 0.0456 0.0436 0.0420 0.0409 0.0400 0.0392 0.0387 0.0383 0.0380 0.0378 

[TRAIN] Epoch[6](32/375); Loss: 0.045290; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0984 0.0711 0.0568 0.0490 0.0450 0.0420 0.0398 0.0383 0.0372 0.0364 0.0359 0.0355 0.0352 0.0349 0.0347 0.0345 

[TRAIN] Epoch[6](33/375); Loss: 0.051709; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.1015 0.0803 0.0662 0.0588 0.0541 0.0502 0.0473 0.0450 0.0434 0.0422 0.0413 0.0404 0.0398 0.0393 0.0390 0.0387 

[TRAIN] Epoch[6](34/375); Loss: 0.043571; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.0826 0.0646 0.0520 0.0464 0.0432 0.0409 0.0394 0.0384 0.0376 0.0370 0.0365 0.0362 0.0358 0.0357 0.0355 0.0354 

[TRAIN] Epoch[6](35/375); Loss: 0.047873; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.0938 0.0675 0.0587 0.0528 0.0487 0.0459 0.0438 0.0423 0.0410 0.0401 0.0394 0.0389 0.0386 0.0383 0.0381 0.0379 

[TRAIN] Epoch[6](36/375); Loss: 0.043117; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.0983 0.0714 0.0560 0.0463 0.0419 0.0393 0.0372 0.0356 0.0347 0.0339 0.0334 0.0330 0.0326 0.0323 0.0320 0.0319 

[TRAIN] Epoch[6](37/375); Loss: 0.050558; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1015 0.0827 0.0641 0.0563 0.0517 0.0480 0.0455 0.0435 0.0420 0.0408 0.0400 0.0393 0.0389 0.0385 0.0382 0.0380 

[TRAIN] Epoch[6](38/375); Loss: 0.067487; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1230 0.0968 0.0827 0.0744 0.0696 0.0659 0.0626 0.0602 0.0586 0.0572 0.0563 0.0555 0.0549 0.0544 0.0540 0.0538 

[TRAIN] Epoch[6](39/375); Loss: 0.046534; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0759 0.0623 0.0547 0.0492 0.0469 0.0449 0.0436 0.0426 0.0417 0.0412 0.0409 0.0406 0.0403 0.0401 0.0399 0.0398 

[TRAIN] Epoch[6](40/375); Loss: 0.037040; Backpropagation: 0.2896 sec; Batch: 2.0757 sec
0.0788 0.0559 0.0466 0.0405 0.0375 0.0349 0.0332 0.0318 0.0309 0.0302 0.0295 0.0291 0.0288 0.0285 0.0283 0.0281 

[TRAIN] Epoch[6](41/375); Loss: 0.047578; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.0961 0.0746 0.0600 0.0527 0.0484 0.0455 0.0432 0.0415 0.0399 0.0389 0.0380 0.0374 0.0368 0.0364 0.0361 0.0359 

[TRAIN] Epoch[6](42/375); Loss: 0.054776; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.1188 0.0923 0.0721 0.0609 0.0548 0.0510 0.0482 0.0461 0.0444 0.0430 0.0421 0.0414 0.0408 0.0405 0.0401 0.0398 

[TRAIN] Epoch[6](43/375); Loss: 0.029442; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0620 0.0481 0.0387 0.0330 0.0291 0.0268 0.0255 0.0246 0.0240 0.0235 0.0231 0.0229 0.0227 0.0225 0.0223 0.0223 

[TRAIN] Epoch[6](44/375); Loss: 0.022340; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0614 0.0400 0.0283 0.0236 0.0210 0.0193 0.0183 0.0176 0.0170 0.0166 0.0162 0.0159 0.0157 0.0156 0.0155 0.0154 

[TRAIN] Epoch[6](45/375); Loss: 0.062722; Backpropagation: 0.2888 sec; Batch: 2.0751 sec
0.1206 0.0921 0.0760 0.0684 0.0643 0.0609 0.0580 0.0557 0.0540 0.0526 0.0516 0.0507 0.0502 0.0498 0.0494 0.0493 

[TRAIN] Epoch[6](46/375); Loss: 0.054868; Backpropagation: 0.2886 sec; Batch: 2.0804 sec
0.1094 0.0804 0.0673 0.0601 0.0558 0.0524 0.0500 0.0482 0.0468 0.0457 0.0448 0.0442 0.0437 0.0433 0.0429 0.0428 

[TRAIN] Epoch[6](47/375); Loss: 0.050703; Backpropagation: 0.2886 sec; Batch: 2.0751 sec
0.1114 0.0806 0.0662 0.0564 0.0512 0.0475 0.0450 0.0428 0.0415 0.0405 0.0395 0.0387 0.0381 0.0376 0.0372 0.0370 

[TRAIN] Epoch[6](48/375); Loss: 0.042879; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.0907 0.0686 0.0566 0.0479 0.0434 0.0402 0.0380 0.0364 0.0353 0.0343 0.0335 0.0329 0.0325 0.0322 0.0320 0.0318 

[TRAIN] Epoch[6](49/375); Loss: 0.018282; Backpropagation: 0.2885 sec; Batch: 2.0756 sec
0.0607 0.0391 0.0255 0.0193 0.0160 0.0143 0.0132 0.0127 0.0122 0.0119 0.0116 0.0114 0.0113 0.0112 0.0111 0.0111 

[TRAIN] Epoch[6](50/375); Loss: 0.052187; Backpropagation: 0.2886 sec; Batch: 2.0748 sec
0.0944 0.0731 0.0601 0.0555 0.0526 0.0502 0.0484 0.0469 0.0459 0.0452 0.0446 0.0442 0.0438 0.0436 0.0434 0.0433 

[TRAIN] Epoch[6](51/375); Loss: 0.032607; Backpropagation: 0.2882 sec; Batch: 2.0760 sec
0.0717 0.0460 0.0402 0.0350 0.0324 0.0305 0.0291 0.0281 0.0273 0.0268 0.0263 0.0260 0.0257 0.0256 0.0255 0.0255 

[TRAIN] Epoch[6](52/375); Loss: 0.045305; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0853 0.0660 0.0548 0.0487 0.0454 0.0431 0.0413 0.0401 0.0391 0.0383 0.0377 0.0373 0.0371 0.0370 0.0368 0.0368 

[TRAIN] Epoch[6](53/375); Loss: 0.055549; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1056 0.0790 0.0673 0.0597 0.0558 0.0529 0.0507 0.0491 0.0479 0.0469 0.0464 0.0460 0.0457 0.0454 0.0452 0.0452 

[TRAIN] Epoch[6](54/375); Loss: 0.059596; Backpropagation: 0.2930 sec; Batch: 2.0784 sec
0.1076 0.0856 0.0730 0.0652 0.0605 0.0571 0.0547 0.0531 0.0516 0.0506 0.0500 0.0494 0.0491 0.0487 0.0486 0.0486 

[TRAIN] Epoch[6](55/375); Loss: 0.046476; Backpropagation: 0.2884 sec; Batch: 2.0781 sec
0.1029 0.0735 0.0588 0.0509 0.0466 0.0433 0.0411 0.0393 0.0379 0.0370 0.0362 0.0357 0.0354 0.0351 0.0350 0.0349 

[TRAIN] Epoch[6](56/375); Loss: 0.032769; Backpropagation: 0.2933 sec; Batch: 2.0883 sec
0.0858 0.0593 0.0423 0.0351 0.0313 0.0289 0.0272 0.0258 0.0250 0.0244 0.0238 0.0235 0.0232 0.0230 0.0229 0.0228 

[TRAIN] Epoch[6](57/375); Loss: 0.037236; Backpropagation: 0.2882 sec; Batch: 2.0759 sec
0.0886 0.0632 0.0492 0.0405 0.0357 0.0330 0.0314 0.0301 0.0293 0.0287 0.0283 0.0279 0.0277 0.0275 0.0274 0.0273 

[TRAIN] Epoch[6](58/375); Loss: 0.043925; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0871 0.0644 0.0543 0.0482 0.0444 0.0419 0.0401 0.0386 0.0376 0.0366 0.0359 0.0353 0.0349 0.0347 0.0344 0.0343 

[TRAIN] Epoch[6](59/375); Loss: 0.050998; Backpropagation: 0.2888 sec; Batch: 2.0737 sec
0.1056 0.0761 0.0640 0.0553 0.0510 0.0483 0.0460 0.0443 0.0430 0.0420 0.0410 0.0405 0.0401 0.0398 0.0396 0.0394 

[TRAIN] Epoch[6](60/375); Loss: 0.044106; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0875 0.0685 0.0560 0.0487 0.0449 0.0419 0.0397 0.0382 0.0372 0.0362 0.0354 0.0349 0.0345 0.0342 0.0340 0.0338 

[TRAIN] Epoch[6](61/375); Loss: 0.041857; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0894 0.0627 0.0524 0.0458 0.0421 0.0396 0.0379 0.0363 0.0351 0.0341 0.0334 0.0328 0.0324 0.0321 0.0319 0.0317 

[TRAIN] Epoch[6](62/375); Loss: 0.052012; Backpropagation: 0.2884 sec; Batch: 2.0809 sec
0.0948 0.0756 0.0622 0.0551 0.0517 0.0493 0.0476 0.0463 0.0454 0.0446 0.0440 0.0436 0.0433 0.0430 0.0428 0.0426 

[TRAIN] Epoch[6](63/375); Loss: 0.041118; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0887 0.0645 0.0541 0.0457 0.0408 0.0380 0.0361 0.0348 0.0338 0.0330 0.0324 0.0318 0.0314 0.0311 0.0309 0.0307 

[TRAIN] Epoch[6](64/375); Loss: 0.042198; Backpropagation: 0.2891 sec; Batch: 2.0755 sec
0.1026 0.0710 0.0528 0.0443 0.0409 0.0382 0.0363 0.0350 0.0338 0.0329 0.0322 0.0317 0.0313 0.0309 0.0306 0.0304 

[TRAIN] Epoch[6](65/375); Loss: 0.056872; Backpropagation: 0.2892 sec; Batch: 2.0761 sec
0.1099 0.0845 0.0695 0.0614 0.0571 0.0541 0.0517 0.0501 0.0489 0.0479 0.0470 0.0464 0.0459 0.0455 0.0452 0.0449 

[TRAIN] Epoch[6](66/375); Loss: 0.041545; Backpropagation: 0.2890 sec; Batch: 2.0748 sec
0.0880 0.0670 0.0543 0.0453 0.0409 0.0380 0.0362 0.0351 0.0342 0.0335 0.0328 0.0324 0.0321 0.0318 0.0316 0.0314 

[TRAIN] Epoch[6](67/375); Loss: 0.050404; Backpropagation: 0.2944 sec; Batch: 2.0805 sec
0.0983 0.0745 0.0618 0.0552 0.0512 0.0481 0.0460 0.0443 0.0431 0.0421 0.0414 0.0408 0.0404 0.0400 0.0397 0.0395 

[TRAIN] Epoch[6](68/375); Loss: 0.045512; Backpropagation: 0.2886 sec; Batch: 2.0759 sec
0.0946 0.0676 0.0560 0.0497 0.0464 0.0434 0.0412 0.0396 0.0384 0.0374 0.0366 0.0362 0.0357 0.0354 0.0352 0.0349 

[TRAIN] Epoch[6](69/375); Loss: 0.041205; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0895 0.0664 0.0547 0.0467 0.0422 0.0387 0.0364 0.0347 0.0335 0.0327 0.0318 0.0311 0.0307 0.0303 0.0301 0.0299 

[TRAIN] Epoch[6](70/375); Loss: 0.040073; Backpropagation: 0.2889 sec; Batch: 2.0757 sec
0.0908 0.0673 0.0520 0.0440 0.0398 0.0370 0.0351 0.0335 0.0323 0.0314 0.0307 0.0301 0.0297 0.0294 0.0291 0.0289 

[TRAIN] Epoch[6](71/375); Loss: 0.046512; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0935 0.0757 0.0601 0.0514 0.0466 0.0438 0.0416 0.0400 0.0387 0.0377 0.0369 0.0364 0.0359 0.0355 0.0352 0.0350 

[TRAIN] Epoch[6](72/375); Loss: 0.055185; Backpropagation: 0.2886 sec; Batch: 2.0807 sec
0.1109 0.0837 0.0706 0.0623 0.0570 0.0530 0.0500 0.0477 0.0462 0.0450 0.0440 0.0433 0.0428 0.0424 0.0421 0.0418 

[TRAIN] Epoch[6](73/375); Loss: 0.043792; Backpropagation: 0.2888 sec; Batch: 2.0761 sec
0.0863 0.0653 0.0546 0.0490 0.0455 0.0422 0.0402 0.0384 0.0372 0.0362 0.0354 0.0348 0.0343 0.0340 0.0337 0.0335 

[TRAIN] Epoch[6](74/375); Loss: 0.045914; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1020 0.0737 0.0596 0.0518 0.0466 0.0431 0.0407 0.0387 0.0372 0.0361 0.0353 0.0348 0.0343 0.0339 0.0336 0.0334 

[TRAIN] Epoch[6](75/375); Loss: 0.054963; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1154 0.0878 0.0707 0.0622 0.0568 0.0529 0.0499 0.0475 0.0455 0.0438 0.0427 0.0418 0.0412 0.0407 0.0403 0.0400 

[TRAIN] Epoch[6](76/375); Loss: 0.035711; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.0813 0.0590 0.0469 0.0396 0.0355 0.0328 0.0309 0.0296 0.0286 0.0278 0.0273 0.0269 0.0266 0.0263 0.0261 0.0260 

[TRAIN] Epoch[6](77/375); Loss: 0.042025; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0827 0.0607 0.0515 0.0453 0.0424 0.0403 0.0387 0.0373 0.0362 0.0353 0.0347 0.0342 0.0337 0.0334 0.0331 0.0329 

[TRAIN] Epoch[6](78/375); Loss: 0.044167; Backpropagation: 0.2888 sec; Batch: 2.0750 sec
0.0968 0.0703 0.0580 0.0489 0.0441 0.0415 0.0393 0.0377 0.0363 0.0352 0.0343 0.0336 0.0331 0.0327 0.0324 0.0323 

[TRAIN] Epoch[6](79/375); Loss: 0.037755; Backpropagation: 0.2890 sec; Batch: 2.0761 sec
0.0826 0.0563 0.0463 0.0408 0.0376 0.0354 0.0338 0.0326 0.0316 0.0308 0.0302 0.0298 0.0294 0.0291 0.0289 0.0288 

[TRAIN] Epoch[6](80/375); Loss: 0.044300; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0839 0.0660 0.0558 0.0496 0.0453 0.0420 0.0399 0.0385 0.0376 0.0368 0.0363 0.0359 0.0356 0.0354 0.0352 0.0351 

[TRAIN] Epoch[6](81/375); Loss: 0.036853; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.0754 0.0544 0.0466 0.0416 0.0377 0.0353 0.0333 0.0321 0.0311 0.0303 0.0296 0.0291 0.0287 0.0284 0.0281 0.0279 

[TRAIN] Epoch[6](82/375); Loss: 0.057192; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1025 0.0808 0.0699 0.0628 0.0582 0.0548 0.0528 0.0512 0.0499 0.0489 0.0482 0.0477 0.0473 0.0469 0.0467 0.0465 

[TRAIN] Epoch[6](83/375); Loss: 0.044625; Backpropagation: 0.2886 sec; Batch: 2.0743 sec
0.0977 0.0705 0.0563 0.0485 0.0438 0.0408 0.0391 0.0378 0.0369 0.0360 0.0353 0.0348 0.0345 0.0342 0.0340 0.0338 

[TRAIN] Epoch[6](84/375); Loss: 0.048850; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1038 0.0698 0.0591 0.0519 0.0484 0.0460 0.0440 0.0425 0.0415 0.0406 0.0399 0.0394 0.0390 0.0387 0.0385 0.0383 

[TRAIN] Epoch[6](85/375); Loss: 0.061917; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1113 0.0921 0.0788 0.0700 0.0645 0.0605 0.0577 0.0555 0.0536 0.0521 0.0508 0.0498 0.0492 0.0486 0.0482 0.0479 

[TRAIN] Epoch[6](86/375); Loss: 0.037175; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0869 0.0631 0.0483 0.0391 0.0358 0.0335 0.0319 0.0308 0.0298 0.0291 0.0285 0.0281 0.0278 0.0275 0.0274 0.0273 

[TRAIN] Epoch[6](87/375); Loss: 0.056363; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0969 0.0789 0.0689 0.0620 0.0583 0.0556 0.0532 0.0515 0.0500 0.0488 0.0477 0.0469 0.0464 0.0459 0.0456 0.0454 

[TRAIN] Epoch[6](88/375); Loss: 0.062173; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.1086 0.0871 0.0761 0.0692 0.0651 0.0616 0.0587 0.0565 0.0548 0.0532 0.0521 0.0513 0.0507 0.0502 0.0499 0.0496 

[TRAIN] Epoch[6](89/375); Loss: 0.034275; Backpropagation: 0.2887 sec; Batch: 2.0739 sec
0.0830 0.0593 0.0478 0.0397 0.0347 0.0311 0.0290 0.0277 0.0265 0.0256 0.0249 0.0244 0.0240 0.0238 0.0236 0.0234 

[TRAIN] Epoch[6](90/375); Loss: 0.050997; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1034 0.0757 0.0637 0.0556 0.0515 0.0483 0.0461 0.0445 0.0432 0.0422 0.0414 0.0408 0.0403 0.0400 0.0397 0.0395 

[TRAIN] Epoch[6](91/375); Loss: 0.053831; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0982 0.0738 0.0636 0.0570 0.0537 0.0515 0.0496 0.0484 0.0474 0.0466 0.0461 0.0457 0.0453 0.0450 0.0447 0.0445 

[TRAIN] Epoch[6](92/375); Loss: 0.047966; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1127 0.0751 0.0624 0.0529 0.0474 0.0442 0.0419 0.0402 0.0390 0.0378 0.0368 0.0362 0.0357 0.0353 0.0351 0.0349 

[TRAIN] Epoch[6](93/375); Loss: 0.067379; Backpropagation: 0.2886 sec; Batch: 2.0831 sec
0.1252 0.0964 0.0829 0.0744 0.0692 0.0651 0.0623 0.0599 0.0583 0.0569 0.0559 0.0552 0.0546 0.0543 0.0539 0.0537 

[TRAIN] Epoch[6](94/375); Loss: 0.042054; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.0882 0.0617 0.0509 0.0448 0.0413 0.0389 0.0374 0.0365 0.0356 0.0350 0.0345 0.0341 0.0338 0.0336 0.0334 0.0332 

[TRAIN] Epoch[6](95/375); Loss: 0.044673; Backpropagation: 0.2888 sec; Batch: 2.0766 sec
0.0976 0.0692 0.0597 0.0529 0.0470 0.0427 0.0401 0.0379 0.0360 0.0348 0.0340 0.0332 0.0328 0.0325 0.0322 0.0321 

[TRAIN] Epoch[6](96/375); Loss: 0.049154; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1047 0.0787 0.0650 0.0556 0.0502 0.0464 0.0437 0.0416 0.0403 0.0392 0.0381 0.0374 0.0369 0.0365 0.0362 0.0359 

[TRAIN] Epoch[6](97/375); Loss: 0.035302; Backpropagation: 0.2885 sec; Batch: 2.0769 sec
0.0722 0.0496 0.0429 0.0383 0.0357 0.0335 0.0320 0.0309 0.0301 0.0295 0.0289 0.0286 0.0284 0.0282 0.0280 0.0280 

[TRAIN] Epoch[6](98/375); Loss: 0.055757; Backpropagation: 0.2882 sec; Batch: 2.0756 sec
0.1101 0.0900 0.0707 0.0618 0.0565 0.0531 0.0507 0.0483 0.0466 0.0455 0.0446 0.0438 0.0432 0.0427 0.0424 0.0422 

[TRAIN] Epoch[6](99/375); Loss: 0.037119; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.0728 0.0541 0.0459 0.0419 0.0391 0.0365 0.0344 0.0325 0.0314 0.0305 0.0299 0.0294 0.0291 0.0289 0.0288 0.0286 

[TRAIN] Epoch[6](100/375); Loss: 0.041698; Backpropagation: 0.2890 sec; Batch: 2.0750 sec
0.0763 0.0583 0.0506 0.0454 0.0423 0.0402 0.0386 0.0376 0.0366 0.0358 0.0352 0.0346 0.0343 0.0340 0.0338 0.0336 

[TRAIN] Epoch[6](101/375); Loss: 0.058164; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1139 0.0872 0.0743 0.0659 0.0607 0.0561 0.0529 0.0504 0.0488 0.0477 0.0467 0.0461 0.0455 0.0451 0.0448 0.0445 

[TRAIN] Epoch[6](102/375); Loss: 0.044080; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0953 0.0707 0.0613 0.0533 0.0468 0.0419 0.0390 0.0369 0.0351 0.0340 0.0330 0.0324 0.0319 0.0315 0.0312 0.0310 

[TRAIN] Epoch[6](103/375); Loss: 0.061757; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1110 0.0858 0.0725 0.0653 0.0618 0.0590 0.0570 0.0556 0.0545 0.0537 0.0530 0.0525 0.0521 0.0518 0.0514 0.0512 

[TRAIN] Epoch[6](104/375); Loss: 0.046158; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1127 0.0800 0.0617 0.0519 0.0465 0.0422 0.0393 0.0373 0.0358 0.0346 0.0338 0.0332 0.0328 0.0324 0.0322 0.0319 

[TRAIN] Epoch[6](105/375); Loss: 0.052510; Backpropagation: 0.2880 sec; Batch: 2.0729 sec
0.1154 0.0767 0.0656 0.0581 0.0531 0.0493 0.0470 0.0452 0.0438 0.0426 0.0417 0.0411 0.0406 0.0402 0.0399 0.0397 

[TRAIN] Epoch[6](106/375); Loss: 0.031287; Backpropagation: 0.2890 sec; Batch: 2.0759 sec
0.0738 0.0563 0.0421 0.0347 0.0309 0.0283 0.0265 0.0254 0.0244 0.0236 0.0231 0.0227 0.0224 0.0223 0.0221 0.0220 

[TRAIN] Epoch[6](107/375); Loss: 0.040837; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0925 0.0609 0.0540 0.0469 0.0413 0.0378 0.0359 0.0344 0.0332 0.0323 0.0317 0.0311 0.0308 0.0305 0.0302 0.0300 

[TRAIN] Epoch[6](108/375); Loss: 0.062698; Backpropagation: 0.2887 sec; Batch: 2.0757 sec
0.1075 0.0842 0.0734 0.0678 0.0639 0.0611 0.0587 0.0570 0.0558 0.0549 0.0542 0.0536 0.0532 0.0528 0.0526 0.0525 

[TRAIN] Epoch[6](109/375); Loss: 0.046322; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0992 0.0726 0.0620 0.0534 0.0473 0.0435 0.0409 0.0392 0.0375 0.0365 0.0359 0.0354 0.0349 0.0345 0.0343 0.0341 

[TRAIN] Epoch[6](110/375); Loss: 0.065432; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1294 0.1007 0.0834 0.0721 0.0661 0.0622 0.0594 0.0572 0.0553 0.0539 0.0528 0.0519 0.0513 0.0508 0.0504 0.0501 

[TRAIN] Epoch[6](111/375); Loss: 0.080890; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1700 0.1482 0.1121 0.0888 0.0774 0.0724 0.0691 0.0667 0.0648 0.0631 0.0620 0.0610 0.0603 0.0598 0.0594 0.0591 

[TRAIN] Epoch[6](112/375); Loss: 0.034513; Backpropagation: 0.2888 sec; Batch: 2.0748 sec
0.0822 0.0557 0.0461 0.0382 0.0340 0.0315 0.0299 0.0286 0.0275 0.0269 0.0262 0.0257 0.0253 0.0250 0.0247 0.0246 

[TRAIN] Epoch[6](113/375); Loss: 0.046881; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.0823 0.0653 0.0561 0.0518 0.0487 0.0459 0.0439 0.0425 0.0413 0.0403 0.0397 0.0391 0.0387 0.0384 0.0381 0.0380 

[TRAIN] Epoch[6](114/375); Loss: 0.051540; Backpropagation: 0.2886 sec; Batch: 2.0752 sec
0.1095 0.0884 0.0698 0.0581 0.0512 0.0472 0.0448 0.0431 0.0415 0.0403 0.0395 0.0389 0.0384 0.0382 0.0379 0.0378 

[TRAIN] Epoch[6](115/375); Loss: 0.039075; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.0862 0.0619 0.0506 0.0429 0.0386 0.0358 0.0342 0.0330 0.0322 0.0313 0.0307 0.0302 0.0298 0.0295 0.0293 0.0291 

[TRAIN] Epoch[6](116/375); Loss: 0.031698; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0691 0.0514 0.0411 0.0355 0.0319 0.0298 0.0280 0.0270 0.0260 0.0252 0.0246 0.0241 0.0238 0.0234 0.0232 0.0231 

[TRAIN] Epoch[6](117/375); Loss: 0.062021; Backpropagation: 0.2882 sec; Batch: 2.0733 sec
0.1167 0.0894 0.0805 0.0716 0.0650 0.0601 0.0570 0.0546 0.0529 0.0516 0.0506 0.0497 0.0489 0.0483 0.0479 0.0475 

[TRAIN] Epoch[6](118/375); Loss: 0.044027; Backpropagation: 0.2960 sec; Batch: 2.0923 sec
0.0877 0.0709 0.0572 0.0497 0.0454 0.0416 0.0393 0.0378 0.0366 0.0356 0.0349 0.0343 0.0338 0.0334 0.0331 0.0328 

[TRAIN] Epoch[6](119/375); Loss: 0.041755; Backpropagation: 0.2888 sec; Batch: 2.0741 sec
0.0827 0.0611 0.0514 0.0458 0.0423 0.0394 0.0376 0.0364 0.0356 0.0348 0.0343 0.0339 0.0336 0.0333 0.0330 0.0329 

[TRAIN] Epoch[6](120/375); Loss: 0.052404; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1112 0.0893 0.0699 0.0590 0.0533 0.0489 0.0459 0.0440 0.0424 0.0413 0.0404 0.0396 0.0390 0.0384 0.0381 0.0378 

[TRAIN] Epoch[6](121/375); Loss: 0.034889; Backpropagation: 0.2886 sec; Batch: 2.0781 sec
0.0704 0.0571 0.0453 0.0382 0.0344 0.0325 0.0311 0.0298 0.0289 0.0282 0.0278 0.0274 0.0271 0.0269 0.0267 0.0265 

[TRAIN] Epoch[6](122/375); Loss: 0.057689; Backpropagation: 0.2884 sec; Batch: 2.0854 sec
0.0943 0.0797 0.0693 0.0626 0.0588 0.0560 0.0541 0.0526 0.0515 0.0506 0.0499 0.0494 0.0490 0.0487 0.0484 0.0482 

[TRAIN] Epoch[6](123/375); Loss: 0.056955; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.1009 0.0822 0.0684 0.0611 0.0579 0.0551 0.0529 0.0512 0.0499 0.0490 0.0483 0.0477 0.0472 0.0468 0.0465 0.0462 

[TRAIN] Epoch[6](124/375); Loss: 0.045238; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.0904 0.0748 0.0598 0.0508 0.0455 0.0422 0.0401 0.0386 0.0374 0.0364 0.0357 0.0351 0.0346 0.0343 0.0341 0.0339 

[TRAIN] Epoch[6](125/375); Loss: 0.043336; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.0982 0.0791 0.0596 0.0482 0.0421 0.0390 0.0369 0.0354 0.0342 0.0332 0.0324 0.0318 0.0313 0.0309 0.0306 0.0305 

[TRAIN] Epoch[6](126/375); Loss: 0.033410; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0856 0.0635 0.0471 0.0379 0.0325 0.0294 0.0274 0.0260 0.0249 0.0241 0.0235 0.0231 0.0227 0.0225 0.0222 0.0221 

[TRAIN] Epoch[6](127/375); Loss: 0.027603; Backpropagation: 0.2958 sec; Batch: 2.0954 sec
0.0626 0.0525 0.0436 0.0348 0.0287 0.0247 0.0228 0.0215 0.0205 0.0197 0.0192 0.0187 0.0184 0.0182 0.0180 0.0179 

[TRAIN] Epoch[6](128/375); Loss: 0.048149; Backpropagation: 0.2896 sec; Batch: 2.1023 sec
0.0947 0.0814 0.0640 0.0532 0.0481 0.0451 0.0431 0.0413 0.0398 0.0387 0.0380 0.0373 0.0369 0.0365 0.0362 0.0360 

[TRAIN] Epoch[6](129/375); Loss: 0.036009; Backpropagation: 0.2895 sec; Batch: 2.0855 sec
0.1002 0.0667 0.0492 0.0400 0.0343 0.0310 0.0291 0.0278 0.0267 0.0257 0.0251 0.0246 0.0243 0.0241 0.0238 0.0237 

[TRAIN] Epoch[6](130/375); Loss: 0.044917; Backpropagation: 0.2891 sec; Batch: 2.0757 sec
0.1036 0.0817 0.0632 0.0525 0.0459 0.0409 0.0381 0.0364 0.0349 0.0335 0.0326 0.0319 0.0314 0.0310 0.0307 0.0304 

[TRAIN] Epoch[6](131/375); Loss: 0.054981; Backpropagation: 0.2889 sec; Batch: 2.0740 sec
0.1315 0.1012 0.0765 0.0621 0.0539 0.0492 0.0464 0.0442 0.0423 0.0410 0.0400 0.0393 0.0386 0.0381 0.0378 0.0375 

[TRAIN] Epoch[6](132/375); Loss: 0.041745; Backpropagation: 0.2887 sec; Batch: 2.0821 sec
0.0918 0.0759 0.0603 0.0496 0.0435 0.0388 0.0355 0.0339 0.0325 0.0313 0.0304 0.0298 0.0292 0.0288 0.0285 0.0282 

[TRAIN] Epoch[6](133/375); Loss: 0.029151; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0813 0.0550 0.0398 0.0328 0.0283 0.0253 0.0236 0.0224 0.0214 0.0206 0.0200 0.0196 0.0193 0.0191 0.0190 0.0189 

[TRAIN] Epoch[6](134/375); Loss: 0.067130; Backpropagation: 0.2886 sec; Batch: 2.0840 sec
0.1283 0.1153 0.0995 0.0817 0.0696 0.0623 0.0588 0.0563 0.0541 0.0523 0.0510 0.0500 0.0493 0.0489 0.0486 0.0483 

[TRAIN] Epoch[6](135/375); Loss: 0.061001; Backpropagation: 0.2885 sec; Batch: 2.0946 sec
0.1251 0.0977 0.0784 0.0681 0.0622 0.0576 0.0547 0.0524 0.0507 0.0495 0.0483 0.0474 0.0467 0.0461 0.0457 0.0454 

[TRAIN] Epoch[6](136/375); Loss: 0.039289; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0859 0.0674 0.0517 0.0451 0.0403 0.0371 0.0348 0.0329 0.0317 0.0307 0.0298 0.0290 0.0285 0.0282 0.0279 0.0276 

[TRAIN] Epoch[6](137/375); Loss: 0.048458; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.1082 0.0800 0.0636 0.0540 0.0490 0.0450 0.0422 0.0403 0.0389 0.0380 0.0372 0.0366 0.0361 0.0356 0.0354 0.0352 

[TRAIN] Epoch[6](138/375); Loss: 0.037435; Backpropagation: 0.2886 sec; Batch: 2.0770 sec
0.0730 0.0594 0.0467 0.0406 0.0374 0.0354 0.0339 0.0326 0.0316 0.0309 0.0304 0.0299 0.0296 0.0294 0.0292 0.0291 

[TRAIN] Epoch[6](139/375); Loss: 0.045715; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1024 0.0763 0.0599 0.0512 0.0459 0.0425 0.0399 0.0382 0.0368 0.0357 0.0350 0.0343 0.0338 0.0334 0.0332 0.0330 

[TRAIN] Epoch[6](140/375); Loss: 0.049987; Backpropagation: 0.2882 sec; Batch: 2.0803 sec
0.0994 0.0788 0.0642 0.0559 0.0512 0.0475 0.0451 0.0434 0.0419 0.0408 0.0399 0.0392 0.0387 0.0383 0.0380 0.0378 

[TRAIN] Epoch[6](141/375); Loss: 0.057449; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1136 0.0955 0.0743 0.0633 0.0573 0.0532 0.0512 0.0493 0.0478 0.0466 0.0458 0.0451 0.0445 0.0441 0.0439 0.0437 

[TRAIN] Epoch[6](142/375); Loss: 0.053927; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.1110 0.0838 0.0660 0.0580 0.0536 0.0506 0.0486 0.0469 0.0455 0.0444 0.0435 0.0428 0.0424 0.0421 0.0419 0.0417 

[TRAIN] Epoch[6](143/375); Loss: 0.046079; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.1059 0.0763 0.0594 0.0520 0.0467 0.0426 0.0402 0.0384 0.0371 0.0360 0.0351 0.0344 0.0338 0.0334 0.0331 0.0329 

[TRAIN] Epoch[6](144/375); Loss: 0.059126; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1018 0.0846 0.0722 0.0654 0.0608 0.0573 0.0549 0.0532 0.0519 0.0508 0.0500 0.0494 0.0489 0.0485 0.0483 0.0481 

[TRAIN] Epoch[6](145/375); Loss: 0.039842; Backpropagation: 0.2882 sec; Batch: 2.0767 sec
0.0978 0.0722 0.0554 0.0448 0.0392 0.0356 0.0334 0.0318 0.0307 0.0297 0.0290 0.0284 0.0278 0.0275 0.0272 0.0270 

[TRAIN] Epoch[6](146/375); Loss: 0.041844; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.0728 0.0597 0.0508 0.0452 0.0425 0.0402 0.0386 0.0376 0.0369 0.0361 0.0356 0.0351 0.0349 0.0346 0.0344 0.0343 

[TRAIN] Epoch[6](147/375); Loss: 0.047058; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0926 0.0737 0.0581 0.0502 0.0465 0.0444 0.0428 0.0414 0.0404 0.0393 0.0386 0.0379 0.0373 0.0369 0.0365 0.0363 

[TRAIN] Epoch[6](148/375); Loss: 0.059600; Backpropagation: 0.2887 sec; Batch: 2.0734 sec
0.1233 0.0991 0.0773 0.0671 0.0612 0.0566 0.0532 0.0507 0.0490 0.0476 0.0464 0.0456 0.0448 0.0443 0.0439 0.0436 

[TRAIN] Epoch[6](149/375); Loss: 0.032351; Backpropagation: 0.2884 sec; Batch: 2.0785 sec
0.0830 0.0545 0.0413 0.0348 0.0315 0.0293 0.0277 0.0264 0.0254 0.0246 0.0240 0.0236 0.0232 0.0230 0.0228 0.0226 

[TRAIN] Epoch[6](150/375); Loss: 0.035527; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0911 0.0599 0.0441 0.0379 0.0346 0.0323 0.0304 0.0290 0.0281 0.0272 0.0266 0.0260 0.0256 0.0254 0.0252 0.0250 

[TRAIN] Epoch[6](151/375); Loss: 0.067871; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.1112 0.0913 0.0804 0.0739 0.0703 0.0671 0.0645 0.0624 0.0608 0.0596 0.0586 0.0580 0.0574 0.0571 0.0568 0.0565 

[TRAIN] Epoch[6](152/375); Loss: 0.041275; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.0946 0.0669 0.0571 0.0473 0.0410 0.0379 0.0359 0.0342 0.0331 0.0321 0.0311 0.0306 0.0301 0.0298 0.0295 0.0293 

[TRAIN] Epoch[6](153/375); Loss: 0.061545; Backpropagation: 0.2885 sec; Batch: 2.0785 sec
0.1232 0.1007 0.0839 0.0701 0.0624 0.0581 0.0548 0.0524 0.0508 0.0493 0.0481 0.0472 0.0465 0.0460 0.0457 0.0455 

[TRAIN] Epoch[6](154/375); Loss: 0.042224; Backpropagation: 0.2884 sec; Batch: 2.0728 sec
0.1032 0.0780 0.0555 0.0465 0.0402 0.0364 0.0347 0.0336 0.0327 0.0319 0.0314 0.0309 0.0305 0.0302 0.0300 0.0298 

[TRAIN] Epoch[6](155/375); Loss: 0.048052; Backpropagation: 0.2881 sec; Batch: 2.0781 sec
0.1111 0.0783 0.0623 0.0522 0.0476 0.0444 0.0420 0.0402 0.0388 0.0377 0.0369 0.0362 0.0357 0.0354 0.0352 0.0349 

[TRAIN] Epoch[6](156/375); Loss: 0.058520; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1010 0.0837 0.0710 0.0642 0.0604 0.0571 0.0549 0.0530 0.0516 0.0504 0.0495 0.0487 0.0482 0.0478 0.0475 0.0473 

[TRAIN] Epoch[6](157/375); Loss: 0.061426; Backpropagation: 0.2886 sec; Batch: 2.0727 sec
0.1449 0.1289 0.1034 0.0722 0.0572 0.0513 0.0482 0.0459 0.0441 0.0430 0.0420 0.0414 0.0407 0.0402 0.0398 0.0396 

[TRAIN] Epoch[6](158/375); Loss: 0.058627; Backpropagation: 0.2883 sec; Batch: 2.0776 sec
0.1333 0.1130 0.0886 0.0692 0.0580 0.0517 0.0486 0.0464 0.0445 0.0431 0.0419 0.0411 0.0404 0.0398 0.0394 0.0391 

[TRAIN] Epoch[6](159/375); Loss: 0.059131; Backpropagation: 0.2892 sec; Batch: 2.0744 sec
0.0992 0.0854 0.0708 0.0644 0.0608 0.0580 0.0556 0.0538 0.0524 0.0512 0.0503 0.0496 0.0491 0.0487 0.0484 0.0482 

[TRAIN] Epoch[6](160/375); Loss: 0.062106; Backpropagation: 0.2887 sec; Batch: 2.0774 sec
0.1136 0.0929 0.0770 0.0684 0.0641 0.0608 0.0580 0.0559 0.0538 0.0522 0.0511 0.0502 0.0496 0.0491 0.0487 0.0484 

[TRAIN] Epoch[6](161/375); Loss: 0.038515; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0809 0.0611 0.0493 0.0426 0.0387 0.0359 0.0343 0.0330 0.0319 0.0311 0.0305 0.0300 0.0296 0.0293 0.0291 0.0289 

[TRAIN] Epoch[6](162/375); Loss: 0.045264; Backpropagation: 0.2885 sec; Batch: 2.0815 sec
0.1057 0.0759 0.0566 0.0479 0.0440 0.0410 0.0391 0.0376 0.0365 0.0356 0.0349 0.0345 0.0341 0.0338 0.0336 0.0335 

[TRAIN] Epoch[6](163/375); Loss: 0.062794; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1163 0.0937 0.0807 0.0696 0.0640 0.0605 0.0577 0.0555 0.0538 0.0525 0.0515 0.0508 0.0501 0.0497 0.0493 0.0491 

[TRAIN] Epoch[6](164/375); Loss: 0.055622; Backpropagation: 0.2885 sec; Batch: 2.0766 sec
0.1012 0.0836 0.0710 0.0617 0.0561 0.0526 0.0505 0.0487 0.0477 0.0467 0.0460 0.0455 0.0450 0.0447 0.0445 0.0443 

[TRAIN] Epoch[6](165/375); Loss: 0.050438; Backpropagation: 0.2887 sec; Batch: 2.1097 sec
0.1178 0.0937 0.0681 0.0570 0.0504 0.0449 0.0420 0.0403 0.0389 0.0379 0.0371 0.0364 0.0360 0.0357 0.0354 0.0353 

[TRAIN] Epoch[6](166/375); Loss: 0.056115; Backpropagation: 0.2885 sec; Batch: 2.0756 sec
0.1251 0.0965 0.0702 0.0588 0.0542 0.0509 0.0487 0.0470 0.0457 0.0446 0.0439 0.0432 0.0426 0.0423 0.0421 0.0420 

[TRAIN] Epoch[6](167/375); Loss: 0.057051; Backpropagation: 0.2887 sec; Batch: 2.1094 sec
0.1148 0.0927 0.0740 0.0628 0.0581 0.0544 0.0515 0.0496 0.0478 0.0463 0.0451 0.0442 0.0435 0.0430 0.0425 0.0423 

[TRAIN] Epoch[6](168/375); Loss: 0.075744; Backpropagation: 0.2891 sec; Batch: 2.0770 sec
0.1274 0.1093 0.0929 0.0832 0.0774 0.0731 0.0704 0.0685 0.0668 0.0655 0.0644 0.0636 0.0629 0.0625 0.0621 0.0619 

[TRAIN] Epoch[6](169/375); Loss: 0.039694; Backpropagation: 0.2883 sec; Batch: 2.1094 sec
0.0836 0.0635 0.0507 0.0443 0.0407 0.0376 0.0355 0.0340 0.0327 0.0318 0.0311 0.0305 0.0301 0.0298 0.0296 0.0294 

[TRAIN] Epoch[6](170/375); Loss: 0.045138; Backpropagation: 0.2888 sec; Batch: 2.0739 sec
0.0926 0.0730 0.0580 0.0501 0.0444 0.0417 0.0398 0.0386 0.0376 0.0367 0.0360 0.0354 0.0350 0.0346 0.0344 0.0343 

[TRAIN] Epoch[6](171/375); Loss: 0.039749; Backpropagation: 0.2881 sec; Batch: 2.0724 sec
0.1012 0.0734 0.0537 0.0434 0.0379 0.0352 0.0332 0.0316 0.0305 0.0294 0.0288 0.0282 0.0277 0.0275 0.0272 0.0271 

[TRAIN] Epoch[6](172/375); Loss: 0.054937; Backpropagation: 0.2887 sec; Batch: 2.0747 sec
0.1091 0.0908 0.0695 0.0603 0.0558 0.0524 0.0498 0.0477 0.0461 0.0448 0.0437 0.0429 0.0422 0.0417 0.0413 0.0410 

[TRAIN] Epoch[6](173/375); Loss: 0.039795; Backpropagation: 0.2889 sec; Batch: 2.0741 sec
0.0855 0.0628 0.0492 0.0426 0.0389 0.0367 0.0350 0.0338 0.0329 0.0323 0.0318 0.0314 0.0312 0.0310 0.0308 0.0307 

[TRAIN] Epoch[6](174/375); Loss: 0.044140; Backpropagation: 0.2889 sec; Batch: 2.1014 sec
0.0950 0.0727 0.0573 0.0489 0.0443 0.0414 0.0391 0.0373 0.0360 0.0350 0.0343 0.0337 0.0333 0.0330 0.0327 0.0324 

[TRAIN] Epoch[6](175/375); Loss: 0.048130; Backpropagation: 0.2880 sec; Batch: 2.0774 sec
0.1062 0.0839 0.0647 0.0538 0.0483 0.0444 0.0417 0.0401 0.0386 0.0373 0.0364 0.0357 0.0352 0.0348 0.0345 0.0343 

[TRAIN] Epoch[6](176/375); Loss: 0.044073; Backpropagation: 0.2886 sec; Batch: 2.0735 sec
0.1050 0.0820 0.0616 0.0490 0.0436 0.0402 0.0376 0.0356 0.0339 0.0327 0.0319 0.0312 0.0307 0.0303 0.0300 0.0298 

[TRAIN] Epoch[6](177/375); Loss: 0.072814; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.1446 0.1225 0.0967 0.0792 0.0713 0.0673 0.0644 0.0623 0.0608 0.0591 0.0579 0.0570 0.0562 0.0556 0.0551 0.0549 

[TRAIN] Epoch[6](178/375); Loss: 0.064990; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.1509 0.1279 0.1041 0.0894 0.0749 0.0600 0.0501 0.0471 0.0451 0.0436 0.0426 0.0418 0.0412 0.0407 0.0404 0.0401 

[TRAIN] Epoch[6](179/375); Loss: 0.033800; Backpropagation: 0.2885 sec; Batch: 2.0772 sec
0.0665 0.0520 0.0434 0.0367 0.0338 0.0320 0.0306 0.0295 0.0286 0.0279 0.0274 0.0269 0.0266 0.0264 0.0263 0.0262 

[TRAIN] Epoch[6](180/375); Loss: 0.055373; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1041 0.0884 0.0717 0.0623 0.0562 0.0526 0.0503 0.0483 0.0470 0.0457 0.0447 0.0438 0.0432 0.0428 0.0425 0.0423 

[TRAIN] Epoch[6](181/375); Loss: 0.042501; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.0905 0.0700 0.0562 0.0477 0.0433 0.0401 0.0377 0.0360 0.0346 0.0335 0.0328 0.0322 0.0317 0.0314 0.0312 0.0310 

[TRAIN] Epoch[6](182/375); Loss: 0.057823; Backpropagation: 0.2885 sec; Batch: 2.0810 sec
0.1056 0.0863 0.0721 0.0644 0.0598 0.0562 0.0535 0.0514 0.0497 0.0483 0.0474 0.0469 0.0463 0.0460 0.0457 0.0455 

[TRAIN] Epoch[6](183/375); Loss: 0.048570; Backpropagation: 0.2884 sec; Batch: 2.0772 sec
0.0919 0.0720 0.0591 0.0520 0.0490 0.0463 0.0443 0.0429 0.0417 0.0408 0.0402 0.0398 0.0395 0.0393 0.0392 0.0391 

[TRAIN] Epoch[6](184/375); Loss: 0.041829; Backpropagation: 0.2885 sec; Batch: 2.0818 sec
0.0840 0.0640 0.0522 0.0454 0.0419 0.0395 0.0374 0.0360 0.0350 0.0342 0.0337 0.0334 0.0332 0.0331 0.0331 0.0330 

[TRAIN] Epoch[6](185/375); Loss: 0.035670; Backpropagation: 0.2881 sec; Batch: 2.1090 sec
0.0794 0.0553 0.0421 0.0375 0.0347 0.0328 0.0315 0.0305 0.0297 0.0291 0.0287 0.0283 0.0280 0.0278 0.0277 0.0275 

[TRAIN] Epoch[6](186/375); Loss: 0.048235; Backpropagation: 0.2882 sec; Batch: 2.0729 sec
0.0959 0.0773 0.0606 0.0533 0.0495 0.0460 0.0440 0.0420 0.0404 0.0393 0.0385 0.0378 0.0372 0.0369 0.0366 0.0365 

[TRAIN] Epoch[6](187/375); Loss: 0.040163; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.0900 0.0618 0.0500 0.0430 0.0394 0.0371 0.0356 0.0341 0.0331 0.0324 0.0318 0.0313 0.0310 0.0308 0.0306 0.0305 

[TRAIN] Epoch[6](188/375); Loss: 0.050037; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0903 0.0769 0.0630 0.0556 0.0515 0.0487 0.0464 0.0446 0.0431 0.0419 0.0411 0.0403 0.0398 0.0394 0.0391 0.0389 

[TRAIN] Epoch[6](189/375); Loss: 0.036527; Backpropagation: 0.2891 sec; Batch: 2.0806 sec
0.1047 0.0706 0.0475 0.0377 0.0333 0.0307 0.0291 0.0280 0.0270 0.0262 0.0257 0.0253 0.0249 0.0247 0.0245 0.0244 

[TRAIN] Epoch[6](190/375); Loss: 0.034090; Backpropagation: 0.2889 sec; Batch: 2.0745 sec
0.0972 0.0624 0.0455 0.0358 0.0315 0.0292 0.0274 0.0262 0.0253 0.0247 0.0241 0.0237 0.0234 0.0231 0.0230 0.0228 

[TRAIN] Epoch[6](191/375); Loss: 0.032744; Backpropagation: 0.2890 sec; Batch: 2.0751 sec
0.0935 0.0635 0.0457 0.0343 0.0299 0.0275 0.0259 0.0247 0.0239 0.0233 0.0228 0.0223 0.0220 0.0218 0.0216 0.0214 

[TRAIN] Epoch[6](192/375); Loss: 0.027192; Backpropagation: 0.2885 sec; Batch: 2.0728 sec
0.0636 0.0450 0.0339 0.0289 0.0263 0.0246 0.0234 0.0225 0.0220 0.0215 0.0211 0.0208 0.0206 0.0204 0.0203 0.0202 

[TRAIN] Epoch[6](193/375); Loss: 0.037029; Backpropagation: 0.2888 sec; Batch: 2.0734 sec
0.0790 0.0559 0.0459 0.0400 0.0370 0.0347 0.0331 0.0319 0.0310 0.0303 0.0297 0.0293 0.0290 0.0288 0.0286 0.0284 

[TRAIN] Epoch[6](194/375); Loss: 0.038889; Backpropagation: 0.2890 sec; Batch: 2.0757 sec
0.0891 0.0631 0.0493 0.0415 0.0379 0.0355 0.0339 0.0325 0.0315 0.0308 0.0303 0.0299 0.0296 0.0293 0.0291 0.0290 

[TRAIN] Epoch[6](195/375); Loss: 0.057850; Backpropagation: 0.2891 sec; Batch: 2.0776 sec
0.1097 0.0865 0.0715 0.0635 0.0593 0.0560 0.0535 0.0513 0.0496 0.0484 0.0474 0.0467 0.0462 0.0457 0.0453 0.0450 

[TRAIN] Epoch[6](196/375); Loss: 0.054646; Backpropagation: 0.2892 sec; Batch: 2.0752 sec
0.1108 0.0805 0.0638 0.0574 0.0540 0.0515 0.0496 0.0481 0.0469 0.0460 0.0452 0.0447 0.0443 0.0440 0.0438 0.0436 

[TRAIN] Epoch[6](197/375); Loss: 0.047457; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.1032 0.0769 0.0585 0.0508 0.0468 0.0439 0.0419 0.0403 0.0391 0.0383 0.0376 0.0371 0.0366 0.0363 0.0361 0.0360 

[TRAIN] Epoch[6](198/375); Loss: 0.069819; Backpropagation: 0.2884 sec; Batch: 2.0765 sec
0.1188 0.1005 0.0862 0.0767 0.0717 0.0678 0.0650 0.0632 0.0616 0.0603 0.0591 0.0583 0.0577 0.0572 0.0568 0.0564 

[TRAIN] Epoch[6](199/375); Loss: 0.060643; Backpropagation: 0.2890 sec; Batch: 2.0767 sec
0.1169 0.0898 0.0736 0.0659 0.0617 0.0585 0.0560 0.0539 0.0523 0.0511 0.0500 0.0491 0.0484 0.0480 0.0477 0.0474 

[TRAIN] Epoch[6](200/375); Loss: 0.047837; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0838 0.0674 0.0565 0.0513 0.0488 0.0467 0.0448 0.0435 0.0423 0.0414 0.0408 0.0403 0.0399 0.0396 0.0393 0.0391 

[TRAIN] Epoch[6](201/375); Loss: 0.028464; Backpropagation: 0.2884 sec; Batch: 2.0797 sec
0.0711 0.0490 0.0387 0.0311 0.0279 0.0258 0.0241 0.0230 0.0222 0.0214 0.0209 0.0205 0.0202 0.0200 0.0198 0.0197 

[TRAIN] Epoch[6](202/375); Loss: 0.051372; Backpropagation: 0.2886 sec; Batch: 2.0764 sec
0.1146 0.0869 0.0669 0.0553 0.0502 0.0470 0.0448 0.0432 0.0418 0.0407 0.0398 0.0390 0.0385 0.0381 0.0377 0.0375 

[TRAIN] Epoch[6](203/375); Loss: 0.056716; Backpropagation: 0.2884 sec; Batch: 2.0729 sec
0.1200 0.0980 0.0743 0.0637 0.0578 0.0533 0.0502 0.0481 0.0462 0.0445 0.0432 0.0426 0.0419 0.0416 0.0412 0.0409 

[TRAIN] Epoch[6](204/375); Loss: 0.057150; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1127 0.0888 0.0710 0.0620 0.0574 0.0544 0.0519 0.0498 0.0483 0.0472 0.0464 0.0457 0.0452 0.0448 0.0446 0.0444 

[TRAIN] Epoch[6](205/375); Loss: 0.044516; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0864 0.0697 0.0566 0.0496 0.0458 0.0429 0.0407 0.0390 0.0378 0.0366 0.0357 0.0351 0.0346 0.0342 0.0340 0.0337 

[TRAIN] Epoch[6](206/375); Loss: 0.047986; Backpropagation: 0.2884 sec; Batch: 2.0763 sec
0.0980 0.0698 0.0576 0.0513 0.0477 0.0453 0.0436 0.0422 0.0410 0.0401 0.0394 0.0390 0.0385 0.0383 0.0381 0.0380 

[TRAIN] Epoch[6](207/375); Loss: 0.027598; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0568 0.0428 0.0351 0.0298 0.0277 0.0259 0.0247 0.0238 0.0231 0.0226 0.0221 0.0218 0.0215 0.0214 0.0212 0.0212 

[TRAIN] Epoch[6](208/375); Loss: 0.057184; Backpropagation: 0.2882 sec; Batch: 2.0767 sec
0.1273 0.0997 0.0788 0.0676 0.0595 0.0525 0.0488 0.0465 0.0449 0.0436 0.0425 0.0417 0.0410 0.0405 0.0401 0.0399 

[TRAIN] Epoch[6](209/375); Loss: 0.053586; Backpropagation: 0.2889 sec; Batch: 2.0830 sec
0.0893 0.0775 0.0650 0.0571 0.0540 0.0519 0.0500 0.0485 0.0474 0.0465 0.0459 0.0454 0.0451 0.0448 0.0445 0.0443 

[TRAIN] Epoch[6](210/375); Loss: 0.049843; Backpropagation: 0.2883 sec; Batch: 2.0763 sec
0.1138 0.0884 0.0656 0.0534 0.0478 0.0444 0.0425 0.0411 0.0398 0.0388 0.0380 0.0374 0.0370 0.0367 0.0364 0.0363 

[TRAIN] Epoch[6](211/375); Loss: 0.046797; Backpropagation: 0.2883 sec; Batch: 2.0726 sec
0.1048 0.0843 0.0635 0.0513 0.0454 0.0419 0.0398 0.0384 0.0370 0.0361 0.0354 0.0349 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[6](212/375); Loss: 0.038123; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0809 0.0608 0.0488 0.0420 0.0380 0.0356 0.0339 0.0325 0.0315 0.0307 0.0301 0.0297 0.0293 0.0290 0.0287 0.0286 

[TRAIN] Epoch[6](213/375); Loss: 0.034977; Backpropagation: 0.2888 sec; Batch: 2.0744 sec
0.0734 0.0507 0.0426 0.0384 0.0356 0.0333 0.0315 0.0303 0.0293 0.0287 0.0283 0.0279 0.0277 0.0274 0.0272 0.0271 

[TRAIN] Epoch[6](214/375); Loss: 0.050810; Backpropagation: 0.2885 sec; Batch: 2.1093 sec
0.1125 0.0900 0.0675 0.0534 0.0478 0.0451 0.0433 0.0419 0.0409 0.0401 0.0393 0.0388 0.0385 0.0382 0.0379 0.0378 

[TRAIN] Epoch[6](215/375); Loss: 0.047600; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.0913 0.0713 0.0600 0.0528 0.0488 0.0458 0.0437 0.0420 0.0407 0.0396 0.0387 0.0381 0.0377 0.0373 0.0370 0.0368 

[TRAIN] Epoch[6](216/375); Loss: 0.044103; Backpropagation: 0.2883 sec; Batch: 2.0770 sec
0.1040 0.0745 0.0572 0.0480 0.0434 0.0403 0.0381 0.0365 0.0351 0.0342 0.0334 0.0328 0.0324 0.0321 0.0319 0.0318 

[TRAIN] Epoch[6](217/375); Loss: 0.047246; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0919 0.0708 0.0593 0.0517 0.0481 0.0454 0.0433 0.0414 0.0400 0.0391 0.0385 0.0379 0.0375 0.0372 0.0370 0.0368 

[TRAIN] Epoch[6](218/375); Loss: 0.038927; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0778 0.0575 0.0481 0.0420 0.0392 0.0369 0.0352 0.0340 0.0330 0.0323 0.0318 0.0314 0.0312 0.0309 0.0308 0.0307 

[TRAIN] Epoch[6](219/375); Loss: 0.031266; Backpropagation: 0.2881 sec; Batch: 2.0742 sec
0.0640 0.0527 0.0398 0.0337 0.0305 0.0288 0.0275 0.0265 0.0259 0.0253 0.0249 0.0246 0.0243 0.0241 0.0240 0.0239 

[TRAIN] Epoch[6](220/375); Loss: 0.034957; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0704 0.0556 0.0448 0.0387 0.0351 0.0328 0.0312 0.0300 0.0291 0.0284 0.0279 0.0275 0.0272 0.0270 0.0269 0.0267 

[TRAIN] Epoch[6](221/375); Loss: 0.044020; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0914 0.0694 0.0544 0.0478 0.0444 0.0417 0.0395 0.0379 0.0368 0.0359 0.0352 0.0347 0.0342 0.0339 0.0336 0.0334 

[TRAIN] Epoch[6](222/375); Loss: 0.034912; Backpropagation: 0.2883 sec; Batch: 2.0772 sec
0.0800 0.0562 0.0460 0.0389 0.0347 0.0319 0.0302 0.0292 0.0281 0.0273 0.0268 0.0264 0.0260 0.0258 0.0256 0.0255 

[TRAIN] Epoch[6](223/375); Loss: 0.046030; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0957 0.0735 0.0578 0.0503 0.0462 0.0431 0.0411 0.0395 0.0383 0.0373 0.0365 0.0360 0.0356 0.0353 0.0351 0.0350 

[TRAIN] Epoch[6](224/375); Loss: 0.062254; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.1150 0.0931 0.0780 0.0691 0.0634 0.0595 0.0568 0.0548 0.0533 0.0523 0.0515 0.0508 0.0502 0.0497 0.0494 0.0491 

[TRAIN] Epoch[6](225/375); Loss: 0.042154; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0902 0.0635 0.0527 0.0473 0.0434 0.0403 0.0382 0.0364 0.0351 0.0342 0.0333 0.0327 0.0322 0.0319 0.0316 0.0314 

[TRAIN] Epoch[6](226/375); Loss: 0.051137; Backpropagation: 0.2882 sec; Batch: 2.1089 sec
0.1028 0.0791 0.0634 0.0559 0.0521 0.0487 0.0462 0.0443 0.0430 0.0420 0.0412 0.0406 0.0402 0.0398 0.0395 0.0393 

[TRAIN] Epoch[6](227/375); Loss: 0.046913; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0976 0.0752 0.0583 0.0510 0.0469 0.0441 0.0418 0.0403 0.0392 0.0382 0.0374 0.0369 0.0364 0.0360 0.0358 0.0355 

[TRAIN] Epoch[6](228/375); Loss: 0.050012; Backpropagation: 0.2885 sec; Batch: 2.1015 sec
0.0913 0.0698 0.0585 0.0534 0.0507 0.0484 0.0466 0.0454 0.0442 0.0432 0.0425 0.0419 0.0415 0.0412 0.0409 0.0407 

[TRAIN] Epoch[6](229/375); Loss: 0.049242; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.1082 0.0791 0.0636 0.0546 0.0493 0.0460 0.0434 0.0416 0.0403 0.0391 0.0383 0.0377 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[6](230/375); Loss: 0.046136; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0986 0.0704 0.0567 0.0500 0.0458 0.0432 0.0411 0.0399 0.0384 0.0376 0.0370 0.0365 0.0361 0.0359 0.0356 0.0355 

[TRAIN] Epoch[6](231/375); Loss: 0.046698; Backpropagation: 0.2883 sec; Batch: 2.0769 sec
0.0881 0.0721 0.0576 0.0509 0.0473 0.0447 0.0428 0.0411 0.0399 0.0390 0.0383 0.0378 0.0373 0.0370 0.0368 0.0365 

[TRAIN] Epoch[6](232/375); Loss: 0.050311; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1023 0.0773 0.0660 0.0567 0.0515 0.0482 0.0457 0.0436 0.0420 0.0406 0.0397 0.0391 0.0386 0.0381 0.0379 0.0377 

[TRAIN] Epoch[6](233/375); Loss: 0.055260; Backpropagation: 0.2883 sec; Batch: 2.0847 sec
0.1046 0.0870 0.0712 0.0620 0.0569 0.0534 0.0505 0.0482 0.0464 0.0453 0.0445 0.0438 0.0432 0.0428 0.0424 0.0421 

[TRAIN] Epoch[6](234/375); Loss: 0.061638; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.1266 0.1108 0.0914 0.0735 0.0610 0.0555 0.0525 0.0504 0.0486 0.0474 0.0463 0.0454 0.0449 0.0444 0.0440 0.0437 

[TRAIN] Epoch[6](235/375); Loss: 0.069766; Backpropagation: 0.2883 sec; Batch: 2.0814 sec
0.1239 0.1054 0.0869 0.0758 0.0706 0.0669 0.0642 0.0621 0.0605 0.0592 0.0582 0.0574 0.0568 0.0563 0.0560 0.0558 

[TRAIN] Epoch[6](236/375); Loss: 0.033113; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0914 0.0631 0.0430 0.0352 0.0313 0.0281 0.0264 0.0254 0.0245 0.0239 0.0235 0.0232 0.0229 0.0227 0.0227 0.0226 

[TRAIN] Epoch[6](237/375); Loss: 0.025925; Backpropagation: 0.2882 sec; Batch: 2.0735 sec
0.0718 0.0498 0.0362 0.0272 0.0238 0.0220 0.0207 0.0199 0.0192 0.0185 0.0182 0.0179 0.0176 0.0175 0.0173 0.0173 

[TRAIN] Epoch[6](238/375); Loss: 0.059375; Backpropagation: 0.2883 sec; Batch: 2.1099 sec
0.1150 0.0916 0.0775 0.0677 0.0610 0.0570 0.0539 0.0516 0.0499 0.0486 0.0475 0.0467 0.0460 0.0456 0.0452 0.0449 

[TRAIN] Epoch[6](239/375); Loss: 0.039170; Backpropagation: 0.2884 sec; Batch: 2.1155 sec
0.0840 0.0596 0.0484 0.0421 0.0392 0.0369 0.0352 0.0339 0.0329 0.0320 0.0313 0.0308 0.0304 0.0302 0.0299 0.0297 

[TRAIN] Epoch[6](240/375); Loss: 0.050310; Backpropagation: 0.2881 sec; Batch: 2.0745 sec
0.1093 0.0858 0.0668 0.0545 0.0494 0.0462 0.0438 0.0421 0.0408 0.0397 0.0390 0.0383 0.0378 0.0374 0.0371 0.0369 

[TRAIN] Epoch[6](241/375); Loss: 0.037862; Backpropagation: 0.2885 sec; Batch: 2.0936 sec
0.0803 0.0606 0.0486 0.0416 0.0379 0.0355 0.0338 0.0322 0.0312 0.0304 0.0298 0.0294 0.0290 0.0287 0.0285 0.0283 

[TRAIN] Epoch[6](242/375); Loss: 0.048549; Backpropagation: 0.2881 sec; Batch: 2.0755 sec
0.1060 0.0855 0.0636 0.0534 0.0483 0.0450 0.0424 0.0404 0.0389 0.0379 0.0371 0.0364 0.0360 0.0356 0.0353 0.0351 

[TRAIN] Epoch[6](243/375); Loss: 0.045149; Backpropagation: 0.2889 sec; Batch: 2.0752 sec
0.0892 0.0676 0.0554 0.0495 0.0459 0.0432 0.0411 0.0396 0.0384 0.0375 0.0368 0.0363 0.0359 0.0355 0.0353 0.0351 

[TRAIN] Epoch[6](244/375); Loss: 0.064876; Backpropagation: 0.2884 sec; Batch: 2.0757 sec
0.1068 0.0879 0.0768 0.0703 0.0671 0.0640 0.0616 0.0599 0.0583 0.0571 0.0561 0.0554 0.0548 0.0543 0.0540 0.0537 

[TRAIN] Epoch[6](245/375); Loss: 0.053541; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1096 0.0831 0.0667 0.0589 0.0544 0.0506 0.0481 0.0464 0.0449 0.0438 0.0429 0.0422 0.0417 0.0414 0.0411 0.0409 

[TRAIN] Epoch[6](246/375); Loss: 0.062265; Backpropagation: 0.2886 sec; Batch: 2.0759 sec
0.1142 0.0910 0.0757 0.0675 0.0631 0.0601 0.0576 0.0555 0.0539 0.0529 0.0520 0.0513 0.0508 0.0505 0.0501 0.0499 

[TRAIN] Epoch[6](247/375); Loss: 0.047284; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0951 0.0702 0.0580 0.0513 0.0477 0.0449 0.0429 0.0414 0.0402 0.0394 0.0386 0.0380 0.0376 0.0373 0.0371 0.0369 

[TRAIN] Epoch[6](248/375); Loss: 0.059240; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.1032 0.0820 0.0708 0.0646 0.0609 0.0580 0.0556 0.0538 0.0524 0.0514 0.0505 0.0497 0.0492 0.0489 0.0486 0.0483 

[TRAIN] Epoch[6](249/375); Loss: 0.042717; Backpropagation: 0.2879 sec; Batch: 2.0894 sec
0.0968 0.0759 0.0555 0.0450 0.0410 0.0384 0.0366 0.0354 0.0343 0.0334 0.0328 0.0322 0.0319 0.0316 0.0314 0.0313 

[TRAIN] Epoch[6](250/375); Loss: 0.054984; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.1118 0.0883 0.0696 0.0595 0.0550 0.0519 0.0494 0.0474 0.0459 0.0448 0.0440 0.0433 0.0428 0.0423 0.0420 0.0417 

[TRAIN] Epoch[6](251/375); Loss: 0.050925; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1202 0.0882 0.0677 0.0543 0.0496 0.0461 0.0436 0.0416 0.0402 0.0392 0.0384 0.0378 0.0374 0.0371 0.0368 0.0367 

[TRAIN] Epoch[6](252/375); Loss: 0.046191; Backpropagation: 0.2887 sec; Batch: 2.0750 sec
0.1041 0.0792 0.0612 0.0508 0.0455 0.0423 0.0402 0.0385 0.0370 0.0359 0.0352 0.0346 0.0341 0.0337 0.0335 0.0333 

[TRAIN] Epoch[6](253/375); Loss: 0.048371; Backpropagation: 0.2886 sec; Batch: 2.0771 sec
0.0966 0.0700 0.0580 0.0514 0.0482 0.0458 0.0438 0.0424 0.0415 0.0408 0.0401 0.0396 0.0393 0.0390 0.0388 0.0386 

[TRAIN] Epoch[6](254/375); Loss: 0.065722; Backpropagation: 0.2885 sec; Batch: 2.1164 sec
0.1354 0.1126 0.0908 0.0759 0.0656 0.0611 0.0578 0.0551 0.0531 0.0515 0.0502 0.0494 0.0488 0.0483 0.0480 0.0477 

[TRAIN] Epoch[6](255/375); Loss: 0.052146; Backpropagation: 0.2883 sec; Batch: 2.0751 sec
0.1045 0.0801 0.0656 0.0569 0.0525 0.0492 0.0470 0.0452 0.0438 0.0429 0.0421 0.0415 0.0411 0.0408 0.0406 0.0404 

[TRAIN] Epoch[6](256/375); Loss: 0.049237; Backpropagation: 0.2889 sec; Batch: 2.0765 sec
0.1204 0.0954 0.0681 0.0522 0.0463 0.0432 0.0406 0.0389 0.0375 0.0366 0.0358 0.0353 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[6](257/375); Loss: 0.045424; Backpropagation: 0.2882 sec; Batch: 2.0802 sec
0.1031 0.0742 0.0577 0.0493 0.0456 0.0424 0.0400 0.0381 0.0366 0.0356 0.0349 0.0346 0.0341 0.0337 0.0335 0.0333 

[TRAIN] Epoch[6](258/375); Loss: 0.023807; Backpropagation: 0.2884 sec; Batch: 2.0977 sec
0.0584 0.0373 0.0302 0.0257 0.0228 0.0214 0.0204 0.0195 0.0190 0.0186 0.0183 0.0180 0.0179 0.0178 0.0177 0.0177 

[TRAIN] Epoch[6](259/375); Loss: 0.057832; Backpropagation: 0.2886 sec; Batch: 2.0751 sec
0.1041 0.0819 0.0699 0.0630 0.0590 0.0559 0.0537 0.0519 0.0506 0.0496 0.0487 0.0481 0.0477 0.0473 0.0470 0.0468 

[TRAIN] Epoch[6](260/375); Loss: 0.062090; Backpropagation: 0.2888 sec; Batch: 2.0769 sec
0.1095 0.0947 0.0792 0.0688 0.0637 0.0605 0.0576 0.0554 0.0536 0.0524 0.0512 0.0504 0.0497 0.0492 0.0489 0.0485 

[TRAIN] Epoch[6](261/375); Loss: 0.045443; Backpropagation: 0.2890 sec; Batch: 2.0745 sec
0.0856 0.0629 0.0546 0.0504 0.0477 0.0448 0.0424 0.0408 0.0394 0.0384 0.0377 0.0371 0.0367 0.0364 0.0362 0.0360 

[TRAIN] Epoch[6](262/375); Loss: 0.037672; Backpropagation: 0.2888 sec; Batch: 2.0954 sec
0.0738 0.0583 0.0478 0.0418 0.0388 0.0363 0.0344 0.0329 0.0317 0.0309 0.0302 0.0298 0.0294 0.0290 0.0289 0.0287 

[TRAIN] Epoch[6](263/375); Loss: 0.049246; Backpropagation: 0.2888 sec; Batch: 2.0751 sec
0.0948 0.0724 0.0607 0.0535 0.0499 0.0473 0.0453 0.0436 0.0422 0.0413 0.0406 0.0400 0.0395 0.0392 0.0389 0.0387 

[TRAIN] Epoch[6](264/375); Loss: 0.036031; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0729 0.0541 0.0445 0.0391 0.0362 0.0342 0.0327 0.0314 0.0306 0.0299 0.0293 0.0289 0.0285 0.0282 0.0280 0.0279 

[TRAIN] Epoch[6](265/375); Loss: 0.061032; Backpropagation: 0.2889 sec; Batch: 2.0822 sec
0.1312 0.0996 0.0805 0.0694 0.0614 0.0567 0.0535 0.0512 0.0494 0.0482 0.0473 0.0465 0.0459 0.0455 0.0452 0.0449 

[TRAIN] Epoch[6](266/375); Loss: 0.042621; Backpropagation: 0.2884 sec; Batch: 2.1131 sec
0.1046 0.0896 0.0677 0.0504 0.0410 0.0365 0.0341 0.0322 0.0307 0.0295 0.0287 0.0281 0.0276 0.0273 0.0270 0.0268 

[TRAIN] Epoch[6](267/375); Loss: 0.060058; Backpropagation: 0.2885 sec; Batch: 2.0730 sec
0.1178 0.1002 0.0828 0.0682 0.0596 0.0560 0.0531 0.0511 0.0495 0.0481 0.0470 0.0463 0.0458 0.0455 0.0451 0.0449 

[TRAIN] Epoch[6](268/375); Loss: 0.037375; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0792 0.0574 0.0479 0.0421 0.0386 0.0361 0.0338 0.0322 0.0308 0.0300 0.0293 0.0287 0.0283 0.0280 0.0278 0.0277 

[TRAIN] Epoch[6](269/375); Loss: 0.040545; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0993 0.0741 0.0550 0.0440 0.0391 0.0362 0.0340 0.0322 0.0313 0.0304 0.0298 0.0293 0.0289 0.0286 0.0283 0.0281 

[TRAIN] Epoch[6](270/375); Loss: 0.029729; Backpropagation: 0.2885 sec; Batch: 2.0811 sec
0.0758 0.0574 0.0408 0.0325 0.0281 0.0258 0.0242 0.0231 0.0224 0.0217 0.0213 0.0209 0.0206 0.0204 0.0203 0.0202 

[TRAIN] Epoch[6](271/375); Loss: 0.063106; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1154 0.0952 0.0794 0.0691 0.0638 0.0603 0.0579 0.0561 0.0545 0.0533 0.0523 0.0514 0.0508 0.0504 0.0500 0.0497 

[TRAIN] Epoch[6](272/375); Loss: 0.039432; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0794 0.0604 0.0484 0.0420 0.0391 0.0370 0.0355 0.0343 0.0335 0.0327 0.0322 0.0318 0.0315 0.0312 0.0310 0.0309 

[TRAIN] Epoch[6](273/375); Loss: 0.036914; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0867 0.0684 0.0566 0.0435 0.0355 0.0319 0.0304 0.0291 0.0281 0.0273 0.0266 0.0260 0.0256 0.0252 0.0249 0.0247 

[TRAIN] Epoch[6](274/375); Loss: 0.054775; Backpropagation: 0.2889 sec; Batch: 2.0744 sec
0.1085 0.0836 0.0694 0.0608 0.0552 0.0520 0.0495 0.0474 0.0460 0.0450 0.0442 0.0437 0.0433 0.0429 0.0426 0.0425 

[TRAIN] Epoch[6](275/375); Loss: 0.057569; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1022 0.0834 0.0719 0.0650 0.0608 0.0569 0.0540 0.0518 0.0500 0.0485 0.0474 0.0467 0.0462 0.0457 0.0454 0.0452 

[TRAIN] Epoch[6](276/375); Loss: 0.046776; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0884 0.0679 0.0575 0.0515 0.0478 0.0451 0.0430 0.0413 0.0401 0.0393 0.0387 0.0381 0.0378 0.0375 0.0373 0.0371 

[TRAIN] Epoch[6](277/375); Loss: 0.054046; Backpropagation: 0.2883 sec; Batch: 2.0767 sec
0.1074 0.0808 0.0670 0.0587 0.0543 0.0512 0.0490 0.0473 0.0459 0.0450 0.0442 0.0435 0.0431 0.0427 0.0424 0.0423 

[TRAIN] Epoch[6](278/375); Loss: 0.051543; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0995 0.0787 0.0643 0.0568 0.0528 0.0497 0.0473 0.0453 0.0439 0.0427 0.0419 0.0413 0.0407 0.0403 0.0399 0.0397 

[TRAIN] Epoch[6](279/375); Loss: 0.031169; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.0758 0.0538 0.0416 0.0342 0.0304 0.0282 0.0266 0.0254 0.0245 0.0237 0.0232 0.0227 0.0224 0.0222 0.0221 0.0219 

[TRAIN] Epoch[6](280/375); Loss: 0.040867; Backpropagation: 0.2884 sec; Batch: 2.0729 sec
0.0911 0.0654 0.0524 0.0445 0.0409 0.0380 0.0358 0.0344 0.0334 0.0325 0.0319 0.0314 0.0309 0.0306 0.0304 0.0303 

[TRAIN] Epoch[6](281/375); Loss: 0.067643; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.1214 0.1014 0.0875 0.0782 0.0714 0.0653 0.0623 0.0596 0.0577 0.0562 0.0551 0.0543 0.0537 0.0531 0.0527 0.0524 

[TRAIN] Epoch[6](282/375); Loss: 0.030318; Backpropagation: 0.2884 sec; Batch: 2.0726 sec
0.0769 0.0544 0.0411 0.0333 0.0298 0.0275 0.0257 0.0243 0.0232 0.0226 0.0219 0.0214 0.0211 0.0208 0.0206 0.0205 

[TRAIN] Epoch[6](283/375); Loss: 0.038999; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.0879 0.0618 0.0499 0.0420 0.0382 0.0358 0.0340 0.0327 0.0318 0.0311 0.0305 0.0301 0.0298 0.0296 0.0294 0.0293 

[TRAIN] Epoch[6](284/375); Loss: 0.039002; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0750 0.0597 0.0474 0.0415 0.0391 0.0372 0.0355 0.0343 0.0334 0.0326 0.0321 0.0317 0.0314 0.0311 0.0310 0.0309 

[TRAIN] Epoch[6](285/375); Loss: 0.048710; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0989 0.0722 0.0603 0.0538 0.0500 0.0469 0.0442 0.0425 0.0411 0.0400 0.0392 0.0387 0.0383 0.0379 0.0377 0.0376 

[TRAIN] Epoch[6](286/375); Loss: 0.047457; Backpropagation: 0.2885 sec; Batch: 2.0729 sec
0.0993 0.0772 0.0636 0.0541 0.0487 0.0450 0.0422 0.0402 0.0385 0.0374 0.0366 0.0360 0.0356 0.0352 0.0349 0.0347 

[TRAIN] Epoch[6](287/375); Loss: 0.039603; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.0858 0.0656 0.0512 0.0441 0.0399 0.0370 0.0350 0.0335 0.0323 0.0313 0.0306 0.0300 0.0297 0.0294 0.0292 0.0290 

[TRAIN] Epoch[6](288/375); Loss: 0.055903; Backpropagation: 0.2887 sec; Batch: 2.0814 sec
0.1029 0.0835 0.0699 0.0616 0.0571 0.0540 0.0516 0.0496 0.0483 0.0471 0.0461 0.0453 0.0448 0.0444 0.0442 0.0440 

[TRAIN] Epoch[6](289/375); Loss: 0.047156; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0980 0.0725 0.0587 0.0513 0.0472 0.0443 0.0424 0.0408 0.0395 0.0386 0.0379 0.0374 0.0369 0.0366 0.0363 0.0362 

[TRAIN] Epoch[6](290/375); Loss: 0.052993; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.1115 0.0766 0.0637 0.0575 0.0536 0.0505 0.0481 0.0463 0.0450 0.0439 0.0430 0.0424 0.0420 0.0415 0.0413 0.0411 

[TRAIN] Epoch[6](291/375); Loss: 0.046721; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1014 0.0724 0.0591 0.0521 0.0474 0.0444 0.0420 0.0400 0.0385 0.0374 0.0365 0.0359 0.0355 0.0352 0.0349 0.0348 

[TRAIN] Epoch[6](292/375); Loss: 0.059422; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.1137 0.0900 0.0750 0.0658 0.0605 0.0567 0.0541 0.0521 0.0506 0.0494 0.0485 0.0477 0.0472 0.0468 0.0465 0.0463 

[TRAIN] Epoch[6](293/375); Loss: 0.033175; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0847 0.0559 0.0447 0.0382 0.0337 0.0301 0.0278 0.0264 0.0254 0.0246 0.0240 0.0236 0.0233 0.0230 0.0229 0.0227 

[TRAIN] Epoch[6](294/375); Loss: 0.028960; Backpropagation: 0.2884 sec; Batch: 2.1128 sec
0.0697 0.0471 0.0367 0.0316 0.0286 0.0265 0.0251 0.0239 0.0231 0.0225 0.0220 0.0217 0.0214 0.0213 0.0212 0.0211 

[TRAIN] Epoch[6](295/375); Loss: 0.035833; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.0681 0.0510 0.0429 0.0389 0.0366 0.0348 0.0333 0.0320 0.0311 0.0304 0.0298 0.0294 0.0290 0.0288 0.0287 0.0285 

[TRAIN] Epoch[6](296/375); Loss: 0.040859; Backpropagation: 0.2885 sec; Batch: 2.0812 sec
0.0929 0.0674 0.0519 0.0448 0.0408 0.0379 0.0361 0.0345 0.0332 0.0323 0.0315 0.0309 0.0303 0.0300 0.0298 0.0296 

[TRAIN] Epoch[6](297/375); Loss: 0.046713; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.1242 0.0921 0.0703 0.0530 0.0442 0.0398 0.0374 0.0352 0.0338 0.0326 0.0319 0.0313 0.0308 0.0305 0.0302 0.0300 

[TRAIN] Epoch[6](298/375); Loss: 0.047302; Backpropagation: 0.2887 sec; Batch: 2.0753 sec
0.0968 0.0715 0.0592 0.0521 0.0483 0.0452 0.0427 0.0411 0.0400 0.0389 0.0380 0.0374 0.0369 0.0365 0.0362 0.0360 

[TRAIN] Epoch[6](299/375); Loss: 0.038415; Backpropagation: 0.2888 sec; Batch: 2.0731 sec
0.0932 0.0648 0.0490 0.0412 0.0374 0.0348 0.0330 0.0317 0.0306 0.0297 0.0291 0.0286 0.0282 0.0279 0.0277 0.0275 

[TRAIN] Epoch[6](300/375); Loss: 0.049934; Backpropagation: 0.2884 sec; Batch: 2.0811 sec
0.1178 0.0838 0.0666 0.0566 0.0499 0.0453 0.0430 0.0411 0.0394 0.0382 0.0374 0.0367 0.0363 0.0360 0.0356 0.0354 

[TRAIN] Epoch[6](301/375); Loss: 0.028623; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0766 0.0484 0.0372 0.0311 0.0275 0.0253 0.0241 0.0230 0.0221 0.0214 0.0209 0.0205 0.0202 0.0201 0.0199 0.0198 

[TRAIN] Epoch[6](302/375); Loss: 0.064769; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.1158 0.0953 0.0801 0.0709 0.0660 0.0627 0.0601 0.0581 0.0564 0.0551 0.0541 0.0533 0.0527 0.0522 0.0519 0.0516 

[TRAIN] Epoch[6](303/375); Loss: 0.040321; Backpropagation: 0.2886 sec; Batch: 2.0774 sec
0.0999 0.0649 0.0502 0.0429 0.0389 0.0365 0.0346 0.0334 0.0323 0.0315 0.0309 0.0304 0.0300 0.0298 0.0296 0.0295 

[TRAIN] Epoch[6](304/375); Loss: 0.048335; Backpropagation: 0.2884 sec; Batch: 2.1154 sec
0.1210 0.0925 0.0702 0.0566 0.0474 0.0418 0.0396 0.0373 0.0358 0.0347 0.0338 0.0332 0.0327 0.0324 0.0322 0.0320 

[TRAIN] Epoch[6](305/375); Loss: 0.048248; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0916 0.0706 0.0604 0.0540 0.0497 0.0466 0.0444 0.0426 0.0412 0.0403 0.0394 0.0388 0.0385 0.0382 0.0379 0.0377 

[TRAIN] Epoch[6](306/375); Loss: 0.061850; Backpropagation: 0.2884 sec; Batch: 2.1082 sec
0.1106 0.0872 0.0733 0.0672 0.0626 0.0594 0.0573 0.0555 0.0543 0.0532 0.0526 0.0520 0.0516 0.0513 0.0510 0.0508 

[TRAIN] Epoch[6](307/375); Loss: 0.049928; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1229 0.0895 0.0688 0.0543 0.0474 0.0441 0.0419 0.0403 0.0387 0.0375 0.0368 0.0361 0.0356 0.0352 0.0350 0.0347 

[TRAIN] Epoch[6](308/375); Loss: 0.053335; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.0998 0.0773 0.0652 0.0579 0.0542 0.0511 0.0490 0.0472 0.0461 0.0452 0.0445 0.0438 0.0434 0.0431 0.0428 0.0426 

[TRAIN] Epoch[6](309/375); Loss: 0.036369; Backpropagation: 0.2885 sec; Batch: 2.0815 sec
0.0870 0.0650 0.0494 0.0414 0.0369 0.0339 0.0315 0.0295 0.0282 0.0272 0.0265 0.0258 0.0253 0.0250 0.0247 0.0246 

[TRAIN] Epoch[6](310/375); Loss: 0.047381; Backpropagation: 0.2884 sec; Batch: 2.1104 sec
0.1029 0.0742 0.0593 0.0509 0.0466 0.0439 0.0420 0.0405 0.0392 0.0384 0.0377 0.0371 0.0367 0.0364 0.0362 0.0360 

[TRAIN] Epoch[6](311/375); Loss: 0.054691; Backpropagation: 0.2886 sec; Batch: 2.0732 sec
0.1237 0.1027 0.0827 0.0655 0.0546 0.0485 0.0453 0.0431 0.0416 0.0404 0.0395 0.0387 0.0379 0.0374 0.0370 0.0366 

[TRAIN] Epoch[6](312/375); Loss: 0.035519; Backpropagation: 0.2882 sec; Batch: 2.0881 sec
0.0763 0.0551 0.0453 0.0381 0.0350 0.0330 0.0317 0.0305 0.0295 0.0288 0.0282 0.0278 0.0275 0.0273 0.0271 0.0270 

[TRAIN] Epoch[6](313/375); Loss: 0.050002; Backpropagation: 0.2886 sec; Batch: 2.0863 sec
0.0863 0.0721 0.0609 0.0547 0.0516 0.0493 0.0470 0.0454 0.0440 0.0430 0.0421 0.0415 0.0410 0.0407 0.0404 0.0402 

[TRAIN] Epoch[6](314/375); Loss: 0.048348; Backpropagation: 0.2889 sec; Batch: 2.0736 sec
0.1108 0.0956 0.0745 0.0587 0.0483 0.0430 0.0400 0.0379 0.0362 0.0349 0.0338 0.0329 0.0323 0.0318 0.0315 0.0313 

[TRAIN] Epoch[6](315/375); Loss: 0.064385; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1223 0.0976 0.0809 0.0709 0.0657 0.0620 0.0592 0.0569 0.0549 0.0537 0.0526 0.0518 0.0511 0.0506 0.0502 0.0499 

[TRAIN] Epoch[6](316/375); Loss: 0.043323; Backpropagation: 0.2886 sec; Batch: 2.1177 sec
0.0920 0.0703 0.0548 0.0468 0.0425 0.0398 0.0381 0.0368 0.0358 0.0350 0.0344 0.0339 0.0336 0.0333 0.0331 0.0330 

[TRAIN] Epoch[6](317/375); Loss: 0.051550; Backpropagation: 0.2883 sec; Batch: 2.0781 sec
0.0958 0.0730 0.0612 0.0557 0.0519 0.0494 0.0474 0.0460 0.0449 0.0440 0.0435 0.0430 0.0426 0.0424 0.0422 0.0420 

[TRAIN] Epoch[6](318/375); Loss: 0.037662; Backpropagation: 0.2889 sec; Batch: 2.0742 sec
0.0755 0.0563 0.0455 0.0398 0.0372 0.0355 0.0341 0.0329 0.0321 0.0314 0.0310 0.0306 0.0304 0.0302 0.0300 0.0299 

[TRAIN] Epoch[6](319/375); Loss: 0.046817; Backpropagation: 0.2886 sec; Batch: 2.0808 sec
0.0974 0.0778 0.0615 0.0514 0.0475 0.0444 0.0419 0.0398 0.0383 0.0372 0.0364 0.0358 0.0354 0.0350 0.0347 0.0345 

[TRAIN] Epoch[6](320/375); Loss: 0.040607; Backpropagation: 0.2881 sec; Batch: 2.0742 sec
0.0851 0.0607 0.0500 0.0439 0.0408 0.0387 0.0367 0.0351 0.0340 0.0332 0.0327 0.0323 0.0319 0.0317 0.0315 0.0314 

[TRAIN] Epoch[6](321/375); Loss: 0.027819; Backpropagation: 0.2885 sec; Batch: 2.0728 sec
0.0734 0.0503 0.0379 0.0308 0.0269 0.0245 0.0229 0.0218 0.0210 0.0203 0.0198 0.0194 0.0192 0.0190 0.0189 0.0188 

[TRAIN] Epoch[6](322/375); Loss: 0.064888; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1164 0.0929 0.0799 0.0716 0.0670 0.0632 0.0602 0.0582 0.0565 0.0553 0.0544 0.0536 0.0529 0.0524 0.0520 0.0517 

[TRAIN] Epoch[6](323/375); Loss: 0.036114; Backpropagation: 0.2882 sec; Batch: 2.0838 sec
0.0751 0.0566 0.0452 0.0388 0.0354 0.0334 0.0319 0.0309 0.0301 0.0295 0.0291 0.0288 0.0285 0.0283 0.0282 0.0281 

[TRAIN] Epoch[6](324/375); Loss: 0.053018; Backpropagation: 0.2885 sec; Batch: 2.1145 sec
0.1053 0.0806 0.0664 0.0581 0.0536 0.0504 0.0482 0.0465 0.0449 0.0437 0.0429 0.0422 0.0418 0.0415 0.0412 0.0410 

[TRAIN] Epoch[6](325/375); Loss: 0.052145; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1064 0.0798 0.0632 0.0563 0.0516 0.0486 0.0466 0.0450 0.0439 0.0431 0.0425 0.0420 0.0416 0.0414 0.0412 0.0411 

[TRAIN] Epoch[6](326/375); Loss: 0.045617; Backpropagation: 0.2889 sec; Batch: 2.0750 sec
0.1007 0.0703 0.0566 0.0494 0.0454 0.0430 0.0407 0.0389 0.0377 0.0369 0.0362 0.0356 0.0352 0.0348 0.0345 0.0342 

[TRAIN] Epoch[6](327/375); Loss: 0.029399; Backpropagation: 0.2887 sec; Batch: 2.1132 sec
0.0655 0.0432 0.0367 0.0321 0.0297 0.0279 0.0263 0.0252 0.0244 0.0238 0.0232 0.0229 0.0227 0.0224 0.0223 0.0222 

[TRAIN] Epoch[6](328/375); Loss: 0.070640; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.1485 0.1181 0.0943 0.0795 0.0706 0.0660 0.0625 0.0597 0.0577 0.0562 0.0549 0.0537 0.0529 0.0523 0.0518 0.0515 

[TRAIN] Epoch[6](329/375); Loss: 0.058589; Backpropagation: 0.2887 sec; Batch: 2.1101 sec
0.1128 0.0845 0.0719 0.0654 0.0610 0.0569 0.0540 0.0517 0.0501 0.0489 0.0480 0.0472 0.0468 0.0464 0.0461 0.0459 

[TRAIN] Epoch[6](330/375); Loss: 0.056497; Backpropagation: 0.2892 sec; Batch: 2.0748 sec
0.1112 0.0840 0.0708 0.0628 0.0580 0.0543 0.0519 0.0496 0.0480 0.0468 0.0458 0.0450 0.0445 0.0440 0.0437 0.0434 

[TRAIN] Epoch[6](331/375); Loss: 0.037235; Backpropagation: 0.2885 sec; Batch: 2.0764 sec
0.0806 0.0589 0.0455 0.0396 0.0370 0.0349 0.0333 0.0321 0.0311 0.0302 0.0295 0.0291 0.0288 0.0285 0.0284 0.0282 

[TRAIN] Epoch[6](332/375); Loss: 0.042627; Backpropagation: 0.2888 sec; Batch: 2.0743 sec
0.0880 0.0668 0.0551 0.0475 0.0432 0.0402 0.0379 0.0363 0.0351 0.0344 0.0337 0.0333 0.0330 0.0327 0.0325 0.0323 

[TRAIN] Epoch[6](333/375); Loss: 0.033108; Backpropagation: 0.2884 sec; Batch: 2.0769 sec
0.0715 0.0513 0.0410 0.0360 0.0338 0.0317 0.0299 0.0285 0.0273 0.0266 0.0261 0.0257 0.0253 0.0251 0.0250 0.0248 

[TRAIN] Epoch[6](334/375); Loss: 0.022031; Backpropagation: 0.2889 sec; Batch: 2.0744 sec
0.0437 0.0324 0.0270 0.0231 0.0215 0.0204 0.0196 0.0190 0.0187 0.0184 0.0183 0.0182 0.0181 0.0181 0.0180 0.0180 

[TRAIN] Epoch[6](335/375); Loss: 0.039595; Backpropagation: 0.2885 sec; Batch: 2.1123 sec
0.0915 0.0628 0.0517 0.0436 0.0394 0.0367 0.0348 0.0334 0.0323 0.0312 0.0304 0.0298 0.0293 0.0290 0.0288 0.0287 

[TRAIN] Epoch[6](336/375); Loss: 0.039689; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0874 0.0669 0.0522 0.0437 0.0395 0.0367 0.0347 0.0332 0.0321 0.0312 0.0306 0.0301 0.0296 0.0293 0.0290 0.0288 

[TRAIN] Epoch[6](337/375); Loss: 0.038179; Backpropagation: 0.2884 sec; Batch: 2.0768 sec
0.0769 0.0576 0.0458 0.0409 0.0379 0.0356 0.0343 0.0332 0.0325 0.0319 0.0314 0.0310 0.0307 0.0306 0.0304 0.0303 

[TRAIN] Epoch[6](338/375); Loss: 0.043924; Backpropagation: 0.2887 sec; Batch: 2.0757 sec
0.0820 0.0637 0.0539 0.0480 0.0447 0.0422 0.0405 0.0392 0.0381 0.0372 0.0365 0.0359 0.0355 0.0352 0.0351 0.0350 

[TRAIN] Epoch[6](339/375); Loss: 0.062459; Backpropagation: 0.2883 sec; Batch: 2.0731 sec
0.1111 0.0900 0.0763 0.0678 0.0639 0.0607 0.0581 0.0563 0.0547 0.0535 0.0526 0.0518 0.0511 0.0507 0.0504 0.0501 

[TRAIN] Epoch[6](340/375); Loss: 0.064967; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1291 0.1036 0.0830 0.0710 0.0645 0.0608 0.0582 0.0561 0.0547 0.0533 0.0521 0.0514 0.0509 0.0505 0.0502 0.0500 

[TRAIN] Epoch[6](341/375); Loss: 0.051702; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.1066 0.0808 0.0659 0.0592 0.0540 0.0496 0.0465 0.0443 0.0428 0.0414 0.0405 0.0399 0.0394 0.0390 0.0387 0.0385 

[TRAIN] Epoch[6](342/375); Loss: 0.031975; Backpropagation: 0.2881 sec; Batch: 2.1163 sec
0.0725 0.0531 0.0422 0.0361 0.0323 0.0297 0.0279 0.0264 0.0253 0.0246 0.0241 0.0238 0.0235 0.0234 0.0233 0.0232 

[TRAIN] Epoch[6](343/375); Loss: 0.045444; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.0882 0.0662 0.0555 0.0495 0.0461 0.0436 0.0418 0.0403 0.0391 0.0382 0.0374 0.0369 0.0366 0.0362 0.0359 0.0357 

[TRAIN] Epoch[6](344/375); Loss: 0.047048; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0793 0.0653 0.0562 0.0511 0.0482 0.0460 0.0442 0.0428 0.0418 0.0410 0.0404 0.0399 0.0395 0.0392 0.0390 0.0388 

[TRAIN] Epoch[6](345/375); Loss: 0.064625; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1175 0.0937 0.0814 0.0712 0.0661 0.0631 0.0603 0.0581 0.0561 0.0546 0.0536 0.0528 0.0520 0.0515 0.0511 0.0509 

[TRAIN] Epoch[6](346/375); Loss: 0.064326; Backpropagation: 0.2888 sec; Batch: 2.0945 sec
0.1268 0.0963 0.0776 0.0670 0.0629 0.0604 0.0582 0.0565 0.0553 0.0543 0.0535 0.0529 0.0524 0.0520 0.0517 0.0515 

[TRAIN] Epoch[6](347/375); Loss: 0.034267; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0845 0.0655 0.0461 0.0376 0.0333 0.0304 0.0285 0.0272 0.0261 0.0253 0.0247 0.0243 0.0240 0.0237 0.0235 0.0234 

[TRAIN] Epoch[6](348/375); Loss: 0.049339; Backpropagation: 0.2884 sec; Batch: 2.0730 sec
0.1084 0.0766 0.0646 0.0560 0.0504 0.0463 0.0437 0.0416 0.0401 0.0391 0.0383 0.0376 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[6](349/375); Loss: 0.031510; Backpropagation: 0.2887 sec; Batch: 2.0772 sec
0.0676 0.0513 0.0411 0.0345 0.0313 0.0291 0.0275 0.0265 0.0257 0.0251 0.0247 0.0243 0.0241 0.0239 0.0238 0.0237 

[TRAIN] Epoch[6](350/375); Loss: 0.035022; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0669 0.0523 0.0433 0.0385 0.0358 0.0337 0.0321 0.0309 0.0299 0.0292 0.0286 0.0283 0.0280 0.0278 0.0276 0.0275 

[TRAIN] Epoch[6](351/375); Loss: 0.045891; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0953 0.0709 0.0584 0.0501 0.0454 0.0427 0.0408 0.0395 0.0384 0.0375 0.0368 0.0363 0.0359 0.0357 0.0354 0.0352 

[TRAIN] Epoch[6](352/375); Loss: 0.041657; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0937 0.0689 0.0538 0.0455 0.0415 0.0386 0.0361 0.0346 0.0336 0.0327 0.0320 0.0316 0.0312 0.0310 0.0308 0.0307 

[TRAIN] Epoch[6](353/375); Loss: 0.057575; Backpropagation: 0.2887 sec; Batch: 2.0769 sec
0.1340 0.1139 0.0872 0.0662 0.0554 0.0509 0.0478 0.0452 0.0433 0.0419 0.0408 0.0399 0.0393 0.0388 0.0384 0.0382 

[TRAIN] Epoch[6](354/375); Loss: 0.035874; Backpropagation: 0.2883 sec; Batch: 2.0727 sec
0.0815 0.0572 0.0452 0.0384 0.0354 0.0332 0.0316 0.0304 0.0294 0.0287 0.0281 0.0276 0.0271 0.0269 0.0267 0.0266 

[TRAIN] Epoch[6](355/375); Loss: 0.046338; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.0860 0.0666 0.0554 0.0500 0.0471 0.0446 0.0428 0.0414 0.0403 0.0395 0.0388 0.0383 0.0380 0.0377 0.0376 0.0374 

[TRAIN] Epoch[6](356/375); Loss: 0.046118; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.1201 0.0819 0.0585 0.0487 0.0442 0.0408 0.0386 0.0369 0.0356 0.0347 0.0340 0.0334 0.0330 0.0327 0.0325 0.0324 

[TRAIN] Epoch[6](357/375); Loss: 0.060938; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.1148 0.0927 0.0762 0.0678 0.0622 0.0588 0.0561 0.0538 0.0520 0.0508 0.0498 0.0490 0.0484 0.0479 0.0475 0.0472 

[TRAIN] Epoch[6](358/375); Loss: 0.041252; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0862 0.0684 0.0528 0.0452 0.0413 0.0387 0.0367 0.0350 0.0339 0.0330 0.0324 0.0319 0.0315 0.0312 0.0310 0.0308 

[TRAIN] Epoch[6](359/375); Loss: 0.046054; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.0913 0.0695 0.0571 0.0506 0.0468 0.0440 0.0417 0.0401 0.0390 0.0381 0.0374 0.0369 0.0365 0.0362 0.0360 0.0359 

[TRAIN] Epoch[6](360/375); Loss: 0.058289; Backpropagation: 0.2883 sec; Batch: 2.0771 sec
0.1152 0.0916 0.0746 0.0649 0.0588 0.0549 0.0524 0.0505 0.0489 0.0477 0.0468 0.0462 0.0457 0.0452 0.0448 0.0446 

[TRAIN] Epoch[6](361/375); Loss: 0.049445; Backpropagation: 0.2887 sec; Batch: 2.0747 sec
0.1131 0.0791 0.0636 0.0564 0.0501 0.0462 0.0436 0.0416 0.0400 0.0386 0.0377 0.0371 0.0365 0.0361 0.0359 0.0357 

[TRAIN] Epoch[6](362/375); Loss: 0.046477; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.0794 0.0581 0.0519 0.0490 0.0474 0.0456 0.0440 0.0427 0.0418 0.0413 0.0409 0.0406 0.0403 0.0403 0.0402 0.0402 

[TRAIN] Epoch[6](363/375); Loss: 0.047481; Backpropagation: 0.2884 sec; Batch: 2.0774 sec
0.0982 0.0743 0.0593 0.0508 0.0467 0.0441 0.0423 0.0407 0.0398 0.0389 0.0384 0.0379 0.0375 0.0372 0.0370 0.0368 

[TRAIN] Epoch[6](364/375); Loss: 0.041834; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.0934 0.0662 0.0531 0.0451 0.0407 0.0380 0.0363 0.0351 0.0343 0.0336 0.0330 0.0326 0.0323 0.0320 0.0319 0.0317 

[TRAIN] Epoch[6](365/375); Loss: 0.056395; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.1062 0.0874 0.0710 0.0618 0.0571 0.0539 0.0517 0.0496 0.0481 0.0470 0.0460 0.0454 0.0448 0.0444 0.0441 0.0438 

[TRAIN] Epoch[6](366/375); Loss: 0.029759; Backpropagation: 0.2881 sec; Batch: 2.0830 sec
0.0640 0.0470 0.0381 0.0328 0.0302 0.0281 0.0266 0.0254 0.0244 0.0238 0.0233 0.0229 0.0226 0.0224 0.0223 0.0222 

[TRAIN] Epoch[6](367/375); Loss: 0.041598; Backpropagation: 0.2883 sec; Batch: 2.0765 sec
0.1106 0.0785 0.0559 0.0452 0.0410 0.0374 0.0348 0.0327 0.0312 0.0300 0.0291 0.0285 0.0281 0.0278 0.0275 0.0273 

[TRAIN] Epoch[6](368/375); Loss: 0.042532; Backpropagation: 0.2885 sec; Batch: 2.0731 sec
0.0821 0.0615 0.0512 0.0454 0.0425 0.0404 0.0389 0.0377 0.0368 0.0360 0.0354 0.0350 0.0347 0.0344 0.0342 0.0341 

[TRAIN] Epoch[6](369/375); Loss: 0.044377; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0894 0.0690 0.0563 0.0489 0.0451 0.0423 0.0402 0.0384 0.0371 0.0361 0.0355 0.0349 0.0346 0.0343 0.0340 0.0339 

[TRAIN] Epoch[6](370/375); Loss: 0.049492; Backpropagation: 0.2886 sec; Batch: 2.0756 sec
0.1018 0.0794 0.0627 0.0532 0.0487 0.0461 0.0441 0.0425 0.0414 0.0404 0.0397 0.0391 0.0387 0.0383 0.0380 0.0378 

[TRAIN] Epoch[6](371/375); Loss: 0.050796; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0969 0.0777 0.0644 0.0565 0.0522 0.0490 0.0466 0.0447 0.0431 0.0420 0.0412 0.0405 0.0399 0.0395 0.0392 0.0390 

[TRAIN] Epoch[6](372/375); Loss: 0.054790; Backpropagation: 0.2888 sec; Batch: 2.1135 sec
0.1038 0.0828 0.0676 0.0597 0.0555 0.0526 0.0503 0.0485 0.0470 0.0458 0.0450 0.0443 0.0439 0.0435 0.0432 0.0430 

[TRAIN] Epoch[6](373/375); Loss: 0.043025; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0956 0.0701 0.0565 0.0469 0.0425 0.0400 0.0378 0.0362 0.0350 0.0341 0.0333 0.0327 0.0323 0.0320 0.0318 0.0315 

[TRAIN] Epoch[6](374/375); Loss: 0.030497; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0751 0.0498 0.0385 0.0331 0.0300 0.0276 0.0260 0.0251 0.0242 0.0235 0.0231 0.0227 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[6](375/375); Loss: 0.047645; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0991 0.0758 0.0583 0.0517 0.0477 0.0450 0.0429 0.0412 0.0398 0.0388 0.0381 0.0375 0.0371 0.0367 0.0365 0.0363 

[TRAIN] Epoch[7](1/375); Loss: 0.048258; Backpropagation: 0.3036 sec; Batch: 2.1450 sec
0.0894 0.0752 0.0609 0.0534 0.0496 0.0467 0.0445 0.0427 0.0413 0.0401 0.0392 0.0385 0.0381 0.0378 0.0375 0.0373 

[TRAIN] Epoch[7](2/375); Loss: 0.038923; Backpropagation: 0.2885 sec; Batch: 2.1002 sec
0.0746 0.0531 0.0449 0.0417 0.0392 0.0373 0.0359 0.0348 0.0340 0.0334 0.0329 0.0326 0.0323 0.0321 0.0320 0.0319 

[TRAIN] Epoch[7](3/375); Loss: 0.030147; Backpropagation: 0.2887 sec; Batch: 2.0854 sec
0.0631 0.0468 0.0373 0.0327 0.0301 0.0283 0.0270 0.0260 0.0253 0.0246 0.0241 0.0238 0.0235 0.0233 0.0232 0.0231 

[TRAIN] Epoch[7](4/375); Loss: 0.041543; Backpropagation: 0.2889 sec; Batch: 2.0824 sec
0.0887 0.0716 0.0550 0.0448 0.0411 0.0383 0.0364 0.0349 0.0338 0.0329 0.0321 0.0316 0.0312 0.0310 0.0307 0.0306 

[TRAIN] Epoch[7](5/375); Loss: 0.051287; Backpropagation: 0.2887 sec; Batch: 2.1160 sec
0.1002 0.0794 0.0631 0.0559 0.0515 0.0485 0.0464 0.0448 0.0435 0.0425 0.0418 0.0413 0.0408 0.0405 0.0403 0.0401 

[TRAIN] Epoch[7](6/375); Loss: 0.054179; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.1121 0.0866 0.0689 0.0595 0.0552 0.0514 0.0487 0.0466 0.0450 0.0437 0.0428 0.0421 0.0416 0.0412 0.0408 0.0405 

[TRAIN] Epoch[7](7/375); Loss: 0.054971; Backpropagation: 0.2882 sec; Batch: 2.1153 sec
0.1102 0.0870 0.0712 0.0606 0.0555 0.0525 0.0499 0.0479 0.0462 0.0448 0.0438 0.0429 0.0424 0.0419 0.0416 0.0413 

[TRAIN] Epoch[7](8/375); Loss: 0.047093; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.1032 0.0705 0.0605 0.0537 0.0484 0.0443 0.0414 0.0397 0.0385 0.0374 0.0368 0.0363 0.0360 0.0358 0.0356 0.0354 

[TRAIN] Epoch[7](9/375); Loss: 0.043104; Backpropagation: 0.2885 sec; Batch: 2.0804 sec
0.0822 0.0617 0.0515 0.0462 0.0433 0.0411 0.0396 0.0383 0.0374 0.0367 0.0361 0.0357 0.0353 0.0351 0.0348 0.0347 

[TRAIN] Epoch[7](10/375); Loss: 0.045985; Backpropagation: 0.2886 sec; Batch: 2.0872 sec
0.0897 0.0687 0.0561 0.0491 0.0460 0.0437 0.0418 0.0405 0.0395 0.0386 0.0379 0.0375 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[7](11/375); Loss: 0.050492; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.0939 0.0766 0.0629 0.0554 0.0515 0.0486 0.0464 0.0446 0.0432 0.0423 0.0415 0.0408 0.0404 0.0401 0.0399 0.0397 

[TRAIN] Epoch[7](12/375); Loss: 0.033338; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0832 0.0566 0.0441 0.0363 0.0328 0.0303 0.0284 0.0269 0.0260 0.0253 0.0247 0.0242 0.0239 0.0237 0.0235 0.0234 

[TRAIN] Epoch[7](13/375); Loss: 0.029510; Backpropagation: 0.2886 sec; Batch: 2.0822 sec
0.0669 0.0459 0.0372 0.0313 0.0286 0.0270 0.0257 0.0248 0.0242 0.0237 0.0233 0.0230 0.0228 0.0226 0.0226 0.0225 

[TRAIN] Epoch[7](14/375); Loss: 0.046151; Backpropagation: 0.2886 sec; Batch: 2.1135 sec
0.1062 0.0843 0.0654 0.0536 0.0459 0.0417 0.0390 0.0370 0.0355 0.0345 0.0337 0.0331 0.0326 0.0322 0.0319 0.0317 

[TRAIN] Epoch[7](15/375); Loss: 0.030331; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0805 0.0564 0.0416 0.0340 0.0296 0.0268 0.0249 0.0237 0.0227 0.0219 0.0213 0.0209 0.0206 0.0203 0.0202 0.0200 

[TRAIN] Epoch[7](16/375); Loss: 0.042919; Backpropagation: 0.2888 sec; Batch: 2.0924 sec
0.0915 0.0671 0.0546 0.0476 0.0435 0.0404 0.0384 0.0368 0.0355 0.0345 0.0338 0.0333 0.0329 0.0326 0.0323 0.0321 

[TRAIN] Epoch[7](17/375); Loss: 0.040184; Backpropagation: 0.2889 sec; Batch: 2.0758 sec
0.0768 0.0602 0.0493 0.0445 0.0414 0.0388 0.0366 0.0353 0.0344 0.0336 0.0329 0.0324 0.0321 0.0318 0.0315 0.0314 

[TRAIN] Epoch[7](18/375); Loss: 0.042102; Backpropagation: 0.2885 sec; Batch: 2.0768 sec
0.0902 0.0709 0.0534 0.0451 0.0415 0.0392 0.0372 0.0357 0.0345 0.0337 0.0330 0.0325 0.0321 0.0318 0.0315 0.0314 

[TRAIN] Epoch[7](19/375); Loss: 0.040083; Backpropagation: 0.2888 sec; Batch: 2.0744 sec
0.0838 0.0642 0.0502 0.0439 0.0404 0.0381 0.0360 0.0345 0.0333 0.0325 0.0318 0.0312 0.0308 0.0305 0.0302 0.0300 

[TRAIN] Epoch[7](20/375); Loss: 0.056421; Backpropagation: 0.2884 sec; Batch: 2.0757 sec
0.1016 0.0784 0.0675 0.0615 0.0579 0.0550 0.0528 0.0509 0.0494 0.0483 0.0476 0.0471 0.0466 0.0462 0.0460 0.0458 

[TRAIN] Epoch[7](21/375); Loss: 0.032517; Backpropagation: 0.2885 sec; Batch: 2.0859 sec
0.0796 0.0520 0.0412 0.0353 0.0321 0.0296 0.0281 0.0269 0.0259 0.0253 0.0247 0.0244 0.0240 0.0238 0.0237 0.0235 

[TRAIN] Epoch[7](22/375); Loss: 0.026077; Backpropagation: 0.2887 sec; Batch: 2.0774 sec
0.0659 0.0457 0.0331 0.0275 0.0247 0.0228 0.0218 0.0209 0.0203 0.0198 0.0195 0.0193 0.0191 0.0190 0.0189 0.0189 

[TRAIN] Epoch[7](23/375); Loss: 0.024862; Backpropagation: 0.2885 sec; Batch: 2.0862 sec
0.0613 0.0409 0.0297 0.0262 0.0239 0.0221 0.0212 0.0204 0.0199 0.0195 0.0191 0.0189 0.0188 0.0187 0.0186 0.0186 

[TRAIN] Epoch[7](24/375); Loss: 0.048435; Backpropagation: 0.2883 sec; Batch: 2.0770 sec
0.0906 0.0703 0.0597 0.0531 0.0496 0.0468 0.0446 0.0430 0.0419 0.0409 0.0400 0.0395 0.0392 0.0388 0.0386 0.0384 

[TRAIN] Epoch[7](25/375); Loss: 0.038213; Backpropagation: 0.2888 sec; Batch: 2.0781 sec
0.1048 0.0709 0.0499 0.0414 0.0356 0.0329 0.0310 0.0297 0.0286 0.0278 0.0273 0.0268 0.0265 0.0262 0.0261 0.0259 

[TRAIN] Epoch[7](26/375); Loss: 0.046674; Backpropagation: 0.2883 sec; Batch: 2.0762 sec
0.0891 0.0696 0.0576 0.0514 0.0474 0.0445 0.0428 0.0413 0.0401 0.0390 0.0383 0.0378 0.0374 0.0370 0.0368 0.0366 

[TRAIN] Epoch[7](27/375); Loss: 0.036188; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0785 0.0564 0.0451 0.0396 0.0364 0.0340 0.0323 0.0310 0.0300 0.0292 0.0286 0.0281 0.0278 0.0275 0.0273 0.0272 

[TRAIN] Epoch[7](28/375); Loss: 0.050531; Backpropagation: 0.2887 sec; Batch: 2.0742 sec
0.0927 0.0707 0.0607 0.0549 0.0513 0.0488 0.0468 0.0453 0.0443 0.0433 0.0426 0.0421 0.0417 0.0414 0.0411 0.0409 

[TRAIN] Epoch[7](29/375); Loss: 0.030864; Backpropagation: 0.2884 sec; Batch: 2.0817 sec
0.0714 0.0571 0.0407 0.0334 0.0301 0.0281 0.0264 0.0251 0.0240 0.0234 0.0229 0.0226 0.0224 0.0222 0.0221 0.0220 

[TRAIN] Epoch[7](30/375); Loss: 0.033677; Backpropagation: 0.2885 sec; Batch: 2.0817 sec
0.0590 0.0487 0.0408 0.0369 0.0344 0.0325 0.0312 0.0302 0.0294 0.0288 0.0284 0.0281 0.0279 0.0277 0.0275 0.0274 

[TRAIN] Epoch[7](31/375); Loss: 0.045727; Backpropagation: 0.2885 sec; Batch: 2.0992 sec
0.0952 0.0687 0.0582 0.0503 0.0460 0.0432 0.0410 0.0394 0.0382 0.0375 0.0367 0.0361 0.0357 0.0354 0.0351 0.0348 

[TRAIN] Epoch[7](32/375); Loss: 0.030328; Backpropagation: 0.2884 sec; Batch: 2.0766 sec
0.0692 0.0478 0.0378 0.0320 0.0297 0.0279 0.0266 0.0255 0.0247 0.0242 0.0238 0.0235 0.0233 0.0232 0.0230 0.0229 

[TRAIN] Epoch[7](33/375); Loss: 0.030755; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0665 0.0461 0.0385 0.0340 0.0311 0.0291 0.0276 0.0265 0.0255 0.0248 0.0243 0.0240 0.0238 0.0236 0.0234 0.0233 

[TRAIN] Epoch[7](34/375); Loss: 0.039881; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.0817 0.0598 0.0490 0.0431 0.0404 0.0382 0.0363 0.0347 0.0335 0.0328 0.0322 0.0318 0.0315 0.0313 0.0310 0.0309 

[TRAIN] Epoch[7](35/375); Loss: 0.040085; Backpropagation: 0.2886 sec; Batch: 2.0759 sec
0.0798 0.0582 0.0486 0.0444 0.0415 0.0388 0.0367 0.0353 0.0342 0.0333 0.0326 0.0322 0.0318 0.0315 0.0313 0.0311 

[TRAIN] Epoch[7](36/375); Loss: 0.045415; Backpropagation: 0.2890 sec; Batch: 2.0743 sec
0.1008 0.0745 0.0581 0.0485 0.0439 0.0415 0.0396 0.0382 0.0371 0.0363 0.0357 0.0351 0.0347 0.0344 0.0341 0.0340 

[TRAIN] Epoch[7](37/375); Loss: 0.068643; Backpropagation: 0.2884 sec; Batch: 2.0894 sec
0.1414 0.1193 0.0977 0.0854 0.0735 0.0616 0.0575 0.0552 0.0536 0.0523 0.0515 0.0508 0.0502 0.0498 0.0494 0.0491 

[TRAIN] Epoch[7](38/375); Loss: 0.035975; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0873 0.0602 0.0471 0.0391 0.0354 0.0329 0.0310 0.0294 0.0282 0.0274 0.0269 0.0265 0.0263 0.0261 0.0260 0.0259 

[TRAIN] Epoch[7](39/375); Loss: 0.045431; Backpropagation: 0.2880 sec; Batch: 2.0817 sec
0.0939 0.0670 0.0556 0.0487 0.0455 0.0432 0.0414 0.0398 0.0386 0.0376 0.0369 0.0364 0.0360 0.0356 0.0354 0.0352 

[TRAIN] Epoch[7](40/375); Loss: 0.048641; Backpropagation: 0.2888 sec; Batch: 2.0841 sec
0.1061 0.0764 0.0613 0.0529 0.0485 0.0452 0.0429 0.0412 0.0400 0.0391 0.0384 0.0379 0.0375 0.0371 0.0369 0.0367 

[TRAIN] Epoch[7](41/375); Loss: 0.054642; Backpropagation: 0.2882 sec; Batch: 2.0756 sec
0.1163 0.0842 0.0699 0.0610 0.0554 0.0509 0.0483 0.0464 0.0451 0.0441 0.0433 0.0426 0.0422 0.0418 0.0415 0.0413 

[TRAIN] Epoch[7](42/375); Loss: 0.048110; Backpropagation: 0.2888 sec; Batch: 2.0782 sec
0.0991 0.0741 0.0606 0.0542 0.0496 0.0461 0.0434 0.0416 0.0400 0.0389 0.0381 0.0376 0.0371 0.0367 0.0364 0.0362 

[TRAIN] Epoch[7](43/375); Loss: 0.054125; Backpropagation: 0.2880 sec; Batch: 2.1081 sec
0.1064 0.0844 0.0666 0.0617 0.0544 0.0507 0.0483 0.0467 0.0456 0.0446 0.0438 0.0433 0.0429 0.0425 0.0422 0.0421 

[TRAIN] Epoch[7](44/375); Loss: 0.054157; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1182 0.0914 0.0740 0.0619 0.0555 0.0508 0.0472 0.0448 0.0430 0.0418 0.0410 0.0403 0.0397 0.0393 0.0389 0.0387 

[TRAIN] Epoch[7](45/375); Loss: 0.046224; Backpropagation: 0.2887 sec; Batch: 2.0818 sec
0.1035 0.0757 0.0610 0.0513 0.0468 0.0432 0.0407 0.0388 0.0373 0.0361 0.0354 0.0348 0.0343 0.0339 0.0336 0.0334 

[TRAIN] Epoch[7](46/375); Loss: 0.030298; Backpropagation: 0.2888 sec; Batch: 2.0900 sec
0.0733 0.0468 0.0379 0.0322 0.0298 0.0280 0.0265 0.0255 0.0246 0.0240 0.0235 0.0231 0.0227 0.0225 0.0223 0.0222 

[TRAIN] Epoch[7](47/375); Loss: 0.039234; Backpropagation: 0.2887 sec; Batch: 2.0774 sec
0.0949 0.0654 0.0521 0.0436 0.0389 0.0362 0.0338 0.0322 0.0309 0.0300 0.0294 0.0288 0.0283 0.0280 0.0278 0.0276 

[TRAIN] Epoch[7](48/375); Loss: 0.042414; Backpropagation: 0.2890 sec; Batch: 2.0774 sec
0.0976 0.0711 0.0541 0.0459 0.0415 0.0386 0.0367 0.0352 0.0340 0.0332 0.0327 0.0322 0.0318 0.0315 0.0313 0.0312 

[TRAIN] Epoch[7](49/375); Loss: 0.036129; Backpropagation: 0.2888 sec; Batch: 2.0781 sec
0.0810 0.0582 0.0463 0.0397 0.0361 0.0338 0.0320 0.0306 0.0294 0.0286 0.0279 0.0274 0.0271 0.0268 0.0266 0.0265 

[TRAIN] Epoch[7](50/375); Loss: 0.051218; Backpropagation: 0.2887 sec; Batch: 2.0768 sec
0.1015 0.0815 0.0649 0.0561 0.0523 0.0489 0.0462 0.0443 0.0430 0.0420 0.0411 0.0404 0.0399 0.0395 0.0391 0.0389 

[TRAIN] Epoch[7](51/375); Loss: 0.049952; Backpropagation: 0.2890 sec; Batch: 2.0744 sec
0.0947 0.0709 0.0611 0.0553 0.0510 0.0482 0.0460 0.0442 0.0429 0.0421 0.0414 0.0409 0.0405 0.0402 0.0400 0.0399 

[TRAIN] Epoch[7](52/375); Loss: 0.040229; Backpropagation: 0.2888 sec; Batch: 2.1172 sec
0.0917 0.0643 0.0496 0.0436 0.0402 0.0376 0.0357 0.0342 0.0330 0.0320 0.0313 0.0307 0.0303 0.0300 0.0298 0.0296 

[TRAIN] Epoch[7](53/375); Loss: 0.033615; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0745 0.0498 0.0408 0.0363 0.0334 0.0313 0.0298 0.0288 0.0281 0.0274 0.0270 0.0266 0.0263 0.0261 0.0259 0.0258 

[TRAIN] Epoch[7](54/375); Loss: 0.049119; Backpropagation: 0.2887 sec; Batch: 2.0823 sec
0.1120 0.0839 0.0654 0.0539 0.0479 0.0447 0.0426 0.0406 0.0392 0.0381 0.0373 0.0367 0.0363 0.0360 0.0357 0.0356 

[TRAIN] Epoch[7](55/375); Loss: 0.064200; Backpropagation: 0.2885 sec; Batch: 2.0771 sec
0.1419 0.1255 0.0982 0.0730 0.0610 0.0561 0.0525 0.0505 0.0488 0.0476 0.0467 0.0459 0.0454 0.0450 0.0446 0.0445 

[TRAIN] Epoch[7](56/375); Loss: 0.040269; Backpropagation: 0.2885 sec; Batch: 2.0733 sec
0.0773 0.0616 0.0501 0.0443 0.0411 0.0386 0.0364 0.0350 0.0340 0.0333 0.0328 0.0324 0.0321 0.0319 0.0317 0.0315 

[TRAIN] Epoch[7](57/375); Loss: 0.035684; Backpropagation: 0.2884 sec; Batch: 2.0793 sec
0.0718 0.0517 0.0438 0.0392 0.0362 0.0342 0.0326 0.0313 0.0303 0.0297 0.0291 0.0287 0.0283 0.0281 0.0280 0.0279 

[TRAIN] Epoch[7](58/375); Loss: 0.044770; Backpropagation: 0.2889 sec; Batch: 2.1118 sec
0.1013 0.0722 0.0588 0.0495 0.0445 0.0414 0.0392 0.0376 0.0363 0.0353 0.0344 0.0339 0.0334 0.0331 0.0328 0.0326 

[TRAIN] Epoch[7](59/375); Loss: 0.049356; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.1143 0.0877 0.0674 0.0548 0.0485 0.0449 0.0423 0.0404 0.0389 0.0377 0.0367 0.0361 0.0355 0.0351 0.0348 0.0346 

[TRAIN] Epoch[7](60/375); Loss: 0.047571; Backpropagation: 0.2886 sec; Batch: 2.0732 sec
0.1024 0.0735 0.0591 0.0512 0.0471 0.0444 0.0425 0.0409 0.0396 0.0387 0.0380 0.0374 0.0370 0.0367 0.0364 0.0363 

[TRAIN] Epoch[7](61/375); Loss: 0.057661; Backpropagation: 0.2885 sec; Batch: 2.1096 sec
0.1157 0.0884 0.0719 0.0633 0.0584 0.0550 0.0524 0.0503 0.0486 0.0474 0.0465 0.0458 0.0452 0.0448 0.0445 0.0443 

[TRAIN] Epoch[7](62/375); Loss: 0.029894; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0742 0.0537 0.0397 0.0326 0.0289 0.0266 0.0251 0.0240 0.0231 0.0225 0.0220 0.0216 0.0214 0.0212 0.0210 0.0209 

[TRAIN] Epoch[7](63/375); Loss: 0.071322; Backpropagation: 0.2882 sec; Batch: 2.0780 sec
0.1230 0.1029 0.0870 0.0776 0.0728 0.0692 0.0664 0.0642 0.0624 0.0612 0.0603 0.0596 0.0591 0.0587 0.0585 0.0583 

[TRAIN] Epoch[7](64/375); Loss: 0.059373; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1099 0.0867 0.0731 0.0652 0.0606 0.0575 0.0550 0.0530 0.0513 0.0501 0.0492 0.0485 0.0480 0.0476 0.0473 0.0471 

[TRAIN] Epoch[7](65/375); Loss: 0.042818; Backpropagation: 0.2884 sec; Batch: 2.1055 sec
0.0952 0.0670 0.0537 0.0471 0.0428 0.0398 0.0377 0.0362 0.0352 0.0343 0.0336 0.0331 0.0327 0.0324 0.0322 0.0320 

[TRAIN] Epoch[7](66/375); Loss: 0.040913; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0819 0.0633 0.0502 0.0444 0.0412 0.0389 0.0369 0.0356 0.0345 0.0338 0.0331 0.0327 0.0324 0.0321 0.0319 0.0318 

[TRAIN] Epoch[7](67/375); Loss: 0.039557; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.0774 0.0585 0.0480 0.0424 0.0392 0.0371 0.0357 0.0347 0.0339 0.0333 0.0328 0.0324 0.0322 0.0320 0.0318 0.0317 

[TRAIN] Epoch[7](68/375); Loss: 0.032305; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0674 0.0509 0.0405 0.0348 0.0319 0.0300 0.0285 0.0275 0.0268 0.0262 0.0258 0.0255 0.0254 0.0253 0.0252 0.0252 

[TRAIN] Epoch[7](69/375); Loss: 0.031412; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0794 0.0550 0.0409 0.0341 0.0304 0.0281 0.0265 0.0253 0.0244 0.0237 0.0232 0.0228 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[7](70/375); Loss: 0.045205; Backpropagation: 0.2883 sec; Batch: 2.0727 sec
0.0831 0.0641 0.0540 0.0494 0.0463 0.0440 0.0423 0.0408 0.0396 0.0386 0.0379 0.0374 0.0369 0.0365 0.0363 0.0361 

[TRAIN] Epoch[7](71/375); Loss: 0.047949; Backpropagation: 0.2885 sec; Batch: 2.0815 sec
0.0832 0.0663 0.0566 0.0513 0.0485 0.0465 0.0448 0.0433 0.0423 0.0416 0.0411 0.0408 0.0404 0.0402 0.0401 0.0400 

[TRAIN] Epoch[7](72/375); Loss: 0.048653; Backpropagation: 0.2886 sec; Batch: 2.0739 sec
0.1023 0.0756 0.0613 0.0547 0.0502 0.0467 0.0440 0.0419 0.0403 0.0392 0.0383 0.0377 0.0371 0.0366 0.0364 0.0361 

[TRAIN] Epoch[7](73/375); Loss: 0.045474; Backpropagation: 0.2887 sec; Batch: 2.0771 sec
0.0859 0.0693 0.0568 0.0490 0.0453 0.0425 0.0408 0.0395 0.0388 0.0382 0.0377 0.0373 0.0370 0.0367 0.0365 0.0364 

[TRAIN] Epoch[7](74/375); Loss: 0.058748; Backpropagation: 0.2888 sec; Batch: 2.1137 sec
0.1127 0.0855 0.0715 0.0645 0.0603 0.0570 0.0542 0.0521 0.0506 0.0493 0.0484 0.0477 0.0471 0.0467 0.0463 0.0460 

[TRAIN] Epoch[7](75/375); Loss: 0.039096; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.0839 0.0579 0.0466 0.0419 0.0390 0.0369 0.0353 0.0339 0.0329 0.0321 0.0316 0.0312 0.0308 0.0307 0.0305 0.0303 

[TRAIN] Epoch[7](76/375); Loss: 0.053507; Backpropagation: 0.2885 sec; Batch: 2.0852 sec
0.1076 0.0793 0.0682 0.0601 0.0550 0.0515 0.0487 0.0466 0.0451 0.0439 0.0431 0.0423 0.0418 0.0413 0.0410 0.0408 

[TRAIN] Epoch[7](77/375); Loss: 0.045352; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.0772 0.0628 0.0543 0.0501 0.0469 0.0445 0.0425 0.0411 0.0402 0.0394 0.0387 0.0383 0.0379 0.0375 0.0373 0.0372 

[TRAIN] Epoch[7](78/375); Loss: 0.029632; Backpropagation: 0.2890 sec; Batch: 2.1037 sec
0.0690 0.0478 0.0381 0.0318 0.0293 0.0271 0.0256 0.0245 0.0238 0.0232 0.0229 0.0226 0.0224 0.0222 0.0220 0.0220 

[TRAIN] Epoch[7](79/375); Loss: 0.061257; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1221 0.0918 0.0754 0.0675 0.0628 0.0591 0.0560 0.0537 0.0520 0.0506 0.0495 0.0489 0.0483 0.0479 0.0475 0.0472 

[TRAIN] Epoch[7](80/375); Loss: 0.039836; Backpropagation: 0.2884 sec; Batch: 2.0734 sec
0.0869 0.0639 0.0506 0.0433 0.0394 0.0374 0.0356 0.0340 0.0328 0.0319 0.0312 0.0307 0.0303 0.0300 0.0298 0.0296 

[TRAIN] Epoch[7](81/375); Loss: 0.038646; Backpropagation: 0.2882 sec; Batch: 2.0816 sec
0.0815 0.0615 0.0499 0.0432 0.0394 0.0366 0.0343 0.0328 0.0317 0.0309 0.0303 0.0299 0.0295 0.0292 0.0290 0.0288 

[TRAIN] Epoch[7](82/375); Loss: 0.064334; Backpropagation: 0.2883 sec; Batch: 2.1128 sec
0.1189 0.0894 0.0768 0.0703 0.0662 0.0628 0.0602 0.0581 0.0563 0.0551 0.0540 0.0532 0.0526 0.0522 0.0518 0.0515 

[TRAIN] Epoch[7](83/375); Loss: 0.046676; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0962 0.0726 0.0594 0.0518 0.0475 0.0444 0.0420 0.0403 0.0389 0.0379 0.0370 0.0364 0.0360 0.0357 0.0354 0.0353 

[TRAIN] Epoch[7](84/375); Loss: 0.045625; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0849 0.0656 0.0559 0.0494 0.0461 0.0436 0.0420 0.0405 0.0397 0.0388 0.0382 0.0377 0.0373 0.0370 0.0368 0.0366 

[TRAIN] Epoch[7](85/375); Loss: 0.038812; Backpropagation: 0.2883 sec; Batch: 2.0863 sec
0.0841 0.0580 0.0486 0.0427 0.0391 0.0368 0.0350 0.0334 0.0322 0.0314 0.0307 0.0303 0.0299 0.0297 0.0296 0.0295 

[TRAIN] Epoch[7](86/375); Loss: 0.037153; Backpropagation: 0.2884 sec; Batch: 2.0763 sec
0.0850 0.0605 0.0476 0.0413 0.0374 0.0345 0.0325 0.0310 0.0299 0.0291 0.0284 0.0280 0.0277 0.0273 0.0272 0.0270 

[TRAIN] Epoch[7](87/375); Loss: 0.062701; Backpropagation: 0.2879 sec; Batch: 2.1096 sec
0.1312 0.1028 0.0840 0.0709 0.0634 0.0589 0.0559 0.0533 0.0514 0.0499 0.0486 0.0476 0.0470 0.0465 0.0460 0.0457 

[TRAIN] Epoch[7](88/375); Loss: 0.047330; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0902 0.0705 0.0578 0.0518 0.0481 0.0455 0.0434 0.0417 0.0406 0.0397 0.0390 0.0385 0.0380 0.0377 0.0375 0.0373 

[TRAIN] Epoch[7](89/375); Loss: 0.031866; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0737 0.0517 0.0417 0.0347 0.0311 0.0289 0.0275 0.0264 0.0257 0.0251 0.0246 0.0242 0.0239 0.0237 0.0235 0.0234 

[TRAIN] Epoch[7](90/375); Loss: 0.035729; Backpropagation: 0.2880 sec; Batch: 2.0765 sec
0.0810 0.0613 0.0475 0.0395 0.0354 0.0326 0.0308 0.0294 0.0284 0.0276 0.0271 0.0267 0.0264 0.0262 0.0260 0.0259 

[TRAIN] Epoch[7](91/375); Loss: 0.060201; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.1098 0.0881 0.0734 0.0651 0.0608 0.0576 0.0553 0.0536 0.0524 0.0513 0.0505 0.0499 0.0494 0.0490 0.0487 0.0485 

[TRAIN] Epoch[7](92/375); Loss: 0.044116; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.1040 0.0773 0.0590 0.0475 0.0423 0.0396 0.0375 0.0360 0.0348 0.0340 0.0332 0.0327 0.0323 0.0320 0.0319 0.0317 

[TRAIN] Epoch[7](93/375); Loss: 0.043606; Backpropagation: 0.2887 sec; Batch: 2.0746 sec
0.0863 0.0652 0.0528 0.0467 0.0437 0.0413 0.0396 0.0384 0.0374 0.0365 0.0359 0.0353 0.0350 0.0347 0.0346 0.0344 

[TRAIN] Epoch[7](94/375); Loss: 0.034166; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0614 0.0475 0.0414 0.0368 0.0346 0.0329 0.0318 0.0307 0.0300 0.0294 0.0290 0.0287 0.0284 0.0282 0.0280 0.0279 

[TRAIN] Epoch[7](95/375); Loss: 0.059070; Backpropagation: 0.2885 sec; Batch: 2.0785 sec
0.1339 0.1167 0.0870 0.0674 0.0571 0.0521 0.0492 0.0468 0.0451 0.0435 0.0425 0.0416 0.0411 0.0407 0.0403 0.0400 

[TRAIN] Epoch[7](96/375); Loss: 0.034726; Backpropagation: 0.2887 sec; Batch: 2.0942 sec
0.0871 0.0575 0.0428 0.0374 0.0336 0.0314 0.0297 0.0285 0.0275 0.0267 0.0262 0.0259 0.0256 0.0254 0.0252 0.0251 

[TRAIN] Epoch[7](97/375); Loss: 0.026428; Backpropagation: 0.2882 sec; Batch: 2.0731 sec
0.0604 0.0397 0.0322 0.0281 0.0258 0.0242 0.0232 0.0224 0.0219 0.0214 0.0211 0.0208 0.0206 0.0204 0.0203 0.0203 

[TRAIN] Epoch[7](98/375); Loss: 0.040151; Backpropagation: 0.2883 sec; Batch: 2.0783 sec
0.0806 0.0598 0.0497 0.0440 0.0407 0.0383 0.0366 0.0352 0.0341 0.0332 0.0325 0.0321 0.0318 0.0315 0.0313 0.0311 

[TRAIN] Epoch[7](99/375); Loss: 0.033445; Backpropagation: 0.2886 sec; Batch: 2.0772 sec
0.0904 0.0624 0.0459 0.0358 0.0311 0.0288 0.0272 0.0258 0.0250 0.0243 0.0238 0.0234 0.0230 0.0228 0.0227 0.0226 

[TRAIN] Epoch[7](100/375); Loss: 0.060758; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.1269 0.0931 0.0769 0.0673 0.0618 0.0577 0.0547 0.0524 0.0507 0.0492 0.0483 0.0475 0.0469 0.0465 0.0462 0.0459 

[TRAIN] Epoch[7](101/375); Loss: 0.049920; Backpropagation: 0.2885 sec; Batch: 2.0775 sec
0.0980 0.0769 0.0619 0.0544 0.0503 0.0477 0.0456 0.0439 0.0424 0.0414 0.0405 0.0400 0.0395 0.0390 0.0387 0.0385 

[TRAIN] Epoch[7](102/375); Loss: 0.053215; Backpropagation: 0.2882 sec; Batch: 2.0772 sec
0.1074 0.0824 0.0670 0.0589 0.0543 0.0510 0.0481 0.0461 0.0447 0.0435 0.0426 0.0419 0.0414 0.0410 0.0407 0.0404 

[TRAIN] Epoch[7](103/375); Loss: 0.047421; Backpropagation: 0.2885 sec; Batch: 2.0787 sec
0.1066 0.0766 0.0616 0.0532 0.0483 0.0448 0.0420 0.0400 0.0383 0.0371 0.0362 0.0355 0.0351 0.0347 0.0344 0.0342 

[TRAIN] Epoch[7](104/375); Loss: 0.047484; Backpropagation: 0.2886 sec; Batch: 2.0852 sec
0.0965 0.0726 0.0602 0.0531 0.0492 0.0460 0.0434 0.0415 0.0398 0.0386 0.0377 0.0371 0.0365 0.0361 0.0359 0.0357 

[TRAIN] Epoch[7](105/375); Loss: 0.051311; Backpropagation: 0.2884 sec; Batch: 2.0771 sec
0.1107 0.0835 0.0667 0.0566 0.0511 0.0476 0.0452 0.0432 0.0419 0.0408 0.0400 0.0394 0.0390 0.0387 0.0384 0.0382 

[TRAIN] Epoch[7](106/375); Loss: 0.053120; Backpropagation: 0.2884 sec; Batch: 2.0739 sec
0.1009 0.0784 0.0649 0.0578 0.0537 0.0508 0.0486 0.0469 0.0456 0.0446 0.0440 0.0435 0.0430 0.0426 0.0424 0.0422 

[TRAIN] Epoch[7](107/375); Loss: 0.043840; Backpropagation: 0.2886 sec; Batch: 2.0779 sec
0.0850 0.0601 0.0532 0.0474 0.0442 0.0418 0.0402 0.0389 0.0381 0.0373 0.0368 0.0363 0.0359 0.0356 0.0354 0.0353 

[TRAIN] Epoch[7](108/375); Loss: 0.032892; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0770 0.0579 0.0422 0.0362 0.0323 0.0300 0.0283 0.0269 0.0260 0.0252 0.0247 0.0243 0.0240 0.0238 0.0237 0.0236 

[TRAIN] Epoch[7](109/375); Loss: 0.057265; Backpropagation: 0.2884 sec; Batch: 2.1123 sec
0.1233 0.0950 0.0774 0.0655 0.0574 0.0525 0.0494 0.0476 0.0460 0.0450 0.0441 0.0434 0.0429 0.0425 0.0422 0.0420 

[TRAIN] Epoch[7](110/375); Loss: 0.052431; Backpropagation: 0.2886 sec; Batch: 2.1063 sec
0.0921 0.0769 0.0640 0.0581 0.0545 0.0517 0.0491 0.0471 0.0457 0.0446 0.0437 0.0431 0.0426 0.0422 0.0419 0.0417 

[TRAIN] Epoch[7](111/375); Loss: 0.051463; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1088 0.0795 0.0631 0.0548 0.0504 0.0479 0.0456 0.0441 0.0430 0.0421 0.0415 0.0410 0.0407 0.0405 0.0402 0.0401 

[TRAIN] Epoch[7](112/375); Loss: 0.045393; Backpropagation: 0.2886 sec; Batch: 2.0790 sec
0.0891 0.0713 0.0557 0.0490 0.0456 0.0430 0.0412 0.0396 0.0384 0.0376 0.0369 0.0364 0.0360 0.0357 0.0355 0.0354 

[TRAIN] Epoch[7](113/375); Loss: 0.062513; Backpropagation: 0.2885 sec; Batch: 2.0795 sec
0.1188 0.0924 0.0773 0.0683 0.0629 0.0595 0.0570 0.0550 0.0536 0.0526 0.0517 0.0510 0.0505 0.0501 0.0498 0.0496 

[TRAIN] Epoch[7](114/375); Loss: 0.064312; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1213 0.0972 0.0809 0.0708 0.0655 0.0621 0.0591 0.0570 0.0553 0.0538 0.0526 0.0517 0.0511 0.0506 0.0502 0.0499 

[TRAIN] Epoch[7](115/375); Loss: 0.056955; Backpropagation: 0.2886 sec; Batch: 2.0901 sec
0.0952 0.0799 0.0686 0.0620 0.0577 0.0551 0.0532 0.0517 0.0505 0.0496 0.0490 0.0484 0.0480 0.0477 0.0475 0.0473 

[TRAIN] Epoch[7](116/375); Loss: 0.045642; Backpropagation: 0.2884 sec; Batch: 2.0888 sec
0.1122 0.0769 0.0565 0.0472 0.0430 0.0407 0.0388 0.0375 0.0365 0.0357 0.0351 0.0346 0.0342 0.0339 0.0338 0.0336 

[TRAIN] Epoch[7](117/375); Loss: 0.058996; Backpropagation: 0.2886 sec; Batch: 2.0734 sec
0.1139 0.0883 0.0716 0.0642 0.0594 0.0564 0.0540 0.0520 0.0504 0.0494 0.0484 0.0478 0.0474 0.0471 0.0469 0.0466 

[TRAIN] Epoch[7](118/375); Loss: 0.040481; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0935 0.0673 0.0527 0.0452 0.0407 0.0375 0.0354 0.0338 0.0326 0.0315 0.0307 0.0301 0.0296 0.0293 0.0290 0.0287 

[TRAIN] Epoch[7](119/375); Loss: 0.025585; Backpropagation: 0.2883 sec; Batch: 2.0729 sec
0.0715 0.0474 0.0331 0.0270 0.0241 0.0221 0.0208 0.0199 0.0192 0.0186 0.0182 0.0179 0.0176 0.0174 0.0173 0.0172 

[TRAIN] Epoch[7](120/375); Loss: 0.035722; Backpropagation: 0.2887 sec; Batch: 2.0746 sec
0.0717 0.0537 0.0442 0.0384 0.0356 0.0337 0.0323 0.0312 0.0304 0.0297 0.0292 0.0288 0.0284 0.0282 0.0280 0.0279 

[TRAIN] Epoch[7](121/375); Loss: 0.039658; Backpropagation: 0.2885 sec; Batch: 2.0732 sec
0.0825 0.0602 0.0491 0.0425 0.0395 0.0373 0.0355 0.0341 0.0331 0.0324 0.0320 0.0317 0.0314 0.0312 0.0310 0.0310 

[TRAIN] Epoch[7](122/375); Loss: 0.036318; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1028 0.0765 0.0542 0.0420 0.0342 0.0304 0.0278 0.0263 0.0252 0.0243 0.0237 0.0232 0.0229 0.0226 0.0224 0.0223 

[TRAIN] Epoch[7](123/375); Loss: 0.038910; Backpropagation: 0.2888 sec; Batch: 2.0728 sec
0.0834 0.0591 0.0495 0.0431 0.0393 0.0363 0.0345 0.0331 0.0322 0.0315 0.0309 0.0305 0.0302 0.0299 0.0297 0.0295 

[TRAIN] Epoch[7](124/375); Loss: 0.053004; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0934 0.0746 0.0632 0.0575 0.0542 0.0516 0.0495 0.0479 0.0467 0.0457 0.0449 0.0444 0.0440 0.0437 0.0434 0.0432 

[TRAIN] Epoch[7](125/375); Loss: 0.033833; Backpropagation: 0.2881 sec; Batch: 2.0775 sec
0.0800 0.0559 0.0436 0.0373 0.0337 0.0313 0.0293 0.0278 0.0269 0.0263 0.0256 0.0252 0.0249 0.0247 0.0245 0.0244 

[TRAIN] Epoch[7](126/375); Loss: 0.047068; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0977 0.0719 0.0543 0.0498 0.0469 0.0439 0.0421 0.0409 0.0399 0.0391 0.0385 0.0380 0.0378 0.0376 0.0374 0.0373 

[TRAIN] Epoch[7](127/375); Loss: 0.051681; Backpropagation: 0.2884 sec; Batch: 2.0791 sec
0.0991 0.0763 0.0637 0.0568 0.0526 0.0496 0.0474 0.0455 0.0441 0.0431 0.0423 0.0419 0.0415 0.0412 0.0410 0.0408 

[TRAIN] Epoch[7](128/375); Loss: 0.048214; Backpropagation: 0.2890 sec; Batch: 2.0788 sec
0.0933 0.0757 0.0618 0.0534 0.0495 0.0461 0.0437 0.0419 0.0404 0.0395 0.0387 0.0381 0.0377 0.0374 0.0372 0.0370 

[TRAIN] Epoch[7](129/375); Loss: 0.047765; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.1204 0.0856 0.0646 0.0534 0.0470 0.0430 0.0401 0.0380 0.0364 0.0353 0.0345 0.0339 0.0334 0.0331 0.0329 0.0327 

[TRAIN] Epoch[7](130/375); Loss: 0.029621; Backpropagation: 0.2880 sec; Batch: 2.0811 sec
0.0581 0.0409 0.0348 0.0310 0.0292 0.0280 0.0271 0.0264 0.0258 0.0254 0.0250 0.0247 0.0246 0.0244 0.0243 0.0243 

[TRAIN] Epoch[7](131/375); Loss: 0.040017; Backpropagation: 0.2884 sec; Batch: 2.0747 sec
0.0738 0.0574 0.0479 0.0432 0.0404 0.0385 0.0370 0.0359 0.0350 0.0343 0.0337 0.0332 0.0329 0.0326 0.0324 0.0322 

[TRAIN] Epoch[7](132/375); Loss: 0.059009; Backpropagation: 0.2885 sec; Batch: 2.0818 sec
0.1046 0.0797 0.0694 0.0645 0.0609 0.0584 0.0559 0.0538 0.0522 0.0511 0.0501 0.0495 0.0490 0.0486 0.0483 0.0481 

[TRAIN] Epoch[7](133/375); Loss: 0.057712; Backpropagation: 0.2883 sec; Batch: 2.0767 sec
0.1152 0.0863 0.0721 0.0629 0.0584 0.0550 0.0525 0.0504 0.0489 0.0478 0.0469 0.0463 0.0457 0.0453 0.0450 0.0447 

[TRAIN] Epoch[7](134/375); Loss: 0.057094; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.1121 0.0915 0.0736 0.0629 0.0575 0.0543 0.0517 0.0494 0.0480 0.0467 0.0457 0.0450 0.0444 0.0439 0.0435 0.0433 

[TRAIN] Epoch[7](135/375); Loss: 0.043110; Backpropagation: 0.2885 sec; Batch: 2.0779 sec
0.1064 0.0740 0.0540 0.0461 0.0422 0.0391 0.0367 0.0352 0.0340 0.0331 0.0325 0.0319 0.0315 0.0312 0.0310 0.0309 

[TRAIN] Epoch[7](136/375); Loss: 0.043005; Backpropagation: 0.2889 sec; Batch: 2.0765 sec
0.0986 0.0709 0.0557 0.0463 0.0420 0.0394 0.0374 0.0359 0.0347 0.0338 0.0332 0.0327 0.0323 0.0320 0.0318 0.0316 

[TRAIN] Epoch[7](137/375); Loss: 0.043918; Backpropagation: 0.2886 sec; Batch: 2.0807 sec
0.0964 0.0688 0.0562 0.0484 0.0442 0.0415 0.0393 0.0376 0.0360 0.0349 0.0342 0.0337 0.0333 0.0329 0.0327 0.0325 

[TRAIN] Epoch[7](138/375); Loss: 0.037559; Backpropagation: 0.2886 sec; Batch: 2.0737 sec
0.0904 0.0592 0.0472 0.0393 0.0367 0.0345 0.0328 0.0316 0.0304 0.0296 0.0290 0.0285 0.0282 0.0280 0.0278 0.0277 

[TRAIN] Epoch[7](139/375); Loss: 0.028200; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0734 0.0482 0.0364 0.0305 0.0275 0.0256 0.0241 0.0228 0.0219 0.0212 0.0207 0.0203 0.0200 0.0197 0.0195 0.0194 

[TRAIN] Epoch[7](140/375); Loss: 0.067238; Backpropagation: 0.2883 sec; Batch: 2.0832 sec
0.1250 0.1003 0.0821 0.0730 0.0681 0.0644 0.0619 0.0595 0.0579 0.0567 0.0557 0.0550 0.0545 0.0542 0.0539 0.0537 

[TRAIN] Epoch[7](141/375); Loss: 0.053100; Backpropagation: 0.2885 sec; Batch: 2.0770 sec
0.0945 0.0752 0.0634 0.0578 0.0542 0.0515 0.0497 0.0479 0.0466 0.0455 0.0448 0.0444 0.0439 0.0436 0.0434 0.0432 

[TRAIN] Epoch[7](142/375); Loss: 0.039247; Backpropagation: 0.2884 sec; Batch: 2.1036 sec
0.0982 0.0666 0.0506 0.0437 0.0386 0.0355 0.0333 0.0316 0.0304 0.0297 0.0291 0.0287 0.0283 0.0281 0.0278 0.0277 

[TRAIN] Epoch[7](143/375); Loss: 0.042651; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0771 0.0615 0.0521 0.0467 0.0437 0.0412 0.0392 0.0379 0.0369 0.0363 0.0358 0.0354 0.0350 0.0347 0.0345 0.0344 

[TRAIN] Epoch[7](144/375); Loss: 0.062682; Backpropagation: 0.2883 sec; Batch: 2.0762 sec
0.1436 0.1118 0.0880 0.0738 0.0644 0.0563 0.0523 0.0498 0.0480 0.0469 0.0460 0.0452 0.0447 0.0444 0.0440 0.0438 

[TRAIN] Epoch[7](145/375); Loss: 0.049470; Backpropagation: 0.2885 sec; Batch: 2.0782 sec
0.1014 0.0798 0.0612 0.0519 0.0482 0.0458 0.0441 0.0425 0.0414 0.0406 0.0400 0.0395 0.0391 0.0388 0.0387 0.0385 

[TRAIN] Epoch[7](146/375); Loss: 0.030873; Backpropagation: 0.2884 sec; Batch: 2.1102 sec
0.0700 0.0446 0.0369 0.0322 0.0299 0.0284 0.0273 0.0265 0.0259 0.0254 0.0250 0.0247 0.0245 0.0244 0.0242 0.0241 

[TRAIN] Epoch[7](147/375); Loss: 0.037900; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0858 0.0608 0.0484 0.0423 0.0379 0.0350 0.0332 0.0319 0.0308 0.0299 0.0293 0.0288 0.0284 0.0281 0.0280 0.0278 

[TRAIN] Epoch[7](148/375); Loss: 0.051082; Backpropagation: 0.2885 sec; Batch: 2.0817 sec
0.0946 0.0703 0.0583 0.0533 0.0507 0.0485 0.0471 0.0460 0.0451 0.0444 0.0439 0.0435 0.0432 0.0429 0.0427 0.0426 

[TRAIN] Epoch[7](149/375); Loss: 0.046937; Backpropagation: 0.2888 sec; Batch: 2.0776 sec
0.1069 0.0769 0.0585 0.0506 0.0466 0.0434 0.0412 0.0395 0.0382 0.0372 0.0365 0.0359 0.0354 0.0350 0.0348 0.0346 

[TRAIN] Epoch[7](150/375); Loss: 0.041751; Backpropagation: 0.2884 sec; Batch: 2.0735 sec
0.0815 0.0603 0.0502 0.0447 0.0418 0.0397 0.0381 0.0369 0.0359 0.0352 0.0346 0.0343 0.0340 0.0338 0.0336 0.0335 

[TRAIN] Epoch[7](151/375); Loss: 0.037966; Backpropagation: 0.2885 sec; Batch: 2.0809 sec
0.0836 0.0590 0.0460 0.0409 0.0379 0.0356 0.0338 0.0325 0.0315 0.0307 0.0301 0.0297 0.0294 0.0291 0.0289 0.0288 

[TRAIN] Epoch[7](152/375); Loss: 0.053585; Backpropagation: 0.2888 sec; Batch: 2.0763 sec
0.0994 0.0795 0.0633 0.0571 0.0537 0.0510 0.0491 0.0476 0.0465 0.0456 0.0450 0.0445 0.0441 0.0438 0.0437 0.0435 

[TRAIN] Epoch[7](153/375); Loss: 0.037208; Backpropagation: 0.2889 sec; Batch: 2.0770 sec
0.0922 0.0703 0.0505 0.0412 0.0362 0.0332 0.0312 0.0297 0.0284 0.0275 0.0267 0.0262 0.0258 0.0255 0.0254 0.0252 

[TRAIN] Epoch[7](154/375); Loss: 0.029214; Backpropagation: 0.2888 sec; Batch: 2.0779 sec
0.0619 0.0442 0.0366 0.0319 0.0296 0.0277 0.0262 0.0250 0.0240 0.0235 0.0232 0.0229 0.0228 0.0226 0.0226 0.0225 

[TRAIN] Epoch[7](155/375); Loss: 0.045521; Backpropagation: 0.2887 sec; Batch: 2.0745 sec
0.0876 0.0713 0.0567 0.0496 0.0456 0.0428 0.0410 0.0396 0.0383 0.0376 0.0370 0.0367 0.0364 0.0362 0.0361 0.0360 

[TRAIN] Epoch[7](156/375); Loss: 0.045214; Backpropagation: 0.2886 sec; Batch: 2.0817 sec
0.0922 0.0693 0.0561 0.0493 0.0454 0.0426 0.0405 0.0392 0.0381 0.0372 0.0365 0.0361 0.0357 0.0353 0.0351 0.0349 

[TRAIN] Epoch[7](157/375); Loss: 0.037215; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0915 0.0614 0.0453 0.0394 0.0362 0.0336 0.0320 0.0308 0.0298 0.0291 0.0285 0.0280 0.0277 0.0275 0.0273 0.0272 

[TRAIN] Epoch[7](158/375); Loss: 0.060920; Backpropagation: 0.2884 sec; Batch: 2.0971 sec
0.1339 0.1079 0.0853 0.0678 0.0602 0.0561 0.0528 0.0504 0.0484 0.0470 0.0458 0.0450 0.0442 0.0437 0.0433 0.0430 

[TRAIN] Epoch[7](159/375); Loss: 0.041726; Backpropagation: 0.2884 sec; Batch: 2.0925 sec
0.0896 0.0694 0.0546 0.0466 0.0421 0.0389 0.0369 0.0350 0.0339 0.0329 0.0322 0.0317 0.0313 0.0310 0.0308 0.0306 

[TRAIN] Epoch[7](160/375); Loss: 0.049212; Backpropagation: 0.2887 sec; Batch: 2.0746 sec
0.0914 0.0662 0.0591 0.0535 0.0498 0.0472 0.0454 0.0441 0.0431 0.0422 0.0416 0.0413 0.0409 0.0407 0.0405 0.0403 

[TRAIN] Epoch[7](161/375); Loss: 0.045974; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.1031 0.0732 0.0597 0.0521 0.0468 0.0430 0.0403 0.0383 0.0370 0.0361 0.0354 0.0349 0.0345 0.0340 0.0338 0.0336 

[TRAIN] Epoch[7](162/375); Loss: 0.062109; Backpropagation: 0.2888 sec; Batch: 2.1127 sec
0.1130 0.0974 0.0782 0.0716 0.0638 0.0587 0.0558 0.0540 0.0527 0.0515 0.0507 0.0502 0.0496 0.0492 0.0488 0.0486 
